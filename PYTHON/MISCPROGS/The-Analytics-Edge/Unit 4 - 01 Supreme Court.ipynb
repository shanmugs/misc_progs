{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judge, Jury, and Classifier: An Introduction to Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/CourtBuilding.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, in the Moneyball lecture, we discussed how regular season performance is not strongly correlated with winning the World Series in baseball. In this homework question, we'll use the same data to investigate how well we can predict the World Series winner at the beginning of the playoffs.\n",
    "\n",
    "To begin, load the dataset baseball.csv into R using the read.csv function, and call the data frame \"baseball\". This is the same data file we used during the Moneyball lecture, and the data comes from Baseball-Reference.com.\n",
    "\n",
    "As a reminder, this dataset contains data concerning a baseball team's performance in a given year. It has the following variables:\n",
    "\n",
    "    Team: A code for the name of the team\n",
    "    \n",
    "    League: The Major League Baseball league the team belongs to, either AL (American League) or NL (National League)\n",
    "    \n",
    "    Year: The year of the corresponding record\n",
    "    \n",
    "    RS: The number of runs scored by the team in that year\n",
    "    \n",
    "    RA: The number of runs allowed by the team in that year\n",
    "    \n",
    "    W: The number of regular season wins by the team in that year\n",
    "    \n",
    "    OBP: The on-base percentage of the team in that year\n",
    "    \n",
    "    SLG: The slugging percentage of the team in that year\n",
    "    \n",
    "    BA: The batting average of the team in that year\n",
    "    \n",
    "    Playoffs: Whether the team made the playoffs in that year (1 for yes, 0 for no)\n",
    "    \n",
    "    RankSeason: Among the playoff teams in that year, the ranking of their regular season records (1 is best)\n",
    "    \n",
    "    RankPlayoffs: Among the playoff teams in that year, how well they fared in the playoffs. The team winning the World Series gets a RankPlayoffs of 1.\n",
    "    \n",
    "    G: The number of games a team played in that year\n",
    "    \n",
    "    OOBP: The team's opponents' on-base percentage in that year\n",
    "    \n",
    "    OSLG: The team's opponents' slugging percentage in that year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Cases from 1994 through 2001\n",
    "\n",
    "In this period, same nine justices presided SCOTUS\n",
    "\n",
    "    Breyer, Ginsburg, Kennedy, O’Connor, Rehnquist (Chief Justice), Scalia, Souter, Stevens, Thomas\n",
    "    Rare data set - longest period of time with the same set of justices in over 180 years\n",
    "\n",
    "We will focus on predicting Justice Stevens’ decisions\n",
    "\n",
    "    Started out moderate, but became more liberal\n",
    "    Self-proclaimed conservative\n",
    "\n",
    "### Variables\n",
    "\n",
    "    * Dependent Variable: Did Justice Stevens vote to reverse the lower court decision? 1 = reverse, 0 = affirm\n",
    "\n",
    "    * Indepedent Variable: Properties of the case\n",
    "                           Circuit court of origin\n",
    "                           Issue area of case\n",
    "                           Type of petitioner, type of respondent\n",
    "                           Ideological direction of lower court decision\n",
    "                           Whether petitioner argued that a law/practice was unconstitutional\n",
    "\n",
    "### Logistic Regression for Justice Stevens\n",
    "\n",
    "Some significant variables and their coefficients\n",
    "\n",
    "    Case is from 2nd circuit court: +1.66\n",
    "    Case is from 4th circuit court: +2.82\n",
    "    Lower court decision is liberal: -1.22\n",
    "\n",
    "This is complicated\n",
    "\n",
    "    Difficult to understand which factors are important\n",
    "    Difficult to quickly evaluate what prediction is for a new case\n",
    "\n",
    "### Classification and Regression Trees\n",
    "\n",
    "    Build a tree by splitting on variables\n",
    "    To predict the outcome for an observation, follow the splits and at the end, predict the most frequent outcome\n",
    "    Does not assume a linear model\n",
    "    Interpret able"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Exploration the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Docket</th><th scope=col>Term</th><th scope=col>Circuit</th><th scope=col>Issue</th><th scope=col>Petitioner</th><th scope=col>Respondent</th><th scope=col>LowerCourt</th><th scope=col>Unconst</th><th scope=col>Reverse</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>93-1408</td><td>1994</td><td>2nd</td><td>EconomicActivity</td><td>BUSINESS</td><td>BUSINESS</td><td>liberal</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>93-1577</td><td>1994</td><td>9th</td><td>EconomicActivity</td><td>BUSINESS</td><td>BUSINESS</td><td>liberal</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>93-1612</td><td>1994</td><td>5th</td><td>EconomicActivity</td><td>BUSINESS</td><td>BUSINESS</td><td>liberal</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>94-623 </td><td>1994</td><td>1st</td><td>EconomicActivity</td><td>BUSINESS</td><td>BUSINESS</td><td>conser </td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>94-1175</td><td>1995</td><td>7th</td><td>JudicialPower   </td><td>BUSINESS</td><td>BUSINESS</td><td>conser </td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>95-129 </td><td>1995</td><td>9th</td><td>EconomicActivity</td><td>BUSINESS</td><td>BUSINESS</td><td>conser </td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & Docket & Term & Circuit & Issue & Petitioner & Respondent & LowerCourt & Unconst & Reverse\\\\\n",
       "  & <fct> & <int> & <fct> & <fct> & <fct> & <fct> & <fct> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 93-1408 & 1994 & 2nd & EconomicActivity & BUSINESS & BUSINESS & liberal & 0 & 1\\\\\n",
       "\t2 & 93-1577 & 1994 & 9th & EconomicActivity & BUSINESS & BUSINESS & liberal & 0 & 1\\\\\n",
       "\t3 & 93-1612 & 1994 & 5th & EconomicActivity & BUSINESS & BUSINESS & liberal & 0 & 1\\\\\n",
       "\t4 & 94-623  & 1994 & 1st & EconomicActivity & BUSINESS & BUSINESS & conser  & 0 & 1\\\\\n",
       "\t5 & 94-1175 & 1995 & 7th & JudicialPower    & BUSINESS & BUSINESS & conser  & 0 & 1\\\\\n",
       "\t6 & 95-129  & 1995 & 9th & EconomicActivity & BUSINESS & BUSINESS & conser  & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | Docket &lt;fct&gt; | Term &lt;int&gt; | Circuit &lt;fct&gt; | Issue &lt;fct&gt; | Petitioner &lt;fct&gt; | Respondent &lt;fct&gt; | LowerCourt &lt;fct&gt; | Unconst &lt;int&gt; | Reverse &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 93-1408 | 1994 | 2nd | EconomicActivity | BUSINESS | BUSINESS | liberal | 0 | 1 |\n",
       "| 2 | 93-1577 | 1994 | 9th | EconomicActivity | BUSINESS | BUSINESS | liberal | 0 | 1 |\n",
       "| 3 | 93-1612 | 1994 | 5th | EconomicActivity | BUSINESS | BUSINESS | liberal | 0 | 1 |\n",
       "| 4 | 94-623  | 1994 | 1st | EconomicActivity | BUSINESS | BUSINESS | conser  | 0 | 1 |\n",
       "| 5 | 94-1175 | 1995 | 7th | JudicialPower    | BUSINESS | BUSINESS | conser  | 0 | 1 |\n",
       "| 6 | 95-129  | 1995 | 9th | EconomicActivity | BUSINESS | BUSINESS | conser  | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Docket  Term Circuit Issue            Petitioner Respondent LowerCourt\n",
       "1 93-1408 1994 2nd     EconomicActivity BUSINESS   BUSINESS   liberal   \n",
       "2 93-1577 1994 9th     EconomicActivity BUSINESS   BUSINESS   liberal   \n",
       "3 93-1612 1994 5th     EconomicActivity BUSINESS   BUSINESS   liberal   \n",
       "4 94-623  1994 1st     EconomicActivity BUSINESS   BUSINESS   conser    \n",
       "5 94-1175 1995 7th     JudicialPower    BUSINESS   BUSINESS   conser    \n",
       "6 95-129  1995 9th     EconomicActivity BUSINESS   BUSINESS   conser    \n",
       "  Unconst Reverse\n",
       "1 0       1      \n",
       "2 0       1      \n",
       "3 0       1      \n",
       "4 0       1      \n",
       "5 0       1      \n",
       "6 1       0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stevens = read.csv(\"data/stevens.csv\")\n",
    "head(stevens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t566 obs. of  9 variables:\n",
      " $ Docket    : Factor w/ 566 levels \"00-1011\",\"00-1045\",..: 63 69 70 145 97 181 242 289 334 436 ...\n",
      " $ Term      : int  1994 1994 1994 1994 1995 1995 1996 1997 1997 1999 ...\n",
      " $ Circuit   : Factor w/ 13 levels \"10th\",\"11th\",..: 4 11 7 3 9 11 13 11 12 2 ...\n",
      " $ Issue     : Factor w/ 11 levels \"Attorneys\",\"CivilRights\",..: 5 5 5 5 9 5 5 5 5 3 ...\n",
      " $ Petitioner: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ Respondent: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ LowerCourt: Factor w/ 2 levels \"conser\",\"liberal\": 2 2 2 1 1 1 1 1 1 1 ...\n",
      " $ Unconst   : int  0 0 0 0 0 1 0 1 0 0 ...\n",
      " $ Reverse   : int  1 1 1 1 1 0 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(stevens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Docket         Term         Circuit                  Issue    \n",
       " 00-1011:  1   Min.   :1994   9th    :122   CriminalProcedure:132  \n",
       " 00-1045:  1   1st Qu.:1995   5th    : 53   JudicialPower    :102  \n",
       " 00-1072:  1   Median :1997   11th   : 49   EconomicActivity : 98  \n",
       " 00-1073:  1   Mean   :1997   7th    : 47   CivilRights      : 74  \n",
       " 00-1089:  1   3rd Qu.:1999   4th    : 46   DueProcess       : 43  \n",
       " 00-121 :  1   Max.   :2001   8th    : 44   FirstAmendment   : 39  \n",
       " (Other):560                  (Other):205   (Other)          : 78  \n",
       "               Petitioner               Respondent    LowerCourt \n",
       " OTHER              :175   OTHER             :177   conser :293  \n",
       " CRIMINAL.DEFENDENT : 89   BUSINESS          : 80   liberal:273  \n",
       " BUSINESS           : 79   US                : 69                \n",
       " STATE              : 48   CRIMINAL.DEFENDENT: 58                \n",
       " US                 : 48   STATE             : 56                \n",
       " GOVERNMENT.OFFICIAL: 38   EMPLOYEE          : 28                \n",
       " (Other)            : 89   (Other)           : 98                \n",
       "    Unconst          Reverse      \n",
       " Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.0000  \n",
       " Median :0.0000   Median :1.0000  \n",
       " Mean   :0.2473   Mean   :0.5459  \n",
       " 3rd Qu.:0.0000   3rd Qu.:1.0000  \n",
       " Max.   :1.0000   Max.   :1.0000  \n",
       "                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(stevens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before building models, we need to split our data into a training set and a testing set. We'll do this using the sample.split function, like we did last week for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"caTools\")\n",
    "library(caTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3000) # For all students have the same results\n",
    "\n",
    "spl = sample.split(stevens$Reverse, SplitRatio = 0.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the first argument needs to be our outcome variable, stevens$Reverse, and then the second argument is the SplitRatio, or the percentage of data that we want to put in the training set. In this case, we'll put 70\\% of the data in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = subset(stevens, spl==TRUE)  #70%\n",
    "Test = subset(stevens, spl==FALSE)  #30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install rpart library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"rpart\")\n",
    "library(rpart)\n",
    "\n",
    "#install.packages(\"rpart.plot\")\n",
    "library(rpart.plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll call our model StevensTree, and we'll use the *rpart* function, where the first argument is the same as if we were building a linear or logistic regression model.\n",
    "\n",
    "We give our dependent variable, in our case, *Reverse*, followed by a tilde sign, and then the independent variables separated by plus signs. So Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst. We also need to give our data set that should be used to build our model, which in our case is *Train*.\n",
    "\n",
    "Now we'll give two additional arguments here. The first one is method = \"class\". This tells rpart to build a classification tree, instead of a regression tree. You'll see how we can create regression trees in recitation. \n",
    "\n",
    "The last argument we'll give is *minbucket* = 25. This limits the tree so that it doesn't overfit to our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, \n",
    "                    method=\"class\", minbucket=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nSUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prp(StevensTree) # Plot the Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictCART = predict(StevensTree, newdata = Test, type = \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to give the argument \"class\" when making predictions for our CART model if we want the majority class predictions. This is like using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   PredictCART\n",
       "     0  1\n",
       "  0 41 36\n",
       "  1 22 71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "z = table(Test$Reverse, PredictCART)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are labeled with the actual outcome, and the columns are labeled with the predicted outcome.\n",
    "\n",
    "                  Predict 0       Predict 1\n",
    "    Actual 0    True Negative   False Positive\n",
    "    Actual 1    False Negative  True Positive\n",
    "\n",
    "    z = [1][3]\n",
    "        [2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy CART:  0.6588'</span>"
      ],
      "text/latex": [
       "'Accuracy CART:  0.6588'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy CART:  0.6588'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy CART:  0.6588\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy                        # (TN+TP)/(TN+FN+TP+FP)\n",
    "accur <- (z[1]+z[4])/(z[1]+z[2]+z[3]+z[4])  # Another way: sum(diag(z))/sum(z)\n",
    "paste(\"Accuracy CART: \", round(accur,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the accuracy of our CART model is 0.659. If you were to build a logistic regression model, you would get an accuracy of 0.665 and a baseline model that always predicts Reverse, the most common outcome, has an accuracy of 0.547. So our CART model significantly beats the baseline and is competitive with logistic regression.\n",
    "\n",
    "It's also much more interpretable than a logistic regression model would be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Receiver Operator Characteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"ROCR\")\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.3035714</td><td>0.6964286</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.3035714</td><td>0.6964286</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.4000000</td><td>0.6000000</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.4000000</td><td>0.6000000</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0.4000000</td><td>0.6000000</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.3035714</td><td>0.6964286</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       "  & 0 & 1\\\\\n",
       "\\hline\n",
       "\t1 & 0.3035714 & 0.6964286\\\\\n",
       "\t3 & 0.3035714 & 0.6964286\\\\\n",
       "\t4 & 0.4000000 & 0.6000000\\\\\n",
       "\t6 & 0.4000000 & 0.6000000\\\\\n",
       "\t8 & 0.4000000 & 0.6000000\\\\\n",
       "\t21 & 0.3035714 & 0.6964286\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 2 of type dbl\n",
       "\n",
       "| <!--/--> | 0 | 1 |\n",
       "|---|---|---|\n",
       "| 1 | 0.3035714 | 0.6964286 |\n",
       "| 3 | 0.3035714 | 0.6964286 |\n",
       "| 4 | 0.4000000 | 0.6000000 |\n",
       "| 6 | 0.4000000 | 0.6000000 |\n",
       "| 8 | 0.4000000 | 0.6000000 |\n",
       "| 21 | 0.3035714 | 0.6964286 |\n",
       "\n"
      ],
      "text/plain": [
       "   0         1        \n",
       "1  0.3035714 0.6964286\n",
       "3  0.3035714 0.6964286\n",
       "4  0.4000000 0.6000000\n",
       "6  0.4000000 0.6000000\n",
       "8  0.4000000 0.6000000\n",
       "21 0.3035714 0.6964286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "170"
      ],
      "text/latex": [
       "170"
      ],
      "text/markdown": [
       "170"
      ],
      "text/plain": [
       "[1] 170"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PredictROC = predict(StevensTree, newdata = Test)\n",
    "head(PredictROC)\n",
    "nrow(PredictROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each observation in the test set, it gives two numbers which can be thought of as the probability of outcome 0 and the probability of outcome 1.\n",
    "\n",
    "More concretely, each test set observation is classified into a subset, or bucket, of our CART tree. These numbers give the percentage of training set data in that subset with outcome 0 and the percentage of data in the training set in that subset with outcome 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll use the second column as our probabilities to generate an ROC curve.** So just like we did last week for logistic regression, we'll start by using the prediction function. We'll call the output pred, and then use prediction, where the first argument is the second column of PredictROC, which we can access with square brackets, and the second argument is the true outcome values, Test\\\\$Reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prediction(PredictROC[,2], Test$Reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to use the performance function, where the first argument is the outcome of the prediction function, and then the next two arguments are true positive rate and false positive rate, what we want on the x and y-axes of our ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = performance(pred, \"tpr\", \"fpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAAalUlEQVR4nO3di1rivBqA0RQQFDnc/90OBUdRPNKvaZKu9exnNuMvhEn7Sk9g\nOgKDpamfALRASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBAgQ0gJKnPHWh4fzgRDQCQhQQAhQQAhQQAhQQAh\nQQAhQQAhQQAhQYCsIT1vVueTwKv181hDwCQyhnRYXF1QsRxlCJhIxpDWqXvanW/tt11ajzEE\nTCRjSF3avd7epW6MIWAiGUN6d4Hs91fLConKeEWCAHn3kbb78y37SLQm5+Hv5dVRu8VhlCFg\nGnnPI63P55G61cZ5JNriygYIICQIICQIMFVIziPRlHJCGvjZRjCu71dMm3bwnV/+cBcSfOaP\nG0dCgiv37l0ICe7v5+0BstylwCHg+OcNuG8eKMtdChyCOYs/PJz1/Ui/PsItJMYw4umVjCE9\nColJ5Dg9mXPTbtd9/5EnAUPAm5yn97PuI+2+fztfxBAwyfUxeQ82PF6923ykIZiraa8vc9SO\nuhVyfaaQqFMZ/bwSElUp5AXohpCoQan9vBISJSu9n1dCokDFvwDdEBJlqaufV0KiJDU2dCYk\nClLvghcS5ah4uQuJUlS7WdcTEoWoe6ELiTJUvsyFRAmq3qzrCYkC1L/AhcT0GljeQmJq1W/W\n9YTExNpY2EJiWo0sayExpSY263pCYkLtLGghMZ2GlrOQmEozm3U9ITGRthaykJhGY8tYSEyh\nqc26npCYQHsLWEjk1+DyFRK5NbdZ1xMSmbW5cIVEXo0uWyGRU5ObdT0hkVG7C1ZI5NPwchUS\nuTS7WdcTEpm0vVCFRB6NL1MhkUPTm3U9IZFB+wtUSIxvBstTSIyt+c26npAY2TwWppAY10yW\npZAY0yw263pCYkTzWZBCYjwzWo5CYiyz2azrCYmRzGshColxzGwZCokxzGqzrickRjC/BSgk\n4s1w+QmJaLPbrOsJiWDzXHhCItZMl52QiDTLzbqekAg03wUnJOLMeLkJiTgzXm5CIsycF5uQ\nCDPnxSYkosx6qQmJKLNeakIiyLwXmpAIMu+FJiRizHyZCYkYM19mQiLE3BeZkAgx90UmJCLM\nfokJiQizX2JCIoAFJiQCWGBCYjjLS0gEsLyExHAWl5AIYHEJieEsraOQGM7SOgqJwSysnpAY\nyMLqCYlhLKszITGMZXUmJAaxqC6ExCAW1YWQGMKSeiEkhrCkXgiJASyo/4TEABbUfzlD2j+k\nbnM8Pi5Stx5pCLKynF5lDOnQpZPHTf9nWo4yBHlZTq8yhrROp9ehdZceDsfD+Xb8EGRlMb3J\nGFJ3vmNKh/P/dWMMQVYW05uMIaX09ucPv/3aEqqBpXRlglek/s+DV6T6WUpXJthHWh9ebscP\nQUYW0jVH7biThXTNeSTuYxm948oG7mMZvSMk7mIRvSck7mIRvTdVSM4j1c0S+qCckNK1iCEY\nkSX0gU077mABfSQk7mABfSQk/sqm9yeyhvS8WZ33gFbr57GGYFR2YL+S8xKhxdXRBJcI1UZD\n38p60Wr3tDvf2m87F61WREM/y/o2it3r7Z23UdRBQ7+U/Y19n/0lbAgCaegvvCJxS0N/lncf\nabs/37KPVC4N3Sfn4e/l1VG7xWGUIRhAQwPkPY+0Pp9H6lYb55GK4gLHwVzZMHMSiiGk+dJQ\nICHNkoaiCWluNDQKIc2IhsYjpHnQ0MiE1DwN5SCklmkoGyE1S0M5CalV5jArIbXKHGYlpEaZ\nwryE1ChTmJeQ2mQGMxNSm8xgZkJqkgnMTUhNMoG5CalF5i87IbXI/GUnpAaZvvyE1CDTl5+Q\n2mP2JiCk9pi9CQipOSZvCkJqjsmbgpBaY+4mIaTWmLtJCKkxpm4aQmqMqZuGkNpi5iYipLaY\nuYkIqSkmbipCaoqJm4qQWmLeJiOklpi3yQipIaZtOkJqiGmbjpDaYdYmJKR2mLUJCakZJm1K\nQmqGSZuSkFphziYlpEaYsmkJqRGmbFpCaoMZm5iQ2mDGJiakJpiwqQmpCSZsakJqgfmanJBa\nYL4mJ6QGmK7pCakBpmt6Qqqf2SqAkOpntgogpOqZrBIIqXomqwRCqp25KoKQameuiiCkypmq\nMgipcqaqDEKqm5kqhJDqZqYKIaSqmahSCKlqJqoUQqqZeSqGkGpmnoohpIqZpnIIqWKmqRxC\nqpdZKoiQ6mWWCiKkapmkkgipWiapJEKqlTkqipAqZYrKIqRKmaKyCKlOZqgwQqqTGSqMkKpk\ngkojpCqZoNIIqUbmpzhCqpH5KY6QKmR6yiOkCpme8gwOabtKpy+s9kHP57MheM/sFGhoSMuU\n+pBSF1qSVeU7ZqdAA0N6TMtDH9Jjegh7SkeryrdMTokGhtSlw7EP6fJHGOvKN0xOiQaGdN6s\nE1JO5qZIA0NavLwi7dIi7CkdrSzfMTdFitlH2nbp8ec7Htbd6c/NIqXlU/izmgtTU6ahR+1W\n6WL58/323Sm5Q/eb77e2fMnUlCnkPFJa/fAKc/aQVofTHw/7U1MPaR38rGbCzBQq45UN6bQ/\ndfnjtJWXujGGaJ+ZKVTWkI798fKrv4QP0TwTU6qAw99n3bevMGcPaXc8bvo/+lekb3eSrC9f\nMDGlCgpp/4vzSLvUrXfHVXcqabtI2+BnNQvmpVgDQtqma784j7Tt3r59E/2sZsG8FGvIK9Li\nuqPn39z16eF8n9Xmh0tcrTCfMi3litpHimWN+ZRpKZc39tXDrBQsKqTn1dBn8uMQs2dWCjY0\npPXrXtIfH8R5pL8yKSUbGNJbR98ezv7kQW4GfncM8O/Pqn0mpWSD39j3dFym/X6ZfnXU7p4h\nuDAnRQs4arc5vRrtfnP5931DcGFOihYQ0rZ/L5J3yI7MlJRtYEir06bdPi2Oz78K6XlzefvS\nav3DhqC15iMzUriBIW37gM4fyfXzpwgdrq+E8Ma+vzEjhRt6+HvT/+0hff8+vYt16p7Ol34f\n99vOG/v+xISULuOVDd3lHRRnO2/s+xMTUrqh+0i/eCV6vd/vL9Kz3rxnPoqX8aJVr0h3Mx/F\nC/hcu9867SNtL2+fsI/0N6ajfANDOqyWv7+kYXn9/qVvA7TmvGM6yjd40+4vl8c9r8/nkbrV\nxnmkPzAbFcga0l1DYDYq4I19xTMZNRBS8UxGDYRUOnNRBSGVzlxUQUiFMxV1EFLhTEUdhFQ2\nM1EJIZXNTFRicEj9Lxo7Hlc/fAbxoCFmzETUYmhIy8tFDakLLcn688JE1GJgSC+/jPn0/z+/\n1fzOIebMPFRj8OfaHS7vSXKt3RjMQzUC3tgnpLGYhnoEvLGvb2j3m180dt8QM2Ya6hGzj7Tt\n+g+JjGMN6pmFigw9arf61efUDRpitsxCRULOI6XVU9DT+XSImTIJNXFlQ7FMQk2GfvhJ2BP5\ncoi5MgdVGXr4e/nHXzD29yHmyhxUZfDh75R++tUSd7ASmYLKDN1H2m9OLS02wZt41iJTUJmA\ngw37dZeCN/GsRWagMjFH7R59rl0ov426OhGvSOetu9AzSfNej2RUoZB9pG4d+76+WYckoyoF\nHLV7cNQujowqNfg8UvDFQbdDzImMquXKhnLIqGIDQrq8qc9vowgio6oJqQwyqpyrv4swu39w\nc4RUAC9H9Qv48JOz7tvfUj5kiObJqAVBIe3tI91JRm0YENI2XfMpQveQUSuGvCItrjsKvbxh\nJquXjNoRtY8UaxYrmIxa4qjdRGTUFidkJyGj1ghpCq3/+2bIpl1+Xo4aJKTcZNSkoSE9Lo7H\n/SL46HfDIcmoUQND2vYrRtfvIjmP9AsyatbAkJbp6fy7kZ5ifx1Fm+ubjBoWcEJ2l9bRK0mL\na5yMmhYQ0ipthfQTGTVu8Kbdbpu6o02778moecMPNqS06dcUH1n8JRnNwODD312/h3SM/aDV\ntkJq6h/DF5yQHZmXo3kQ0qhkNBeDQ3pa+mXMX5HRfAwNafly7XfoQbs2QpLRnAwM6TF1/eG6\nbZceo57RxyEqJaN5GRjSIu3O/7/z4SfvyGhuoj6zwZUNV2Q0P2GvSD4g8j8ZzZF9pGg1P3fu\n5qhdLC9HMzX8PNLKeaRXMpotVzbEkdGMCSmKjGYtZtPuIfRNFDWGJKOZizrYsIp6QrdDVEBG\nszcwpLXD3zLiODikziVCMuLoEqHBKnqqjGjwpt3/V6TQnaRq1k4vR1wMPdiwOe8jPXezvLJB\nRvw3eNPunQmfVX4y4o2Q7iQjrrmy4S4y4j0h3UFGfCSkP5MRt4T0RzLiM0L6m3KfGZMS0l94\nOeILQvo9GfElIf2WjPjG4JC2q/Nv7dsHPZ/PhiiBjPhWyBv7Tl/rQksqba2VET8Y/Ll2y0O/\nlj2mh7CndCwtJBnxo8Fv7Dtc1rN2348kI34h4I19TYckI35l8Gd/X16RWn2reTFPhMLF7CM1\n+uEnXo74raFH7Vb3fPb3jytoESuwjPi9kPNIf/3s7xpCkhF/kfHKhj+8m3bylVhG/E3GkJ67\nWkKSEX+V81q7wyotzxdAlL1pJyP+Lu7DT35z16eUno5lhyQj7pE3pON+mVaHgkOSEfeJ2bR7\nXv76g1Y3qduWGpKMuFfQPtLh9xet7hY/v3xNs0LLiLtFHWz4yw/zhyJD8nLEAEEhPaZu8FP5\nYYhxyYhBwg42bMKe0jF/SDJioKCQFn+9ZrWkE7IyYrCpPvzkduUd5dP473om8GcDQ1qtw57J\nV0OMS0aECHiH7Ahyrd0yIkjAO2RHkGf9lhFhBoZ0WC2ff3/P583lfYCr9Q93yrKGy4g4Ga+1\nOyyuvvv7d9RmWMe9HBEpY0jr1D1dfgf6ftulb49SjL6Sy4hYGQ9/d2n3env3/ZUQI6/mMiLa\ngJD+ujqm3x/uG3VFlxHxMoZUxiuSjBhDxpBO+0jby0ftT7ePJCPGkTGky2+u+H9x3rfnn0Za\n3WXEWHKGdHxen88jdavNFOeRZMR4BoU02nWmY6zyMmJEQoIAWTft/jxE2Q8Jr4QEAYQEAeYS\nko4YlZAgwFSf2ZB7CCExKiFBgJmEpCPGJSQIICQIMI+QdMTIhAQBhAQBZhGSjhibkCCAkCCA\nkCDAHELSEaMTEgQQEgSYQUg6YnxCggBCggDth6QjMhASBBASBGg+JB2Rg5AggJAggJAgQOsh\n6YgshAQBhAQBGg9JR+QhJAggJAjQdkg6IhMhQQAhQQAhQYCmQ9IRuQgJAggJArQcko7IRkgQ\nQEgQoOGQdEQ+QoIAQoIAQoIA7YakIzISEgQQEgRoNiQdkZOQIICQIECrIemIrIQEAYQEAYQE\nARoNSUfkJSQIICQIICQI0GZIOiIzIUEAIUEAIUGAJkPSEbkJCQIICQIICQK0GJKOyE5IEEBI\nEKDBkHREfkKCAEKCAEKCAO2FpCMmICQIICQIICQI0FxIOmIKQoIAQoIAOUM6PKS03L48yLeP\nIiQqkzGkQ5d6q8uDjBSSjphExpDW6fFU02O3PD+IkGhJxpC6yx333WIvJBqTMaT/7RyWSyHR\nmIwhLdLh/63lWCHpiGlkDOkxPbzc2qelkGhKzsPf69d6tklINCXrCdnd6v+t/cMoIemIibR1\nZYOQmIiQIICQIMBUIY1ysEFHTKWckNK1Ox906LOCOzW1aSckpiIkCNBSSDpiMllDet6sLm9J\nWj+PMYSQmEzON/Ytro4mLEcYQkhMJusb+7qn3fnWftuldfwQQmIyWd/Yt3u9vUtd+BA6YjoT\nvLHv9i8xQwiJ6XhFggB595G2+/OtcfaRhMR0ch7+Xl4dtVscvvvOe4bQERPKex5pfT6P1K02\nI5xHEhITaufKBiExISFBgGZC0hFTKnOVLfNZwZfKXGXLfFbwpTJX2b8PoSMmJSQIICQIICQI\n0EhIOmJaQoIAQoIAQoIAbYSkIyYmJAggJAggJAjQREg6YmpCggBCggBCggAthKQjJickCCAk\nCNBASDpiekKCAEKCAEKCAPWHpCMKICQIICQIICQIUH1IOqIEQoIAQoIAQoIAtYekI4ogJAgg\nJAggJAhQeUg6ogxCggBCggB1h6QjCiEkCCAkCCAkCFB1SDqiFEKCAEKCAEKCADWHpCOKISQI\nICQIICQIUHFIOqIcQoIAQoIAQoIA9YakIwoiJAggJAhQbUg6oiRCggBCggBCggC1hqQjiiIk\nCCAkCCAkCFBpSDqiLEKCAEKCAEKCAHWGpCMKIyQIICQIICQIUGVIOqI0QoIAQoIAQoIANYak\nI4ojJAggJAhQYUg6ojxCggBCggBCggBZQ3rerFJvtX6+fwgdUaCMIR0W6c3y7iGERIEyhrRO\n3dPufGu/7dL63iGERIEyhtSl3evtXeruHUJIFChjSCl99Ze/DKEjSlTdK5KQKFHefaTt/nxr\nyD6SkChRzsPfy6ujdovDnUMIiRLlPY+0Pp9H6labu88j6Ygi1XZlg5AokpAggJAgwFQh3Xke\nSUeUqZyQ0rVRx4ZwtW3aQZGEBAGEBAHqe2MfFKi+N/ZBgep7Yx8UqLq3UUCJqntjH5TIKxIE\nqO6NfVCi6t7YByWq7Y19UCRXNkAAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUGAQkOCytyx\nlseHU8XYxjd+6PhCMr7xS3uwisY2vvGFZHzjlza+kIxv/NIerKKxjW98IRnf+KWNLyTjG7+0\nB6tobOMbX0jGN35p4wvJ+MYv7cEqGtv4xm8mJGiGkCCAkCCAkCCAkCCAkCCAkCCAkCCAkCCA\nkCCAkCCAkCCAkCCAkCCAkCCAkCBA9pDWXerWh+++kHn8x8W04588Z1wKN+PvHlJ62E82/iHz\n8j8t8PezHTR+7pCW5w/7X3zzhczjr89f6HItyc/+uYcu31K4GX877b9/313Gz1fy7v3vmoha\n/zKH9Jy63XHXpecvv5B5/F16OPQ/pB4mGr+3uufXiESN352+cFil9UTjP5xHXuea/2M/+PVs\nh61/mUNap+3pz6e0+fILmcdfXSYg16r82T/36a7fxxM0/tN5RT6kbqLxU975P/3IXL4bK2z9\nyxzSKvWv4bu0+vILmcd/kWtBfjL+/sOizTv+Q9rlGvvT8V+2anOFfDz93Hg322HrX+aQbn4A\nZf6J9MVwh7ScbPxl2ucL6Wb8RTpuuvPm7TTjb1427TJtkRx3HxZ+2PonpN7j+QV+kvE36Snf\nhs1n87867+xPNf7xsT/a0D1mGv/D4EIKG/9s32Xasrwd/7xRMWlI/cGGh1yvCJ/9IOnlekH6\nMLiQwsbvHbpMG3afbVr1B54nDanfR9rnOv9wM/5jv2l3CjnjS1ITIXUfn/fNFzKP31tmO4t1\nM/7DeZsyX0g3//7MP8huxl+kfvfskO9E4od/a9j6N8lRu/3Ho3b7vEft3g23XyzznQ38OP6Q\nX0gfMX7uw/834+c+/P1xrLD1L3NIm/NP4O3b+b+bL2Qe/3Q723bdJ+PnDumL+d/nmoSb8S+v\nCNnOY/XezXXY+jf3KxuyrUJfjH824ZUNp72jQ7+P8jTR+OvUX+e2zvWDtNfElQ2nbeLeeeW9\n/IOuvjDF+A95XxFu//3vb+UffzPt/L9c65bzp9n/2Y5d/3KHdLnY9zJ0+vCFKcbPvGl1++9/\nf2uC8bfLKef/5errbOMfP4YUtf7lDgmaJCQIICQIICQIICQIICQIICQIICQIICQIICQIICQI\nICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQI\nICQIICQIICQIICQIIKSMPv/1gAN/X9/57tu7Hmg7aGCuCSmj0UJapHseaGHhxzGXGX2+pgf8\nBtn7HiLjr65tn7nMSEjtMpcZXa+521V6+W3al52cZUrLyz7L4yJ1j+/utH79vdun/7a4/LfX\nO5z++8vmYkqHtDj/x0U6fPI4h0VaXQ38upH54Ru5h5Ayugppc9lZWr989fHy1351Xp1vLa/u\ntHn9wvL1v73d4Tqk0zfsT/9x33/L7eOs+vHeBv4f0sdv5B5CyujqWENKT8fj08vN47FLu/6v\np9eTbVoejodl2r7dqdsdd93l+19vvt3hJaHLAz2lzbGvdPvZ45y+cDPwJwNyDyFldHPQ7nV9\nTq/r8arfKjse+o2w/9/T/6dt/4XVy83l9R3ehXQ8b9v1h+M+eZzn62fy/4/bb+QeQsro3d79\nfrtZvq7P69OG1253+Z4Ptb3ceuvl5g7XIT2ctu32rxtunzzOh4G/OibPH5m+jK5X1uXVVt7p\nj013+ku3/3VI13e4Dun5tG237l97vgzpw8BCimH6MrpaWR/S4nG7v1qfj9v14v8uz2d3+hjS\nuzu8hXTsFv3/vn6cm4EVFMIsZvRx7+hdSC+3Vh/3+i/7Ntv08LaPtLq+w4eQ1unxfMDhk8f5\nfOCbb+QeQsroXUjPx93brsricixt8XJk7vh4HcvlUN323VG7tztcQtof3xo5Hz345HFuB95/\n9o3cQ0gZXYW0ftkxeb589en1by/7MP3ez/87nb9yXs/fziM9vbv74nSH/w+/eDkldPs4Hwe+\n3OvmG7mHkDK63h15OAXxfN5Ke7uy4XJ8+vG0gj/sr++0+n85w/Gxe3dlw/PLgz4v3kJ6+r+p\ndvs4Hwa+3OvmG7mHkErnYEAVLKXSCakKllLphFQFS6l0QqqCpQQBhAQBhAQBhAQBhAQBhAQB\nhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQBhAQB\nhAQBhAQBhAQB/gGETAFtry2GeAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method that is similar to CART is called **Random Forests**. This method was designed to improve the prediction accuracy of CART and works by building a large number of CART trees. Unfortunately, this makes the method less interpretable than CART, so often you need to decide if you value the interpretability or the increase in accuracy more.\n",
    "\n",
    "To make a prediction for a new observation, each tree in the forest votes on the outcome and we pick the outcome that receives\n",
    "the majority of the votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install RandomForest package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"randomForest\")\n",
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does random forests build many CART trees? We can't just run CART multiple times because it would create the same tree every time. To prevent this, random forests only allows each tree to split on a random subset of the available independent variables, and each tree is built from what we call a bagged or bootstrapped sample of the data. This just means that the data used as the training data for each tree is selected randomly with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in randomForest.default(m, y, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n"
     ]
    }
   ],
   "source": [
    "# Build random forest model\n",
    "StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, \n",
    "                             data = Train, ntree=200, nodesize=25 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like CART, random forests has some parameter values that need to be selected. The first is the minimum number of observations in a subset, or the minbucket parameter from CART. When we create a random forest in R, this will be called nodesize. A smaller value of nodesize, which leads to bigger trees, may take longer in R. Random forests is much more computationally intensive than CART.\n",
    "\n",
    "The second parameter is the number of trees to build, which is called ntree in R. This should not be set too small, but the larger it is the longer it will take. A couple hundred trees is typically plenty. A nice thing about random forests is that it's not as sensitive to the parameter values as CART is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The RandomForest function does not have a method argument.** So when we want to do a classification problem, we need to make sure outcome is a factor. Let's convert the variable Reverse to a factor variable in both our training and our testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert outcome to factor\n",
    "Train$Reverse = as.factor(Train$Reverse)\n",
    "Test$Reverse = as.factor(Test$Reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t396 obs. of  9 variables:\n",
      " $ Docket    : Factor w/ 566 levels \"00-1011\",\"00-1045\",..: 69 97 242 334 436 505 508 527 155 426 ...\n",
      " $ Term      : int  1994 1995 1996 1997 1999 1999 2000 2000 1994 1999 ...\n",
      " $ Circuit   : Factor w/ 13 levels \"10th\",\"11th\",..: 11 9 13 12 2 4 8 11 9 5 ...\n",
      " $ Issue     : Factor w/ 11 levels \"Attorneys\",\"CivilRights\",..: 5 9 5 5 3 5 5 4 5 6 ...\n",
      " $ Petitioner: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 2 2 2 3 3 ...\n",
      " $ Respondent: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ LowerCourt: Factor w/ 2 levels \"conser\",\"liberal\": 2 1 1 1 1 1 1 2 2 2 ...\n",
      " $ Unconst   : int  0 0 0 0 0 0 1 1 0 0 ...\n",
      " $ Reverse   : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t170 obs. of  9 variables:\n",
      " $ Docket    : Factor w/ 566 levels \"00-1011\",\"00-1045\",..: 63 70 145 181 289 366 71 110 169 190 ...\n",
      " $ Term      : int  1994 1994 1994 1995 1997 1998 1994 1995 1996 1996 ...\n",
      " $ Circuit   : Factor w/ 13 levels \"10th\",\"11th\",..: 4 7 3 11 11 7 1 1 4 12 ...\n",
      " $ Issue     : Factor w/ 11 levels \"Attorneys\",\"CivilRights\",..: 5 5 5 5 5 9 8 5 8 9 ...\n",
      " $ Petitioner: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 8 9 9 9 9 ...\n",
      " $ Respondent: Factor w/ 12 levels \"AMERICAN.INDIAN\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ LowerCourt: Factor w/ 2 levels \"conser\",\"liberal\": 2 2 1 1 1 2 2 2 2 2 ...\n",
      " $ Unconst   : int  0 0 0 1 1 1 0 0 1 0 ...\n",
      " $ Reverse   : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 2 1 1 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "str(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again\n",
    "StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, \n",
    "                             data = Train, ntree=200, nodesize=25 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   PredictForest\n",
       "     0  1\n",
       "  0 43 34\n",
       "  1 17 76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PredictForest = predict(StevensForest, newdata = Test)\n",
    "zf = table(Test$Reverse, PredictForest)\n",
    "zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are labeled with the actual outcome, and the columns are labeled with the predicted outcome.\n",
    "\n",
    "                  Predict 0       Predict 1\n",
    "    Actual 0    True Negative   False Positive\n",
    "    Actual 1    False Negative  True Positive\n",
    "\n",
    "    z = [1][3]\n",
    "        [2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy RandomForest:  0.7'</span>"
      ],
      "text/latex": [
       "'Accuracy RandomForest:  0.7'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy RandomForest:  0.7'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy RandomForest:  0.7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy                        # (TN+TP)/(TN+FN+TP+FP)\n",
    "accur <- (zf[1]+zf[4])/(zf[1]+zf[2]+zf[3]+zf[4])  # Another way: sum(diag(zf))/sum(zf)\n",
    "paste(\"Accuracy RandomForest: \", round(accur,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the accuracy of our Random Forest model is about 69\\\\%. Recall that our logistic regression model had an accuracy of 66.5% and our CART model had an accuracy of 65.9%. So our random forest model improved our accuracy a little bit over CART.\n",
    "\n",
    "Keep in mind that Random Forests has a random component. You may have gotten a different confusion matrix than me because there's a random component to this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CART, the value of minbucket can affect the model's out-of-sample accuracy. As we discussed earlier in the lecture, if minbucket is too small, over-fitting might occur. But if minbucket is too large, the model might be too simple. So how should we set this parameter value?\n",
    "\n",
    "We could select the value that gives the best testing set accuracy, but this isn't right. The idea of the testing set is to measure model performance on data the model has never seen before. By picking the value of minbucket to get the best test set performance, the testing set was implicitly used to generate the model. Instead, we'll use a method called K-fold Cross Validation, which is one way to properly select the parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "\n",
      "Attaching package: 'ggplot2'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:randomForest':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install cross-validation packages\n",
    "#install.packages(\"caret\")\n",
    "library(caret)\n",
    "#install.packages(\"e1071\")\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split the training set into k equally sized subsets, or folds. In this example, k equals 5. Then we select k - 1, or four folds, to estimate the model, and compute predictions on the remaining one fold, which is often referred to as the validation set. We build a model and make predictions for each possible parameter value we're considering. Then we repeat this for each of the other folds, or pieces of our training set.\n",
    "\n",
    "We'll use a parameter called cp (complexity parameter), it's like Adjusted R-squared for linear regression, and AIC for logistic regression, in that it measures the trade-off between model complexity and accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation experiment\n",
    "numFolds = trainControl( method = \"cv\", number = 10 ) # Method cross-validation, number of folds = 10\n",
    "cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))       # Possible values for our cp: from 0.01 until 0.5, pass 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "396 samples\n",
       "  6 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 357, 356, 357, 356, 356, 356, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    Accuracy   Kappa     \n",
       "  0.01  0.6487821  0.27459735\n",
       "  0.02  0.6385897  0.26041057\n",
       "  0.03  0.6335256  0.25398134\n",
       "  0.04  0.6385897  0.27124007\n",
       "  0.05  0.6435897  0.28289264\n",
       "  0.06  0.6435897  0.28289264\n",
       "  0.07  0.6435897  0.28289264\n",
       "  0.08  0.6435897  0.28289264\n",
       "  0.09  0.6435897  0.28289264\n",
       "  0.10  0.6435897  0.28289264\n",
       "  0.11  0.6435897  0.28289264\n",
       "  0.12  0.6435897  0.28289264\n",
       "  0.13  0.6435897  0.28289264\n",
       "  0.14  0.6435897  0.28289264\n",
       "  0.15  0.6435897  0.28289264\n",
       "  0.16  0.6435897  0.28289264\n",
       "  0.17  0.6435897  0.28289264\n",
       "  0.18  0.6435897  0.28289264\n",
       "  0.19  0.6435897  0.28289264\n",
       "  0.20  0.6085897  0.19402926\n",
       "  0.21  0.5835897  0.12602256\n",
       "  0.22  0.5530769  0.04021599\n",
       "  0.23  0.5453846  0.01729109\n",
       "  0.24  0.5453846  0.01729109\n",
       "  0.25  0.5453846  0.00000000\n",
       "  0.26  0.5453846  0.00000000\n",
       "  0.27  0.5453846  0.00000000\n",
       "  0.28  0.5453846  0.00000000\n",
       "  0.29  0.5453846  0.00000000\n",
       "  0.30  0.5453846  0.00000000\n",
       "  0.31  0.5453846  0.00000000\n",
       "  0.32  0.5453846  0.00000000\n",
       "  0.33  0.5453846  0.00000000\n",
       "  0.34  0.5453846  0.00000000\n",
       "  0.35  0.5453846  0.00000000\n",
       "  0.36  0.5453846  0.00000000\n",
       "  0.37  0.5453846  0.00000000\n",
       "  0.38  0.5453846  0.00000000\n",
       "  0.39  0.5453846  0.00000000\n",
       "  0.40  0.5453846  0.00000000\n",
       "  0.41  0.5453846  0.00000000\n",
       "  0.42  0.5453846  0.00000000\n",
       "  0.43  0.5453846  0.00000000\n",
       "  0.44  0.5453846  0.00000000\n",
       "  0.45  0.5453846  0.00000000\n",
       "  0.46  0.5453846  0.00000000\n",
       "  0.47  0.5453846  0.00000000\n",
       "  0.48  0.5453846  0.00000000\n",
       "  0.49  0.5453846  0.00000000\n",
       "  0.50  0.5453846  0.00000000\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform the cross validation\n",
    "train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, \n",
    "      data = Train, method = \"rpart\", trControl = numFolds, tuneGrid = cpGrid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new CART model\n",
    "StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, \n",
    "                      data = Train, method=\"class\", cp = 0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   PredictCV\n",
       "     0  1\n",
       "  0 59 18\n",
       "  1 29 64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "PredictCV = predict(StevensTreeCV, newdata = Test, type = \"class\")\n",
    "zcv = table(Test$Reverse, PredictCV)\n",
    "zcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are labeled with the actual outcome, and the columns are labeled with the predicted outcome.\n",
    "\n",
    "                  Predict 0       Predict 1\n",
    "    Actual 0    True Negative   False Positive\n",
    "    Actual 1    False Negative  True Positive\n",
    "\n",
    "    z = [1][3]\n",
    "        [2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Accuracy Cross-Validation:  0.7235'</span>"
      ],
      "text/latex": [
       "'Accuracy Cross-Validation:  0.7235'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Accuracy Cross-Validation:  0.7235'</span>"
      ],
      "text/plain": [
       "[1] \"Accuracy Cross-Validation:  0.7235\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy                                    # (TN+TP)/(TN+FN+TP+FP)\n",
    "accur <- (zcv[1]+zcv[4])/(zcv[1]+zcv[2]+zcv[3]+zcv[4])  # Another way: sum(diag(zf))/sum(zf)\n",
    "paste(\"Accuracy Cross-Validation: \", round(accur,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the accuracy of this model is 0.724. Remember that the accuracy of our previous CART model was 0.659. Cross validation helps us make sure we're selecting a good parameter value, and often this will significantly increase the accuracy. If we had already happened to select a good parameter value, then the accuracy might not of increased that much. But by using cross validation, we can be sure that we're selecting a smart parameter value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Martin and his colleagues used 628 previous Supreme Court cases between 1994 and 2001 to build their model. They made predictions for the 68 cases that would be decided in October, 2002, before the term started.\n",
    "\n",
    "artin and his colleagues also recruited 83 legal experts, 71 academics, and 12 attorneys. 38 had previously clerked for a Supreme Court Justice, 33 were chaired professors, and five were current or former law school deans. So this was really a dream team of experts. Additionally, the experts were only asked to predict within their area of expertise. So not all experts predicted all cases, but there was more than one expert making predictions for each case.\n",
    "\n",
    "For the 68 cases in October 2002, the predictions were made, and at the end of the month the results were computed.\n",
    "\n",
    "For predicting the overall decision that was made by the Supreme Court, the models had an accuracy of 75%, while the experts only had an accuracy of 59%. So the models had a significant edge over the experts in predicting the overall case outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
