{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. In Chapter 4, we used logistic regression to \n",
    "**predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 default student      balance        income\n",
       "0           1      No      No   729.526495  44361.625074\n",
       "1           2      No     Yes   817.180407  12106.134700\n",
       "2           3      No      No  1073.549164  31767.138947\n",
       "3           4      No      No   529.250605  35704.493935\n",
       "4           5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Default.csv'\n",
    "default = pd.read_csv(file)\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  10000 non-null  int64  \n",
      " 1   default     10000 non-null  object \n",
      " 2   student     10000 non-null  object \n",
      " 3   balance     10000 non-null  float64\n",
      " 4   income      10000 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "default.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  default  student      balance        income\n",
       "0           1        0        0   729.526495  44361.625074\n",
       "1           2        0        1   817.180407  12106.134700\n",
       "2           3        0        0  1073.549164  31767.138947\n",
       "3           4        0        0   529.250605  35704.493935\n",
       "4           5        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_dict = {'Yes': 1, 'No': 0}\n",
    "default['default'] = default['default'].map(encoding_dict)\n",
    "default['student'] = default['student'].map(encoding_dict)\n",
    "\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  10000 non-null  int64  \n",
      " 1   default     10000 non-null  int64  \n",
      " 2   student     10000 non-null  int64  \n",
      " 3   balance     10000 non-null  float64\n",
      " 4   income      10000 non-null  float64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 390.8 KB\n"
     ]
    }
   ],
   "source": [
    "default.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Fit a logistic regression model that uses income and balance to predict default.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[2.77251347 0.26996715]]\n",
      "Intercept: [-6.2137023]\n",
      "Training Accuracy: 0.974875\n",
      "Testing Accuracy: 0.9695\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1921   10]\n",
      " [  51   18]]\n",
      "\n",
      "True Negative: 1921\n",
      "False Positive: 10\n",
      "False Negative: 51\n",
      "True Positive: 18\n",
      "\n",
      "Overall Fraction of Correct Predictions: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the 'default', 'balance', and 'income' columns\n",
    "default.dropna(subset=['default', 'balance', 'income'], inplace=True)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = default[['balance', 'income']]\n",
    "y = default['default']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Coefficients:\", log_reg.coef_)\n",
    "print(\"Intercept:\", log_reg.intercept_)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = log_reg.score(X_train_scaled, y_train)\n",
    "test_accuracy = log_reg.score(X_test_scaled, y_test)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Select elements\n",
    "tn = conf_matrix[0][0]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "\n",
    "# Overall fraction of correct predictions\n",
    "correct_predictions = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"\\nTrue Negative:\", tn)\n",
    "print(\"False Positive:\", fp)\n",
    "print(\"False Negative:\", fn)\n",
    "print(\"True Positive:\", tp)\n",
    "print(\"\\nOverall Fraction of Correct Predictions:\", correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:**\n",
    "\n",
    "**i. Split the sample set into a training set and a validation set.**\n",
    "\n",
    "**ii. Fit a multiple logistic regression model using only the training observations.**\n",
    "\n",
    "**iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of\n",
    "default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.**\n",
    "\n",
    "**iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error: 0.026249999999999996\n"
     ]
    }
   ],
   "source": [
    "# Step i: Split the sample set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Step ii: Fit a multiple logistic regression model using only the training observations\n",
    "log_reg_val = LogisticRegression()\n",
    "log_reg_val.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step iii: Obtain predictions for the validation set\n",
    "y_val_pred = log_reg_val.predict(X_val_scaled)\n",
    "\n",
    "# Step iv: Compute the validation set error\n",
    "validation_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Set Error:\", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error 1: 0.01953125\n",
      "Validation Set Error 2: 0.02734375\n",
      "Validation Set Error 3: 0.034146341463414664\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = 3\n",
    "\n",
    "# Define lists to store validation set errors\n",
    "validation_errors = []\n",
    "\n",
    "# Repeat the process three times\n",
    "for i in range(num_iterations):\n",
    "    # Step i: Split the sample set into a training set and a validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Step ii: Fit a multiple logistic regression model using only the training observations\n",
    "    log_reg_val = LogisticRegression()\n",
    "    log_reg_val.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Step iii: Obtain predictions for the validation set\n",
    "    y_val_pred = log_reg_val.predict(X_val_scaled)\n",
    "\n",
    "    # Step iv: Compute the validation set error\n",
    "    validation_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "    validation_errors.append(validation_error)\n",
    "\n",
    "# Print the validation errors\n",
    "for i, error in enumerate(validation_errors):\n",
    "    print(f\"Validation Set Error {i+1}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random_state` parameter in the `train_test_split` function ensures reproducibility by controlling the randomization applied during the data splitting process. However, even with the same random seed, different splits may occur because of the inherent randomness in the process, especially if the dataset is small.\n",
    "\n",
    "In this case, each iteration of the loop performs a new split of the data into training and validation sets. While the `random_state` is set to 42, the randomization process for splitting the data can still lead to slightly different splits in each iteration. This randomness can result in slightly different validation set errors across the iterations, even with the same random seed.\n",
    "\n",
    "Overall, the `random_state` parameter helps ensure that the same randomization process is applied consistently across different runs of the code, allowing for reproducibility, but it does not guarantee identical splits or results in every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error (with student dummy variable): 0.030000000000000027\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the sample set into a training set and a validation set\n",
    "X = default[['balance', 'income', 'student']]\n",
    "y = default['default']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit a logistic regression model using income, balance, and the dummy variable for student on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "log_reg_student = LogisticRegression()\n",
    "log_reg_student.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions for the validation set\n",
    "y_val_pred_student = log_reg_student.predict(X_val_scaled)\n",
    "\n",
    "# Compute the validation set error\n",
    "validation_error_student = 1 - accuracy_score(y_val, y_val_pred_student)\n",
    "print(\"Validation Set Error (with student dummy variable):\", validation_error_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. We continue to consider the use of a logistic regression model \n",
    "**to predict the probability of default using income and balance on the Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the sm.GLM() function. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors from bootstrap method: [[1.30104261e-18 2.16840434e-18 1.60936260e-20]]\n",
      "Standard errors from standard formula:\n",
      " income     0.000009\n",
      "balance    0.000268\n",
      "student    0.272745\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file = 'data/Default.csv'\n",
    "default = pd.read_csv(file)\n",
    "\n",
    "# Convert 'student' column to binary dummy variable\n",
    "encoding_dict = {'Yes': 1, 'No': 0}\n",
    "default['student'] = default['student'].map(encoding_dict)\n",
    "\n",
    "# Define features (income, balance, student_dummy) and target variable (default)\n",
    "X = default[['income', 'balance', 'student']]\n",
    "y = default['default']\n",
    "\n",
    "# Convert y to numeric type\n",
    "y = y.replace({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert non-numeric columns to appropriate numeric types if necessary\n",
    "X_train['income'] = pd.to_numeric(X_train['income'])\n",
    "X_train['balance'] = pd.to_numeric(X_train['balance'])\n",
    "\n",
    "# Fit a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Compute standard errors using the standard formula\n",
    "X_train_sm = sm.add_constant(X_train)  # Add constant for intercept\n",
    "log_reg_sm = sm.GLM(y_train, X_train_sm, family=sm.families.Binomial()).fit()\n",
    "coef_sm = log_reg_sm.params[1:]  # Exclude intercept\n",
    "std_err_sm = log_reg_sm.bse[1:]  # Standard errors\n",
    "\n",
    "# Fit a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Compute standard errors using the bootstrap method\n",
    "n_iterations = 1000\n",
    "coef_bootstrap = []\n",
    "for _ in range(n_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, replace=True, random_state=42)\n",
    "    log_reg_resampled = LogisticRegression()\n",
    "    log_reg_resampled.fit(X_resampled, y_resampled)\n",
    "    coef_bootstrap.append(log_reg_resampled.coef_)\n",
    "\n",
    "# Compute standard errors using the standard formula\n",
    "X_train_sm = sm.add_constant(X_train)  # Add constant for intercept\n",
    "log_reg_sm = sm.GLM(y_train, X_train_sm, family=sm.families.Binomial()).fit()\n",
    "coef_sm = log_reg_sm.params[1:]  # Exclude intercept\n",
    "std_err_sm = log_reg_sm.bse[1:]  # Standard errors\n",
    "\n",
    "# Compute standard errors from bootstrap results\n",
    "std_err_bootstrap = np.std(coef_bootstrap, axis=0)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Standard errors from bootstrap method:\", std_err_bootstrap)\n",
    "print(\"Standard errors from standard formula:\\n\", std_err_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bootstrap Method:* The code then computes the standard errors of the coefficients using the bootstrap method. It resamples the training data with replacement, fits logistic regression models to the resampled data, and collects the coefficients. The standard errors are computed from the distribution of the coefficient estimates obtained through resampling.\n",
    "\n",
    "*Standard Formula:* Standard errors are also computed using the standard formula for logistic regression coefficients. This is achieved using the `sm.GLM` class from the statsmodels library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with\n",
    "income and balance in a multiple logistic regression model that uses both predictors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 8000\n",
      "Model:                            GLM   Df Residuals:                     7996\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -608.26\n",
      "Date:                Sun, 05 May 2024   Deviance:                       1216.5\n",
      "Time:                        16:43:18   Pearson chi2:                 6.61e+03\n",
      "No. Iterations:                     9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -11.3117      0.577    -19.614      0.000     -12.442     -10.181\n",
      "income       7.21e-06   9.46e-06      0.763      0.446   -1.13e-05    2.57e-05\n",
      "balance        0.0059      0.000     21.933      0.000       0.005       0.006\n",
      "student       -0.4881      0.273     -1.790      0.074      -1.023       0.046\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print(log_reg_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error:\n",
    "\n",
    "    income 9.46e-06\n",
    "    balance ~ 0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Write a function, boot_fn(), that takes as input the Default data set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for income and balance: [[-0.00012904  0.00049604]]\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Select subset of data based on index\n",
    "    subset_data = data.iloc[index]\n",
    "    \n",
    "    # Define features (income, balance) and target variable (default)\n",
    "    X = subset_data[['income', 'balance']]\n",
    "    y = subset_data['default']\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "\n",
    "    # Return coefficient estimates\n",
    "    return log_reg.coef_\n",
    "\n",
    "# Define an example index\n",
    "index = np.random.choice(default.index, size=len(default), replace=True)\n",
    "\n",
    "# Coefficient estimates\n",
    "coefficients = boot_fn(default, index)\n",
    "print(\"Coefficient estimates for income and balance:\", coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Following the bootstrap example in the lab, use your boot_fn() function to estimate the standard errors of the logistic regression coefficients for income and balance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error for income coefficient: 7.292084410896754e-05\n",
      "Standard error for balance coefficient: 0.002571549382287639\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Select subset of data based on index\n",
    "    subset_data = data.iloc[index]\n",
    "    \n",
    "    # Define features (income, balance) and target variable (default)\n",
    "    X = subset_data[['income', 'balance']]\n",
    "    y = subset_data['default']\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "\n",
    "    # Return coefficient estimates\n",
    "    return log_reg.coef_.flatten()  # Flatten coefficients to ensure consistent format\n",
    "\n",
    "# Initialize lists to store coefficient estimates\n",
    "coef_income = []\n",
    "coef_balance = []\n",
    "\n",
    "# Iterate through bootstrap samples\n",
    "for _ in range(n_iterations):\n",
    "    # Generate bootstrap sample index\n",
    "    index = np.random.choice(default.index, size=len(default), replace=True)\n",
    "    \n",
    "    # Call boot_fn to get coefficient estimates\n",
    "    coefficients = boot_fn(default, index)\n",
    "    \n",
    "    # Append coefficient estimates to lists\n",
    "    coef_income.append(coefficients[0])\n",
    "    coef_balance.append(coefficients[1] if len(coefficients) > 1 else np.nan)  # Handle cases where only one \n",
    "                                                                                # coefficient is returned\n",
    "\n",
    "# Calculate standard errors\n",
    "std_err_income = np.std(coef_income)\n",
    "std_err_balance = np.nanstd(coef_balance)  # Use nanstd to handle NaN values\n",
    "\n",
    "# Print standard errors\n",
    "print(\"Standard error for income coefficient:\", std_err_income)\n",
    "print(\"Standard error for balance coefficient:\", std_err_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Comment on the estimated standard errors obtained using the sm.GLM() function and using the bootstrap.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sm.GLM() function\n",
    "\n",
    "    Standard error for income coefficient: 9.46e-06\n",
    "    Standard error for balance coefficient: ~ 0.000\n",
    "\n",
    "Using the Bootstrap\n",
    "\n",
    "    Standard error for income coefficient: 7.34e-05\n",
    "    Standard error for balance coefficient: 0.0026\n",
    "    \n",
    "while the bootstrap method provides a non-parametric approach to estimate standard errors, it may result in higher variability compared to parametric methods like sm.GLM(). It's essential to consider the assumptions and limitations of both approaches when interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. In Sections 5.1.2 and 5.1.3, we saw that the cross_validate() function\n",
    "**can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just `sm.GLM()` and the `predict()` method of the fitted model within a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the Weekly data set. Recall that in the context of classification problems, the LOOCV error is given in (5.4).**\n",
    "\n",
    "**(a) Fit a logistic regression model that predicts Direction using Lag1 and Lag2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Weekly.csv'\n",
    "weekly = pd.read_csv(file)\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1089 entries, 0 to 1088\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Year       1089 non-null   int64  \n",
      " 1   Lag1       1089 non-null   float64\n",
      " 2   Lag2       1089 non-null   float64\n",
      " 3   Lag3       1089 non-null   float64\n",
      " 4   Lag4       1089 non-null   float64\n",
      " 5   Lag5       1089 non-null   float64\n",
      " 6   Volume     1089 non-null   float64\n",
      " 7   Today      1089 non-null   float64\n",
      " 8   Direction  1089 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "weekly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly['Direction'] = weekly['Direction'].map({'Down':0,'Up':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.540900\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Up   No. Observations:                 1089\n",
      "Model:                          Logit   Df Residuals:                     1086\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 05 May 2024   Pseudo R-squ.:                     inf\n",
      "Time:                        16:44:13   Log-Likelihood:                -1678.0\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2212      0.061      3.599      0.000       0.101       0.342\n",
      "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
      "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare the predictors (X) and response (y) variables\n",
    "X = weekly[['Lag1', 'Lag2']]\n",
    "y = pd.get_dummies(weekly['Direction'], drop_first=True)\n",
    "\n",
    "# Add constant to the predictors\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print summary of the logistic regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Fit a logistic regression model that predicts Direction using Lag1 and Lag2 using all but the first observation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.535727\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Up   No. Observations:                 1088\n",
      "Model:                          Logit   Df Residuals:                     1085\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 05 May 2024   Pseudo R-squ.:                     inf\n",
      "Time:                        16:44:13   Log-Likelihood:                -1670.9\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2232      0.061      3.630      0.000       0.103       0.344\n",
      "Lag1          -0.0384      0.026     -1.466      0.143      -0.090       0.013\n",
      "Lag2           0.0608      0.027      2.291      0.022       0.009       0.113\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare the predictors (X) and response (y) variables\n",
    "X = weekly[['Lag1', 'Lag2']].drop(0,axis = 0)\n",
    "y = pd.get_dummies(weekly['Direction'], drop_first=True).drop(0,axis = 0)\n",
    "\n",
    "# Add constant to the predictors\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print summary of the logistic regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Model\tLog-Likelihood\tPseudo R-squared\tCoefficient Significance (p-values)\n",
    "    A\t      -1678.0\t         inf\t          Lag1: 0.140, Lag2: 0.023\n",
    "    B\t      -1670.9\t         inf\t          Lag1: 0.143, Lag2: 0.022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models have `pseudo R-squared` values of `inf`, indicating perfect separation of the data. However, this is likely due to a small number of distinct values in the dependent variable.\n",
    "\n",
    "The coefficients for `Lag1` and `Lag2` are not statistically significant at the 0.05 significance level for both models, as their `p-values` are greater than 0.05. However, the constant term (const) is statistically significant in both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Use the model from (b) to predict the direction of the first observation. You can do this by predicting that the first observation will go up if P(Direction = \"Up\"|Lag1, Lag2) > 0.5. Was this observation correctly classified?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted - 1\n",
      "True value - 0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Weekly.csv'\n",
    "weekly = pd.read_csv(file)\n",
    "\n",
    "# Convert 'Direction' column to binary dummy variable\n",
    "encoding_dict = {'Up': 1, 'Down': 0}\n",
    "weekly['Direction'] = weekly['Direction'].map(encoding_dict)\n",
    "\n",
    "# Prepare the predictors (X) and response (y) variables\n",
    "X_train = weekly[['Lag1', 'Lag2']].iloc[1:]\n",
    "y_train = pd.get_dummies(weekly['Direction'], drop_first=True).iloc[1:]\n",
    "\n",
    "# Build regression model\n",
    "clf = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Prepare the predictors (X_test) for the single observation\n",
    "X_test = weekly[['Lag1', 'Lag2']].iloc[[0]]\n",
    "\n",
    "# Save predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Real value\n",
    "y_test = weekly['Direction'].loc[0]   \n",
    "\n",
    "print('Predicted - {}\\nTrue value - {}'.format(int(clf.predict(X_test)),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Write a for loop from i = 1 to i = n, where n is the number of observations in the data set, that performs each of the following steps:**\n",
    "\n",
    "**i. Fit a logistic regression model using all but the ith observation to predict Direction using Lag1 and Lag2.**\n",
    "\n",
    "**ii. Compute the posterior probability of the market moving up for the ith observation.**\n",
    "\n",
    "**iii. Use the posterior probability for the ith observation in order to predict whether or not the market moves up.**\n",
    "\n",
    "**iv. Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the errors\n",
    "errors = []\n",
    "\n",
    "# Iterate over each observation in the dataset\n",
    "for i in range(len(weekly)):\n",
    "    # Prepare predictors and response variables, excluding the ith observation\n",
    "    X_train = weekly[['Lag1', 'Lag2']].drop(i, axis=0)\n",
    "    y_train = pd.get_dummies(weekly['Direction'], drop_first=True).drop(i, axis=0)\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Prepare the predictors for the ith observation\n",
    "    X_test = weekly[['Lag1', 'Lag2']].iloc[[i]]\n",
    "\n",
    "    # Compute the posterior probability of the market moving up for the ith observation\n",
    "    posterior_prob = clf.predict_proba(X_test)[0, 1]\n",
    "\n",
    "    # Use the posterior probability to predict whether the market moves up\n",
    "    prediction = 1 if posterior_prob > 0.5 else 0\n",
    "\n",
    "    # Determine if an error was made in predicting the direction for the ith observation\n",
    "    true_direction = weekly['Direction'].iloc[i]\n",
    "    error = 1 if prediction != true_direction else 0\n",
    "\n",
    "    # Append the error to the list\n",
    "    errors.append(error)\n",
    "\n",
    "# Print the list of errors\n",
    "print(\"Errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Sum of '1's: 490\n",
      "Sum of '0's: 599\n",
      "Ratio of errors: 0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the errors\n",
    "errors = []\n",
    "\n",
    "# Initialize variables to store the sum of '1's and '0's\n",
    "sum_ones = 0\n",
    "sum_zeros = 0\n",
    "\n",
    "# Iterate over each observation in the dataset\n",
    "for i in range(len(weekly)):\n",
    "    # Prepare predictors and response variables, excluding the ith observation\n",
    "    X_train = weekly[['Lag1', 'Lag2']].drop(i, axis=0)\n",
    "    y_train = pd.get_dummies(weekly['Direction'], drop_first=True).drop(i, axis=0)\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Prepare the predictors for the ith observation\n",
    "    X_test = weekly[['Lag1', 'Lag2']].iloc[[i]]\n",
    "\n",
    "    # Compute the posterior probability of the market moving up for the ith observation\n",
    "    posterior_prob = clf.predict_proba(X_test)[0, 1]\n",
    "\n",
    "    # Use the posterior probability to predict whether the market moves up\n",
    "    prediction = 1 if posterior_prob > 0.5 else 0\n",
    "\n",
    "    # Determine if an error was made in predicting the direction for the ith observation\n",
    "    true_direction = weekly['Direction'].iloc[i]\n",
    "    error = 1 if prediction != true_direction else 0\n",
    "\n",
    "    # Append the error to the list\n",
    "    errors.append(error)\n",
    "\n",
    "    # Update the sum of '1's and '0's\n",
    "    if error == 1:\n",
    "        sum_ones += 1\n",
    "    else:\n",
    "        sum_zeros += 1\n",
    "\n",
    "# Calculate the ratio of errors\n",
    "ratio = sum_ones / len(weekly)\n",
    "\n",
    "# Print the list of errors\n",
    "print(\"Errors:\", errors)\n",
    "print(\"\\nSum of '1's:\", sum_ones)\n",
    "print(\"Sum of '0's:\", sum_zeros)\n",
    "print(\"Ratio of errors:\", ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Take the average of the n numbers obtained in (d)iv in order to obtain the LOOCV estimate for the test error. Comment on the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV estimate for test error: 0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "# Calculate the LOOCV estimate for the test error\n",
    "loocv_error = sum(errors) / len(errors)\n",
    "\n",
    "# Print the LOOCV estimate for the test error\n",
    "print(\"LOOCV estimate for test error:\", loocv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. We will now perform cross-validation on a simulated data set.\n",
    "**(a) Generate a simulated data set as follows:**\n",
    "\n",
    "    rng = np.random.default_rng(1)\n",
    "    x = rng.normal(size=100)\n",
    "    y = x - 2 * x**2 + rng.normal(size=100)\n",
    "    \n",
    "**In this data set, what is n and what is p? Write out the model used to generate the data in equation form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "\n",
    "x = rng.normal(size=100)\n",
    "\n",
    "y = x - 2 * x**2 + rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 100 is the number of observations.\n",
    "\n",
    "p = is the number of predictor variables (features).\n",
    "\n",
    "The model used to generate the data can be written in equation form as:\n",
    "\n",
    "    y = x - 2 * x^2 + \n",
    "\n",
    "Where:\n",
    "\n",
    "    y is the response variable.\n",
    "    x is the predictor variable.\n",
    "     is the random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Create a scatterplot of X against Y . Comment on what you find.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGDCAYAAABdtKgRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw9ElEQVR4nO3de5zcdX3v8fcnmwtmN+EWsknIVYgKIqBZqbac7kZRkUdb0Dan2B6qVclD27W2jX14oRVEPfVRxdZHl4oRPV5qG0ULcpSjgu0OppVqgiESwiVkczOBcDVMQpJN8jl/fH8/dzKZ2Z3Z/c38fjO/1/PxmMfM/G7zne8k+/38vldzdwEAgHyZlHYCAABA8xEAAACQQwQAAADkEAEAAAA5RAAAAEAOEQAAAJBDBAAAJElm5mZ2dhM+x8zs/5jZM2b2k0Z/3kSY2U1m9jdppwNoBAIAoA5mdrGZ/ZeZ/dLMnjaz/zSzV07wmm8zs7Vl275kZh+bWGobo1J663SxpNdJmu/uF1W4/nvM7H4zm1qy7c/N7GdmNnkCn1s3d3+Xu390Itcwsz4z2zXK/qvNbLOZTSvZdrqZ7TWzSyfy2cBoCACAGpnZTEnfkfSPkk6TdKakj0g6lGa6Kml2QVmnRZK2ufv+KvtvlPSspGskycxeqJDP73D3I01JYRO5++cl7ZL04ZLN/yDpDnf/XiqJQj64Ow8ePGp4SOqR9OwYx1wtabOk5yQ9IOkV0fYPSHq0ZPubou3nSDoo6aikokLBt1LSsKTD0bb/Gx07T9K3JD0haUjSn5V87nWSvinpnyXtk/TOCmn7kqSbJN0ZpaMgaVHJfpd0dvT6ZElfiT5ru6S/VrhhOCG9VfJhnqTbJT0taYukq6Pt7yg7/yNVzn9x9D3Ol/RDSX87Sp6fqhCYPSHpmej1/JL9SyTdHX3nuxQCjH8u2X+LpMck/TI67qVlefax6HWfQkG9StJeSXsk/XHJsZdFv+1zkn4h6X2SOiU9L+lY9H2LkuZV+A6Lo7RfKOn1knZLOjXtf/M82vuRegJ48GiVh6SZkp6S9GVJbyz/Ay1pRfSH/5WSTNLZcQEb7ZsXFaK/L2m/pLnRvrdJWlt2rV8VPNH7SZLWK9wlTpX0QklbJb0h2n+dQtBwRXTsCyqk/0tR4fSbkqZJ+kzp5+r4AOArkr4taUZUOD2scAdeMb0VPqsg6Z8knRQVak9Iem2t50fHfVDSk5IeknTSKMedLul3JU2P0nuLpNtK9v9Y0qeifLtYIbAoDQDeHp03TeHOe0Ol30EhADgi6XpJUxQK/APxvwOFgOB/RK9P1Ujw1ydpVw3f9z2S7lUI7q5I+987j/Z/0AQA1Mjd9ykUIC7p85KeMLPbzaw7OuSdkv7O3X/qwRZ33x6de4u773b3Y+7+dUmPSDqh/XsUr5R0hrtf7+6H3X1rlIYrS475sbvfFn3G81Wu8113v9vdDylUsb/azBaUHmBmHQpBygfd/Tl33ybpBklX1ZLQ6HoXS3q/ux909w2Sbq71/BI/Uijcv+nuB6sd5O5Pufu33P2Auz8n6eOSeqO0LFTIuw9H+bZWoWai9PwvRt/zkEIgdYGZnVzl44YlXe/uw+5+h8Id/YtL9p1rZjPd/Rl3v7fO7zsQXWODu99W57lA3QgAgDq4+2Z3f5u7z5d0nsJd/T9EuxcoVPOfwMz+yMw2mNmzZvZsdO6sOj56kaR58fnRNT4kqbvkmJ01XOdXx7h7UaGKfl7ZMbMU7pa3l2zbrtDnoRbzJD0dFcbjOV9RB8DPKfS36I/6AVQ7drqZfc7MtpvZPoVq/FOiQCZOy4GSU3aWnNthZp8ws0ejc7dFu6r9Nk/58f0QDkjqil7/rkKtwHYzK5jZq2v9vpLk7q7QfLSpnvOA8SIAAMbJ3R9UqCI+L9q0U9JZ5ceZ2SKFu/V+Sae7+ymS7ldoJpBCjcIJly97v1PSkLufUvKY4e6XjXJOJb+62zezLoXOjLvLjnlS4U50Ucm2hQrNG7V8zm5Jp5nZjCrn1+JvFNrZ36vQb+Fzoxy7SuEu/NfcfaZCE4cU8ndPlJbpJceX1nj8gaTLJV2i0O9hccm5dYlqfi6XNFvSbZK+Ee+q91pAMxAAADUys5eY2Sozmx+9XyDpLZLuiQ65WdL7zGxZNNb97Kjw71QoBJ6IzvtjjQQNkvS4pPmlw96ibaV3vT+RtM/M3m9mL4juXM8bxxDEy6KhjFMlfVTSf7v7cTUH7n5UofD6uJnNiL7DXyp0MKyW3tLzd0r6L0l/a2Ynmdn5Cp3/vlZLAs3sAkl/ptBx0BWq5RdH+VbJDIWOds+a2WmSri1Jy3ZJ6yRdZ2ZTo7vy3y4795BC347pkv53LWmskOapZvaHZnayuw8r9DM4Gu1+XNLpozQrAKkgAABq95ykX5P032a2X6Hgv1/hDlTufotC+/O/RMfeJuk0d39AoQ39xwqFwcsk/WfJdf9dodr3MTN7Mtr2BYX25GfN7LaoUP5thQ51Qwp36Tcr3LXW418UCsinJS2T9IdVjnuPQkfFrZLWRud9cZT0lnuLwt30bkm3SrrW3e8cK3FRtf0XJH3c3bdIUtSf4WpJnyzpb1HqHyS9QCFP7pFUPnTuDyW9WqGQ/5ikr2tk6OZXFJonfqHQg/8ejd9VkrZFTQnvkvS/ovQ/KOlfJW2Nfs/yJhcgFRYCbADtzsy+pNAb/a/TTkuazOzrkh5092vHPBhoY9QAAGhrZvZKMzvLzCZFM+tdrlA7A+RalmcLA4AkzJH0bwpDCndJere7/yzdJAHpowkAAIAcogkAAIAcIgAAACCHctUHYNasWb548eK0k9Gy9u/fr87OzrST0TbIz2SRn8kiP5OVVn6uX7/+SXc/o9K+XAUAixcv1rp169JORssaHBxUX19f2sloG+RnssjPZJGfyUorP81se7V9NAEAAJBDBAAAAORQJgMAM1tgZv9hZpvNbJOZvbfCMX1m9stohbUNZvbhNNIKAEArymofgCOSVrn7vdGKYuvN7M5oTvVSP3L330ohfQAAtLRM1gC4+x53vzd6/ZzCGtk1ryUOAABGl/mZAM1ssaS7JZ3n7vtKtvdJ+pbC1J67Jb3P3TdVOH+lpJWS1N3dvWzNmjWNT3SbKhaL6urqSjsZbYP8TBb5mSzyM1lp5efy5cvXu3tPpX2ZDgDMrEtSQWFp0H8r2zdT0jF3L5rZZZI+4+5LR7teT0+PMwxw/BgWlCzyM1nkZ7LIz2SlOAywagCQySYASTKzKQp3+F8rL/wlyd33uXsxen2HpClmNqvJyQQAoCVlMgAwM5P0BUmb3f3TVY6ZEx0nM7tI4bs81bxUAgDQurI6CuA3JF0l6edmtiHa9iFJCyXJ3W+S9HuS3m1mRyQ9L+lKz3J7BoCWUChIAwPS0JC0ZInU3y/19qadKiB5mQwA3H2tJBvjmAFJA81JEYA8KBSkVaukzk6pu1vauze8v+EGggC0n0w2AQBAGgYGQuE/c6Y0aVJ47uwM24F2QwAAAJGhIal8pFZXV9gOtBsCAACILFkiFYvHbysWw3ag3RAAAECkv1/av1/at086diw8798ftldSKEgrVkg9PeG5UGhueoGJIAAAgEhvb+jwN3u29Pjj4blaB8C4w+Devcd3GCQIQKvI5CgAAEhLb29tPf5LOwxKI88DA4wYQGugBgAAxoEOg2h1BAAAMA50GESrIwAA0PIKBWnr1uZ2xqu3wyCQNQQAAFpa3BlveLi5nfHq6TAIZBGdAAG0tLgzXkfHyOx98fZGF8a1dhgEsogaAAAtjc54wPgQAABoaY3qjMckP2h3BAAAWlrcGe/o0eQ64zHJD/KAAABAS4s7402ZklxnPFYFRB7QCRBAy+vtldyldeuSud7QULjzL0W/ArQbagAAoAyT/CAPCAAAoAyT/CAPCAAAoAyT/CAP6AMAIFMKhdDZbmgoVLn399df8CZxjUqT/CRxXSArqAEAkBmVht+tXBkK2VrH4zdqCB9DA9FuCAAAZEb58LvhYWn3bumBB2ovdMczhK+WSX8YGoh2QwAAIDPKp/Xdti2M7x8err3QrXdq4Frv7JlyGO2GAABAZpQPvztwQDKTpk8f2TZWoVvvEL5a7+wZGoh2QwAAIBMKhXD3vW6ddM890pNPhrv/w4elRYtGjhur0K13CF+td/YMDUS7IQAAkLq4Gl6SXvay8Lxxo3TmmdLcudLUqbUXuvUO4av1zp6hgWg3DAMEkLrSanhJOuOMUNhL0sknh2BAki64oLZCt9IQvmr6+0eCj66uUPhXCzLquS6QddQAAKhZo5bIrVQNf+jQyNz+v/7r0vnnn3innoS83dmzzDFiBAAAatLIcfCVquEffTR0/hseln72M+m++6Tt26Vrr53455Xr7ZVuuSUEHLfckkzhn8WClrkMUIoAAEBNGjkOvlIHuwMHwt34Aw+E2oBp06SjR6Wf/jT7BVbaBW214IO5DFCKAABATSY6Dn60O+JK1fCvfGUoODs6pMlRb6V4SGCSBVYj7tTTLGhHCz6YywClCAAA1GQi4+BruSMur4b/yEdCLYAkuUtHjoQagLPOSq7AatSdepoF7WjBB3MZoBQBAICaTGQc/HjuiOP5/ydNCnMBTJsmnXNOeK5WYNV7N9+oO/W4oH3ySWn9eulHP5J+8pNw7WqSqomoFnzcd5/0xBMj8yw88QRzGeQdAQCAmkykt/x474ivvz5MAnTBBdLLXx7mA4gLrPICM757r/VuvlCQ7rpL2rAhFNJPPVV7usbS3y/t2SPdf3/ovzBpknTwoPTYYyPpKU1/b29Y9CiJmohKd/m7doUC/5lnQgD1zDMhEHj22fYe8YDRMQ8AgJqNdxz8kiWhUIvH+Uu1VT3HQUf5ErxSKCA7O0P/gMFB6VWvkh55RHrpS0fu5qVwbqVlfVetCuceOxYK6QcekM49N8w+ONEq8d5ead68UNAOD4d+Cy95Sbh2XLsQp7+7O9QOHDwonX762GmvpHSZ4q6uEHxII/Ma7NgRrr19e+hTcfrp4fN27JjY90Rry2wAYGaXSvqMpA5JN7v7J8r2W7T/MkkHJL3N3e9tekIBjKp0it/p06Wzzz7+Tn4slYKOFStC4Xn4sPTgg6FQk0KfgbggP/306nfzcdX/2WdLmzeH8ydNCgHEokXSxReHz4iDjosvltauHSlg3UP644CkUiFdLEoXXRSuGzt2LFyjfOKj4eEQHGzbFtIt1V4TEQczcTBRLIbOklKoqVmyJNTW7Nt3fIfKadOk55+vPchA+8lkE4CZdUi6UdIbJZ0r6S1mdm7ZYW+UtDR6rJT02aYmEsCYqk3xazaxque4II7vaCdPDtd0D++3bQvHVatliM+fNWukX8HRo6Gj4VVXSV/96kh1/MMPSx/6UHieMiU0F9x7b/jM0arqR+twV94kMn16SH/c6XG0tJer1I9hzpxQ6McdKuNJlCaX3PIdPcoIgLzLZAAg6SJJW9x9q7sflrRG0uVlx1wu6Sse3CPpFDOb2+yEAqiutHA644xQTd/TE17XW/iXtpk/9lho1z5wYOTu32zkzjfurFitlqG0cJ41S1q2TLrwQumSS8KdfpzmZ54JBf/Bg9JDD4XXU6eGx44do3caHK3TZHlwsGhR+C7PPy/dfXfopPfYY7XVkNTSv6K/PxT+Bw8eP6Ji9mxGAOSZuXvaaTiBmf2epEvd/Z3R+6sk/Zq795cc8x1Jn3D3tdH7H0p6v7uvK7vWSoUaAnV3dy9bs2ZNk75F+ykWi+oq/0uDcWtGfhaL4S41nkhn9uwTC4tGXnfz5nDXXG54ONx51/N5O3eGO9yOjlD1f+jQ8YX+3LlFPfFEl44cCYXczJnV01V+vaNHQyG9YEHYPmVKKCQPHgz74toFKRwfv4+vXe37VMunSt/n4MGR5gKzsH3x4rF/r4cfDoGDezh/6tRw/pQp0gtfOHLc3r3S7t0jtSRxrcmCBdXyiP/vSUorP5cvX77e3Xsq7ctqHwCrsK08UqnlGLn7akmrJamnp8f7+vomnLi8GhwcFPmXnEbnZ6EgXXdduEMtXeRmPFXv5Z3Mdu8Oq/SNdd0bbzyx89++faEgfPe7a//8uJd/6XV27JB+8YtQ+E2fLn30o4NavbpPO3aEGoYLLqjePl/+nUrb8uPPeuSRUHDv3x+CgI6OECRI0owZoUBftmx836f88x97LLT9L1x4Yj7dckv1a3zmM9I114Q86OgIaZJCB8TVqyt3fqz0nSvh/3uyspifWW0C2CVpQcn7+ZJ2j+MYILeSGuNePlnOpk2hl/nhw2NfdyJzB5SqVM09f364Q77jDqmvLxTSO3aEQnTp0rGH0lWb/z9O83PPhUI1Xop4ypQQaBw9Gr77woUTG0df+vlz5oTvU2qs9vk4wOvoCAGJNNIkMmdO5YK9EWseoHVlNQD4qaSlZrbEzKZKulLS7WXH3C7pjyx4laRfuvueZicUyKqkZqMrDySGh0OhuH372NdNaqW90TrUxYXaC14QOrstXHh8YHLttfVNsBOn+eSTw511V1cYwjdjRij8TztNesUrQhNBUisHjmeGvoGBkIaTTgp3/qeeKp1ySsiH/fsnlh7kQyYDAHc/Iqlf0vclbZb0DXffZGbvMrN3RYfdIWmrpC2SPi/pT1JJLJBRSU37WqnHunttPdbrqXIeTS01CYcOnRjwHD4cFg+qZYKd0k6GAwPSX/2V9OIXh9qExYvD84tfLH3zm+HYJO+iK32/PXvC5D3VApf4dzlyZGRbR0cyU/sWCtLWrdlayRDJy2QAIEnufoe7v8jdz3L3j0fbbnL3m6LX7u5/Gu1/WXnnPyDvkqp+Lw8kFi8eGbc+2nWTnGe/lpqEadNODHi2bAkBy1jNIJXS+tWvhiGBE629GM/3k0Y6GlbLu3h8fzx8UQpB0OTJE5vaN86L4WGWDG53We0ECGCCqs2iV28B1t8/Mpa/qysU/PPmhXbmeKKZSte99trQTBDPhLd48UjhO55CdKxZCGfPHqn6jjsnHjgwMv9ArFJzRfnEPPHz2rWjd8JLUun3W7Hi+HRUmhkw/l0WLQqFdDzO/7rrJhakxHkRT45U76yEaB0EAEAbG+/UveXXKA8krr9+9OsWCqHqfdq08Iin2j3nnMZNPNPVdWI6eyoMfqpURT40FO52y69XLa1JNW1UU0t6Sn+XePriJNJRb16gdREAAKhoIoXcwEC464+HzcUz0G3ZEnrsN0p5wFM6E2HpkMXyKvJ61ioon3o3riJPsnmg1vQkEeBV++xSLBncnjLbBwBAeibafj80JJ111kj7dDyJzoEDjVt6tlgMheGpp4ZHHGjUMgqhnv4SjVpCeLzpSVr82fHkSCwZ3L4IAACcYKKF3JIloeo/nmc/njMgXvo2aYVCmP//3nvD55iFOftXrgz7xxr73tsbOvw9+mhYWfDRR8P7SscmNbxyNEkNn5zIZ0+Z0vzPRnPRBADgBBNtB447qHV2Si9/+UjV+/XXJ59WKQQmF18c5ieImxvMpKefrq3zWqEQev2fddZIU8FXvxrWByg/d7xLG9erEdX79Xy2ewia0L6oAQBwgonOIdDsO9ihoZE57mOTJ4eah1qClnpqPNKsngeSRAAA4ASlhdyTT4bV6datC3e+tfYDaOa0s0uWhDv+o0dHth05EmoEagla6qnWT7N6HkgSAQCAE8SFnJm0cWPYFo+nz+KkMP39I6vqHTkS5h44fDhM21vLnXk9NR6NHgIINAsBAICKenvDqno9PdKrXhVeN6LHexJ6e8NEQ694RaiWdw8r9cUr4pVO81tpattaq/WTnN0QSBsBAICqaqkaH6twbZaurvDZzzwTHoODI4X/WIV2rdX6zRgCWC6p/M3K74TsIAAAUNVYVePlhevDD0tXXBEWzclKIVNroV1Ln4VmDAEslVSNQ6EgXX11CIoeeSQ8X3117dcheGhPBABAnfL0x3CsqvHSwvXpp8Pc//FxWakeT7LQTmqFxVolVePw4Q+H1QWPHQvzMhw7Ft5/+MNjn0uzR/siAADqkLc/hmNVjZcWrtu3h454J50kPf98dvoLJFloN3sIYFLBy8aNI3MkmIXnqVNHOniOJo1mDzQHAQBQhzz+MRytary0cD1wIAQAR46EdQCkbCwik2Sh3ewhgEkGL/F0zNXeV9PsZg80DwEAUIe8/DGstZmjtHB9wQvCqn9Hj4Ye+VI2FpFJutBu5vwGcf7u2BE+b3Aw3LVffHF917nggjA08siR8D4eKnnBBWOf2+xmDzQPAQBQhzz8MaynmaO0cJ0xI9SKLFoUFuPJ0gx5zSy0kxSvUbBjR/h31tUlLVwYpin+zGdq74vykY9I8+aF3+fgwfA8b17YPhZmPmxfBABAHfLwx7DeZo64cH34Yem226QXvaj+O+127FiZ1Hdau1Y6//ywumFPTwgAhoel666rvS9Kb2+YE6GvT1q6NDzHcySMhZkP2xeLAQF1iP8YtvNMcBNZCGg8C9jENQ6dnccXZmkWMhOd7S/J71Tp99i7N1TjxwsSxc+jLXw0kcWF0lyYCI1DDQBQp1atTq5Vqw51S0oSIz3q/U6j1RZU+z3y0BcFjUUAAOA4rTrULSlJBCT1fKexAo5Kv8fkyaEqvlS79UVB4xEAADhOKw91S0ISAUk932msgKPS73HdddKUKe3dFwWNRx8AoEFaedW4Zrb59veHO14pFLTFYrqF2ZIl4S48bleX6g9I6vlOtfS5qPR7XHhh6/77QjZQAwA0QN5mDJyIrPUyT6IJpJ7vNN4akFboi9KOozvaCQEA0ABZ69g2Hs38452lwiypgKTW79TMPhfN/E0JgrOPAABogKx1bKtX0n+8W+1OsJkBSbNqQEp/08mTw6yCl10W5gRoxO/RDkFwuyMAABogjY5tSRSy8TWuuCIs7jM8PPE/3twJjq0ZAUdcIB8+LD344MjKgJs2Neb3aPUgOA8IAIAGaPZQuiQK2dJrHDsW5vR/4AHpqafC/vH+8eZOMBviAjletXHy5DCSYHi4Mb9H1kZ34EQEAEADNLtjWxKFbOk1OjvDsrEdHdK2bWH/eP94cyeYDXGBHK/aKI2s3NiI3yMP02a3OgIAoEEaVa1bqao/iUK29BqLFoUaAGnkj/h4/3hzJ5gNcYE8ZUr4bY8cGVm5sRG/R9ZGd+BEBABAC6lW1d/ZOXYhO1YfgdKCetYs6ZxzQm3CpEkT++PNnWA2xAXyueeOrAh4zjkhIGjU75Gl0R04EQEA0EKqVfWbjV7I1tJHoLygnjo11ATcdtvE/nhzJ5gdvb3hN7/jjtD7f3iY3yPPmAkQaCHVZo17/PHRVyksDRykyqvHNXKlQ1aTyxZ+D0gEAEBLGW2a2tH+qNe6xC8FA5AfmWsCMLNPmtmDZrbRzG41s1OqHLfNzH5uZhvMbF2TkwmkYrzt6XTEA1AucwGApDslnefu50t6WNIHRzl2ubtf6O49zUkakK7xtqfTEQ9Aucw1Abj7D0re3iPp99JKC5BF46mmb2T7PoDWlLkAoMzbJX29yj6X9AMzc0mfc/fVzUsW0Hpo3wdQyty9+R9qdpekORV2XePu346OuUZSj6Q3e4VEmtk8d99tZrMVmg3e4+53VzhupaSVktTd3b1szZo1CX6TfCkWi+oqn20G40Z+Jov8TBb5may08nP58uXrqzWTpxIAjMXM3irpXZJe6+4Hajj+OklFd//UaMf19PT4unX0FxyvwcFB9fX1pZ2MtjGe/CwUqMavhn+fySI/k5VWfppZ1QAgc50AzexSSe+X9DvVCn8z6zSzGfFrSa+XdH/zUgkkq5aV/FhVD0CSMhcASBqQNEPSndEQv5ukUOVvZndEx3RLWmtm90n6iaTvuvv30kkuMDG1FuysqgcgSZnrBOjuZ1fZvlvSZdHrrZIuaGa6gEapZZY+qfbJfACgFlmsAQBypdaV/JjMB0CSCACAlNVasJdP5rNjh7Rxo3TffdX7DQBANQQAQIJq6cxXrtZZ+kpnAdyyJQQACxdKS5e2RofA8eQNgMYhAAASMt5e+vVM7xuvr37++eGxcGFrdAhkBAOQPZnrBAi0qlo781VS7yx9rdYhcCJ5A6AxqAEAElJrZ74ktFqHwGbmDYDaEAAACVmyRNq1S1q/XvrRj8Lzrl2NKZRbbXW/VgtYgDwgAAAScvHFoXPe/v3S1KnhecuWsD1p410WOC2tFrAAeUAfACAha9dKZ58tPfGEdOBAaPM+44yw/b3vTf7zWml1P5YjBrKHAABIyNCQNH9+6JkfO3aMdu5YKwUsQB7QBAAkpN527mKRcfEA0kMAACSknnbuQkHauZNx8QDSQwAAJKSejnkDAyMT+LTCRD4A2g99AIAE1drOPTQkdXQcv41x8QCaiRoAIAVLlkhHjx6/jXHxAJqJAABIQX//SD8BxsUDSANNAEAKenul554L/QQYFw8gDQQAQEq6usLKfgCQBpoAAADIIQIAoEShwOQ8APKBAACIFAphMh4m5wGQBwQAQGRgIEzGw+Q8APKAAACIDA2FjnmlmJwHQLsiAAAi9S7mAwCtjAAAiNSzmA8AtDoCACBSz2I+ANDqmAgIKFHrYj4A0OqoAQAANBXzbWQDAQAAoGmYbyM7CAAAAE3DfBvZQQAAAGga5tvIDgIAAEDTMN9GdhAAAACahvk2soMAAADQNMy3kR3MA4C2VyiEDkZDQ6Gasb+fPzZAmphvIxsyVwNgZteZ2S/MbEP0uKzKcZea2UNmtsXMPtDsdKI1MOQIACrLXAAQ+Xt3vzB63FG+08w6JN0o6Y2SzpX0FjM7t9mJRPYx5AgAKstqADCWiyRtcfet7n5Y0hpJl6ecJmQQQ44AoLKsBgD9ZrbRzL5oZqdW2H+mpJ0l73dF24DjMOQIACozd2/+h5rdJWlOhV3XSLpH0pOSXNJHJc1197eXnb9C0hvc/Z3R+6skXeTu76nwWSslrZSk7u7uZWvWrEnyq+RKsVhUV/ntdMYVi9LOnaH6v6NDOno0DD1asODEmoHmp6318jPLyM9kkZ/JSis/ly9fvt7deyrtS2UUgLtfUstxZvZ5Sd+psGuXpAUl7+dL2l3ls1ZLWi1JPT093tfXV1daMWJwcFCtmH9ZHQXQqvmZVeRnssjPZGUxPzM3DNDM5rr7nujtmyTdX+Gwn0paamZLJP1C0pWS/qBJSUSLSWLIUVaDCAAYryz2Afg7M/u5mW2UtFzSX0iSmc0zszskyd2PSOqX9H1JmyV9w903pZVgtDeGEgJoR5mrAXD3q6ps3y3pspL3d0g6YYggkLTSoYTSyPPAALUAAFpXFmsAgExhKCGAdkQAAIyBoYQA2hEBADAGVi8D0I4IAIAxsHoZgHaUuU6AQBaxehmAdkMNAAAAOUQAAABADhEAAACQQwQAAADkEAEAAABNUihIK1ZIPT3hOc0pxQkAAABogqytK0IAAABAE5SuKzJpUnju7Azb00AAAABAE2RtXRECAAAAmiBr64oQAAAA0ARZW1eEAAAAgCbI2roiVdcCMLM7JP2Ju29rXnIAAGhfWVpXZLQagC9J+oGZXWNmU5qUHgAA0ARVAwB3/4akl0uaKWmdmb3PzP4yfjQthUCKsjRpBwAkaaw+AMOS9kuaJmlG2QNoa1mbtAMAkjRaH4BLJX1a0u2SXuHuB5qWKiADSiftkEaeBway04YHAONVNQCQdI2kFe6+qVmJAbJkaCjc+ZdKc9IOAEjSaH0A/geFP/Isa5N2AECSmAcAqCJrk3YAQJIIAIAqsjZpBwAkabQ+AEDuZWnSDgBIEjUAAADkEAEA2g6T9wDA2AgA0FaYvAcAakMAgLZSOnnPpEnhubMzbAcAjCAAQFsZGgqT9ZRi8h4AWZdG0yUBANoKk/cAaDVpNV0SAKCtMHkPgFaTVtMlAQDaCpP3AGg1aTVdMhEQ2g6T9wBoJUuWhGr/eMVRqTlNl5mrATCzr5vZhuixzcw2VDlum5n9PDpuXZOTCQBAItJqusxcDYC7/3782sxukPTLUQ5f7u5PNj5VAAA0Rtx0OTAQqv2XLAmFf6NrMjMXAMTMzCT9T0mvSTstAAA0UhpNl+buzf3EGpnZb0r6tLv3VNk/JOkZSS7pc+6+uspxKyWtlKTu7u5la9asaVCK21+xWFRXeU+Vhn5eaBc7dEiaNi106Gvixzdcs/Oz3ZGfySI/k5VWfi5fvnx91XI0jQDAzO6SNKfCrmvc/dvRMZ+VtMXdb6hyjXnuvtvMZku6U9J73P3u0T63p6fH162ju8B4DQ4Oqq+vrymfFY+L7ewMhX6xGNrE2qlHfzPzMw/Iz2SRn8lKKz/NrGoAkEoTgLtfMtp+M5ss6c2Slo1yjd3R814zu1XSRZJGDQDQOkrHxUojzwMD7RMAAECaMjcKIHKJpAfdfVelnWbWaWYz4teSXi/p/iamDw3GlL4A0FhZ7QR4paR/Ld1gZvMk3ezul0nqlnRr6CeoyZL+xd2/1/RUomHicbGHD0vbt0sHDkhTpkjnnpt2ygCgPWQyAHD3t1XYtlvSZdHrrZIuaHKy0ET9/dLVV0t79khTp4bpMQ8elB57LPQPoBkAACYmq00AyLneXmnePOmkk6SjR8Pzy14mzZnD0r4AkAQCAGTWnj3S5LI6KvoBAEAyCACQSYVC6ANw4ECYA+DQIemBB6Rdu1jaFwCSQACATBoYkBYulMykI0ekjg7JXdqxg6V9ASAJmewECAwNSfPnS9Onj4wCmD5dmjGDDoAAkAQCAGRSPAxw1qzwkMIKWbNnp5suAGgXNAEgk9JaHhMA8oIAAJkUL485e7b0+OPhuZ3WAQCAtNEEgMxKY3lMAMgLagAAAMghAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAAAHIolQDAzFaY2SYzO2ZmPWX7PmhmW8zsITN7Q5XzTzOzO83skej51OakHNUUCtKKFVJPT3guFNJOEQBgNGnVANwv6c2S7i7daGbnSrpS0kslXSrpn8yso8L5H5D0Q3dfKumH0XukpFCQVq2S9u6VurvD86pVBAEAkGWpBADuvtndH6qw63JJa9z9kLsPSdoi6aIqx305ev1lSVc0JKGoycCA1NkpzZwpTZoUnjs7w3YAQDZNTjsBZc6UdE/J+13RtnLd7r5Hktx9j5nNrnZBM1spaaUkdXd3a3BwMLnU5kyxWKyYf695jTRlyonHDw9LZHd11fIT40N+Jov8TFYW87NhAYCZ3SVpToVd17j7t6udVmGbTyQd7r5a0mpJ6unp8b6+volcLtcGBwdVKf9uvDFU+8+cObJt3z5p9mzp3e9uXvpaTbX8xPiQn8kiP5OVxfxsWADg7peM47RdkhaUvJ8vaXeF4x43s7nR3f9cSXvHk0Yko78/tPlLUleXVCxK+/eH7QCAbMraMMDbJV1pZtPMbImkpZJ+UuW4t0av3yqpWo0CmqC3V7rhhnDH//jj4fmGG8J2AEA2pdIHwMzeJOkfJZ0h6btmtsHd3+Dum8zsG5IekHRE0p+6+9HonJsl3eTu6yR9QtI3zOwdknZIWpHG98CI3l4KfABoJakEAO5+q6Rbq+z7uKSPV9j+zpLXT0l6bcMSCABAm8taEwAAAGgCAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByKJUAwMxWmNkmMztmZj0l219nZuvN7OfR82uqnH+dmf3CzDZEj8ual3oAAFrf5JQ+935Jb5b0ubLtT0r6bXffbWbnSfq+pDOrXOPv3f1TDUwjAABtK5UAwN03S5KZlW//WcnbTZJOMrNp7n6oickDAKDtZbkPwO9K+tkohX+/mW00sy+a2anNTBgAAK3O3L0xFza7S9KcCruucfdvR8cMSnqfu68rO/elkm6X9Hp3f7TCtbsVmgtc0kclzXX3t1dJx0pJKyWpu7t72Zo1a8b9nfKuWCyqq6sr7WS0DfIzWeRnssjPZKWVn8uXL1/v7j2V9jUsAKhFpQDAzOZL+ndJf+zu/1nDNRZL+o67nzfWsT09Pb5u3bqxDkMVg4OD6uvrSzsZbYP8TBb5mSzyM1lp5aeZVQ0AMtUEYGanSPqupA+OVvib2dySt29S6FQIAABqlNYwwDeZ2S5Jr5b0XTP7frSrX9LZkv6mZIjf7Oicm0uGDP5dNFRwo6Tlkv6i2d8BAIBWltYogFsl3Vph+8ckfazKOe8seX1V41IHAED7y1QTAAAAaA4CAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAAAHKIAAAAgBwiAAAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiACgzRQK0ooVUk9PeC4U0k4RACCLCADaSKEgrVol7d0rdXeH51WrCAIAACciAGgjAwNSZ6c0c6Y0aVJ47uwM2wEAKEUA0EaGhqSuruO3dXWF7QAAlCIAaCNLlkjF4vHbisWwHQCAUgQAbaS/X9q/X9q3Tzp2LDzv3x+2AwBQigCgjfT2SjfcIM2eLT3+eHi+4YawHQCAUpPTTgCS1dtLgQ8AGBs1AAAA5BABAAAAOUQAAABADhEAAACQQwQAAADkEAEAAAA5RAAAAEAOEQCMA0vuAgBaHQFAnVhyFwDQDlIJAMxshZltMrNjZtZTsn2xmT1vZhuix01Vzj/NzO40s0ei51OblXaW3AUAtIO0agDul/RmSXdX2Peou18YPd5V5fwPSPqhuy+V9MPofVOw5C4AoB2kEgC4+2Z3f2gCl7hc0pej11+WdMWEE1UjltwFALQDc/f0PtxsUNL73H1d9H6xpE2SHpa0T9Jfu/uPKpz3rLufUvL+GXev2AxgZislrZSk7u7uZWvWrJlQmotFaefOUP3f0SEdPRqW3l2w4MSagXZTLBbV1e5fsonIz2SRn8kiP5OVVn4uX758vbv3VNrXsNUAzewuSXMq7LrG3b9d5bQ9kha6+1NmtkzSbWb2UnffN950uPtqSaslqaenx/v6+sZ7qV8pFEKb/9BQuPPv78/HCnyDg4NKIv8QkJ/JIj+TRX4mK4v52bAAwN0vGcc5hyQdil6vN7NHJb1I0rqyQx83s7nuvsfM5kraO+EE14EldwEArS5TwwDN7Awz64hev1DSUklbKxx6u6S3Rq/fKqlajQIAAKggrWGAbzKzXZJeLem7Zvb9aNdvStpoZvdJ+qakd7n709E5N5cMGfyEpNeZ2SOSXhe9BwAANWpYE8Bo3P1WSbdW2P4tSd+qcs47S14/Jem1DUsgAABtLlNNAAAAoDkIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByKNXFgJrNzJ6QtD3tdLSwWZKeTDsRbYT8TBb5mSzyM1lp5ecidz+j0o5cBQCYGDNbV21VKdSP/EwW+Zks8jNZWcxPmgAAAMghAgAAAHKIAAD1WJ12AtoM+Zks8jNZ5GeyMpef9AEAACCHqAEAACCHCABQFzP7pJk9aGYbzexWMzsl7TS1MjNbYWabzOyYmWWqh3ArMbNLzewhM9tiZh9IOz2tzMy+aGZ7zez+tNPSDsxsgZn9h5ltjv6vvzftNMUIAFCvOyWd5+7nS3pY0gdTTk+ru1/SmyXdnXZCWpWZdUi6UdIbJZ0r6S1mdm66qWppX5J0adqJaCNHJK1y93MkvUrSn2bl3ycBAOri7j9w9yPR23skzU8zPa3O3Te7+0Npp6PFXSRpi7tvdffDktZIujzlNLUsd79b0tNpp6NduPsed783ev2cpM2Szkw3VQEBACbi7ZL+X9qJQO6dKWlnyftdysgfWKCUmS2W9HJJ/51yUiRJk9NOALLHzO6SNKfCrmvc/dvRMdcoVG19rZlpa0W15CcmxCpsY3gTMsXMuiR9S9Kfu/u+tNMjEQCgAne/ZLT9ZvZWSb8l6bXOONIxjZWfmLBdkhaUvJ8vaXdKaQFOYGZTFAr/r7n7v6WdnhhNAKiLmV0q6f2SfsfdD6SdHkDSTyUtNbMlZjZV0pWSbk85TYAkycxM0hckbXb3T6ednlIEAKjXgKQZku40sw1mdlPaCWplZvYmM9sl6dWSvmtm3087Ta0m6pTaL+n7Ch2svuHum9JNVesys3+V9GNJLzazXWb2jrTT1OJ+Q9JVkl4T/c3cYGaXpZ0oiZkAAQDIJWoAAADIIQIAAAByiAAAAIAcIgAAACCHCAAAAMghAgAADRGtgjZkZqdF70+N3i9KO20ACAAANIi775T0WUmfiDZ9QtJqd9+eXqoAxJgHAEDDRFOgrpf0RUlXS3p5tGIfgJSxFgCAhnH3YTP7K0nfk/R6Cn8gO2gCANBob5S0R9J5aScEwAgCAAANY2YXSnqdpFdJ+gszm5tuigDECAAANES0CtpnFdY/3yHpk5I+lW6qAMQIAAA0ytWSdrj7ndH7f5L0EjPrTTFNACKMAgAAIIeoAQAAIIcIAAAAyCECAAAAcogAAACAHCIAAAAghwgAAADIIQIAAAByiAAAAIAc+v8O+B7zUSuonQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, color='blue', alpha=0.7)\n",
    "plt.title('Scatter plot of X against Y')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:**\n",
    "\n",
    "**i. Y = 0 + 1X + **\n",
    "\n",
    "**ii. Y = 0 + 1X + 2X2 + **\n",
    "\n",
    "**iii. Y = 0 + 1X + 2X2 + 3X3 + **\n",
    "\n",
    "**iv. Y = 0 + 1X + 2X2 + 3X3 + 4X4 + **\n",
    "\n",
    "**Note you may find it helpful to use the data.frame() function to create a single data set containing both X and Y.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = 0 + 1X: LOOCV error = 6.6330\n",
      "Y = 0 + 1X + 2X2: LOOCV error = 1.1229\n",
      "Y = 0 + 1X + 2X2 + 3X3: LOOCV error = 6.5976\n",
      "Y = 0 + 1X + 2X2 + 3X3 + 4X4: LOOCV error = 4.7238\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Simulated data\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "\n",
    "# Create a DataFrame containing both X and Y\n",
    "data = pd.DataFrame({'X': x, 'Y': y})\n",
    "\n",
    "# Define function to compute LOOCV error\n",
    "def compute_loocv_error(model, X, y):\n",
    "    loocv_errors = []\n",
    "    n = len(X)\n",
    "    for i in range(n):\n",
    "        # Leave out the ith observation\n",
    "        X_train = np.delete(X, i, axis=0)\n",
    "        y_train = np.delete(y, i)\n",
    "        X_test = X[i].reshape(1, -1)\n",
    "        y_test = y[i]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the left-out observation\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Compute the squared error\n",
    "        loocv_error = (y_test - y_pred) ** 2\n",
    "        loocv_errors.append(loocv_error)\n",
    "    \n",
    "    # Compute the mean LOOCV error\n",
    "    mean_loocv_error = np.mean(loocv_errors)\n",
    "    return mean_loocv_error\n",
    "\n",
    "# Initialize linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Compute LOOCV errors for each model\n",
    "models = ['Y = 0 + 1X', 'Y = 0 + 1X + 2X2', 'Y = 0 + 1X + 2X2 + 3X3', 'Y = 0 + 1X + 2X2 + 3X3 + 4X4']\n",
    "X = data['X'].values.reshape(-1, 1)\n",
    "y = data['Y'].values.reshape(-1, 1)\n",
    "\n",
    "for i, model_description in enumerate(models):\n",
    "    # Select appropriate features for the model\n",
    "    if i == 0:\n",
    "        features = X\n",
    "    else:\n",
    "        features = np.column_stack((X, X ** (i + 1)))\n",
    "    \n",
    "    # Compute LOOCV error for the model\n",
    "    loocv_error = compute_loocv_error(linear_model, features, y)\n",
    "    \n",
    "    # Print the LOOCV error\n",
    "    print(f'{model_description}: LOOCV error = {loocv_error:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is `Y = 0 + 1X + 2X2` (degree = 2, quadratic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Repeat (c) using another random seed, and report your results. Are your results the same as what you got in (c)? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = 0 + 1X: LOOCV error = 6.6330\n",
      "Y = 0 + 1X + 2X2: LOOCV error = 1.1229\n",
      "Y = 0 + 1X + 2X2 + 3X3: LOOCV error = 6.5976\n",
      "Y = 0 + 1X + 2X2 + 3X3 + 4X4: LOOCV error = 4.7238\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulated data\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "\n",
    "# Create a DataFrame containing both X and Y\n",
    "data = pd.DataFrame({'X': x, 'Y': y})\n",
    "\n",
    "# Define function to compute LOOCV error\n",
    "def compute_loocv_error(model, X, y):\n",
    "    loocv_errors = []\n",
    "    n = len(X)\n",
    "    for i in range(n):\n",
    "        # Leave out the ith observation\n",
    "        X_train = np.delete(X, i, axis=0)\n",
    "        y_train = np.delete(y, i)\n",
    "        X_test = X[i].reshape(1, -1)\n",
    "        y_test = y[i]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the left-out observation\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Compute the squared error\n",
    "        loocv_error = (y_test - y_pred) ** 2\n",
    "        loocv_errors.append(loocv_error)\n",
    "    \n",
    "    # Compute the mean LOOCV error\n",
    "    mean_loocv_error = np.mean(loocv_errors)\n",
    "    return mean_loocv_error\n",
    "\n",
    "# Initialize linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Compute LOOCV errors for each model\n",
    "models = ['Y = 0 + 1X', 'Y = 0 + 1X + 2X2', 'Y = 0 + 1X + 2X2 + 3X3', 'Y = 0 + 1X + 2X2 + 3X3 + 4X4']\n",
    "X = data['X'].values.reshape(-1, 1)\n",
    "y = data['Y'].values.reshape(-1, 1)\n",
    "\n",
    "for i, model_description in enumerate(models):\n",
    "    # Select appropriate features for the model\n",
    "    if i == 0:\n",
    "        features = X\n",
    "    else:\n",
    "        features = np.column_stack((X, X ** (i + 1)))\n",
    "    \n",
    "    # Compute LOOCV error for the model\n",
    "    loocv_error = compute_loocv_error(linear_model, features, y)\n",
    "    \n",
    "    # Print the LOOCV error\n",
    "    print(f'{model_description}: LOOCV error = {loocv_error:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcomes we obtained are completely identical, the LOOCV process is not sensitive to changes in the random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was expected that model `Y = 0 + 1X + 2X2` would be better fit with the data. As we saw in the scatterplot previously, the graph suggests a quadratic relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                                   MODEL 1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.318\n",
      "Model:                            OLS   Adj. R-squared:                  0.311\n",
      "Method:                 Least Squares   F-statistic:                     45.60\n",
      "Date:                Sun, 05 May 2024   Prob (F-statistic):           1.04e-09\n",
      "Time:                        16:44:42   Log-Likelihood:                -230.83\n",
      "No. Observations:                 100   AIC:                             465.7\n",
      "Df Residuals:                      98   BIC:                             470.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.4650      0.247     -5.937      0.000      -1.955      -0.975\n",
      "x1             1.9494      0.289      6.752      0.000       1.376       2.522\n",
      "==============================================================================\n",
      "Omnibus:                       52.788   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              149.089\n",
      "Skew:                          -1.953   Prob(JB):                     4.22e-33\n",
      "Kurtosis:                       7.530   Cond. No.                         1.20\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "==============================================================================\n",
      "                                   MODEL 2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.887\n",
      "Model:                            OLS   Adj. R-squared:                  0.884\n",
      "Method:                 Least Squares   F-statistic:                     379.5\n",
      "Date:                Sun, 05 May 2024   Prob (F-statistic):           1.36e-46\n",
      "Time:                        16:44:42   Log-Likelihood:                -141.06\n",
      "No. Observations:                 100   AIC:                             288.1\n",
      "Df Residuals:                      97   BIC:                             295.9\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0728      0.119     -0.611      0.543      -0.309       0.164\n",
      "x1             0.9663      0.126      7.647      0.000       0.715       1.217\n",
      "x2            -2.0047      0.091    -22.072      0.000      -2.185      -1.824\n",
      "==============================================================================\n",
      "Omnibus:                        1.338   Durbin-Watson:                   2.197\n",
      "Prob(Omnibus):                  0.512   Jarque-Bera (JB):                0.814\n",
      "Skew:                           0.119   Prob(JB):                        0.666\n",
      "Kurtosis:                       3.372   Cond. No.                         2.23\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "==============================================================================\n",
      "                                   MODEL 3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.888\n",
      "Model:                            OLS   Adj. R-squared:                  0.885\n",
      "Method:                 Least Squares   F-statistic:                     253.8\n",
      "Date:                Sun, 05 May 2024   Prob (F-statistic):           1.70e-45\n",
      "Time:                        16:44:42   Log-Likelihood:                -140.47\n",
      "No. Observations:                 100   AIC:                             288.9\n",
      "Df Residuals:                      96   BIC:                             299.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0572      0.120     -0.477      0.635      -0.295       0.181\n",
      "x1             1.1146      0.187      5.945      0.000       0.742       1.487\n",
      "x2            -2.0471      0.099    -20.673      0.000      -2.244      -1.851\n",
      "x3            -0.0643      0.060     -1.070      0.287      -0.184       0.055\n",
      "==============================================================================\n",
      "Omnibus:                        0.845   Durbin-Watson:                   2.199\n",
      "Prob(Omnibus):                  0.655   Jarque-Bera (JB):                0.392\n",
      "Skew:                           0.052   Prob(JB):                        0.822\n",
      "Kurtosis:                       3.289   Cond. No.                         5.95\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "==============================================================================\n",
      "                                   MODEL 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.894\n",
      "Model:                            OLS   Adj. R-squared:                  0.890\n",
      "Method:                 Least Squares   F-statistic:                     200.2\n",
      "Date:                Sun, 05 May 2024   Prob (F-statistic):           2.22e-45\n",
      "Time:                        16:44:42   Log-Likelihood:                -137.74\n",
      "No. Observations:                 100   AIC:                             285.5\n",
      "Df Residuals:                      95   BIC:                             298.5\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1008      0.136      0.743      0.460      -0.169       0.370\n",
      "x1             0.9050      0.205      4.423      0.000       0.499       1.311\n",
      "x2            -2.5059      0.221    -11.336      0.000      -2.945      -2.067\n",
      "x3             0.0338      0.073      0.466      0.642      -0.110       0.178\n",
      "x4             0.1042      0.045      2.309      0.023       0.015       0.194\n",
      "==============================================================================\n",
      "Omnibus:                        2.476   Durbin-Watson:                   2.163\n",
      "Prob(Omnibus):                  0.290   Jarque-Bera (JB):                2.097\n",
      "Skew:                           0.118   Prob(JB):                        0.351\n",
      "Kurtosis:                       3.669   Cond. No.                         19.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    \n",
    "    poly = PolynomialFeatures(i)\n",
    "    predictors = poly.fit_transform(X.reshape(-1,1))\n",
    "\n",
    "    results = sm.OLS(y,predictors).fit()\n",
    "    \n",
    "    print(\"==============================================================================\")\n",
    "    print(\"                                   MODEL\",i)\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1:\n",
      "LOOCV error = 5.3030\n",
      "Average p-value = 0.5000\n",
      "\n",
      "Degree 2:\n",
      "LOOCV error = 0.9128\n",
      "Average p-value = 0.3333\n",
      "\n",
      "Degree 3:\n",
      "LOOCV error = 0.9570\n",
      "Average p-value = 0.3517\n",
      "\n",
      "Degree 4:\n",
      "LOOCV error = 0.9728\n",
      "Average p-value = 0.2179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate simulated data\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(size=100)\n",
    "y = X - 2 * X**2 + np.random.normal(size=100)\n",
    "\n",
    "# Perform LOOCV for polynomial regression models of degrees 1 to 4\n",
    "degrees = [1, 2, 3, 4]\n",
    "for degree in degrees:\n",
    "    # Initialize lists to store results\n",
    "    loocv_errors = []\n",
    "    p_values = []\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X.reshape(-1, 1))\n",
    "    \n",
    "    # Perform LOOCV\n",
    "    loo = LeaveOneOut()\n",
    "    for train_index, test_index in loo.split(X_poly):\n",
    "        X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit polynomial regression model\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "        \n",
    "        # Compute LOOCV error\n",
    "        loocv_error = np.mean((model.predict(X_test) - y_test)**2)\n",
    "        loocv_errors.append(loocv_error)\n",
    "        \n",
    "        # Compute standard error and t-statistic for coefficient estimates\n",
    "        n = X_train.shape[0]\n",
    "        dof = n - degree - 1  # Degrees of freedom\n",
    "        mse = np.mean((model.predict(X_train) - y_train)**2)  # Mean squared error\n",
    "        se = np.sqrt(mse / np.sum((X_train[:, 1:] - np.mean(X_train[:, 1:], axis=0))**2, axis=0))\n",
    "        se = np.concatenate(([0], se))  # Adjust shape to match model coefficients\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        se[se == 0] = np.finfo(float).eps\n",
    "        \n",
    "        t_stat = model.coef_ / se\n",
    "        p_value = 2 * (1 - t.cdf(np.abs(t_stat), dof))  # Two-tailed test\n",
    "        \n",
    "        # Store p-values for coefficient estimates\n",
    "        p_values.extend(p_value)\n",
    "    \n",
    "    # Compute average LOOCV error and print results\n",
    "    avg_loocv_error = np.mean(loocv_errors)\n",
    "    avg_p_value = np.nanmean(p_values)  # Exclude NaN values when computing mean\n",
    "    print(f'Degree {degree}:')\n",
    "    print(f'LOOCV error = {avg_loocv_error:.4f}')\n",
    "    print(f'Average p-value = {avg_p_value:.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Polynomial Degree\tLOOCV Error\tAverage p-value\n",
    "                   1\t   5.3030\t   0.5000\n",
    "                   2\t   0.9128\t   0.3333\n",
    "                   3\t   0.9570\t   0.3517\n",
    "                   4       0.9728\t   0.2179\n",
    "                   \n",
    "<u>Degree 1:</u> The average p-value is 0.5000, which indicates that none of the coefficients are statistically significant at the 0.05 significance level. \n",
    "\n",
    "<u>Degree 2:</u> The average p-value is 0.3333, which suggests that some coefficients may be statistically significant at the 0.05 significance level. The LOOCV error is substantially lower than that of the linear model, indicating that the quadratic model provides a better fit to the data.\n",
    "\n",
    "<u>Degree 3 and Degree 4:</u> The LOOCV errors for these higher-degree polynomial models are also lower than that of the linear model, indicating improved model performance.\n",
    "\n",
    "<u>Degree 2:</u> The average p-value is 0.3333, which suggests that some coefficients may be statistically significant at the 0.05 significance level. The LOOCV error is substantially lower than that of the linear model, indicating that the quadratic model provides a better fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. We will now consider the Boston housing data set, \n",
    "**from the ISLP library.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Boston.csv'\n",
    "boston = pd.read_csv(file)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  black    506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated population mean is 22.5328\n"
     ]
    }
   ],
   "source": [
    "# MEDV - Median value of owner-occupied homes in $1000's\n",
    "\n",
    "medv_mean = np.mean(boston['medv'])\n",
    "\n",
    "print('Estimated population mean is',round(medv_mean,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Provide an estimate of the standard error of . Interpret this result. Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated standard error is 0.4085\n"
     ]
    }
   ],
   "source": [
    "# SE = Sample Std deviation / square root of N\n",
    "\n",
    "medv_std = np.std(boston['medv']) / np.sqrt(len(boston))\n",
    "\n",
    "print('Estimated standard error is',round(medv_std,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Now estimate the standard error of  using the bootstrap. How does this compare to your answer from (b)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results  {'estimated_value': 22.539, 'std_dev': 0.4021}\n"
     ]
    }
   ],
   "source": [
    "def boot(data,R):\n",
    "    \n",
    "    medv = []\n",
    "    num_samples = 500\n",
    "    \n",
    "    for i in range(R):\n",
    "        indices = np.random.choice(data.index, num_samples, replace=True)\n",
    "        medv.append(data['medv'].loc[indices].mean())\n",
    "        \n",
    "    mmean = round(np.mean(medv),4)\n",
    "    mstd = round(np.std(medv),4)\n",
    "    bootstrap_statistics = {'estimated_value':mmean,'std_dev':mstd}  \n",
    "    \n",
    "    return bootstrap_statistics\n",
    "\n",
    "result = boot(boston,1000)\n",
    "print('Bootstrap results ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated population mean:22.5328;\n",
      "Bootstrap mean:22.539\n",
      "\n",
      "Estimated std error:0.4085;\n",
      "Bootstrap std error:0.4021\n"
     ]
    }
   ],
   "source": [
    "bmean = result['estimated_value']\n",
    "bstd = result['std_dev']\n",
    "\n",
    "emean = round(medv_mean,4)\n",
    "estd = round(medv_std,4)\n",
    "\n",
    "print('Estimated population mean:{};\\nBootstrap mean:{}'.format(emean,bmean))\n",
    "print('\\nEstimated std error:{};\\nBootstrap std error:{}'.format(estd,bstd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained by using `Boston['medv'].std()` and the two standard error rule (3.9).**\n",
    "\n",
    "**Hint: You can approximate a 95 % confidence interval using the formula [  2SE(),  + 2SE()].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% confidence we can say that intercal is [21.7348,23.343200000000003]\n"
     ]
    }
   ],
   "source": [
    "mean = result['estimated_value']\n",
    "std = result['std_dev']\n",
    "\n",
    "print('With 95% confidence we can say that intercal is [{},{}]'.format(mean - 2*std,mean+ 2*std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Based on this data set, provide an estimate, med, for the median value of medv in the population.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value median is 21.2.\n"
     ]
    }
   ],
   "source": [
    "median = np.median(boston['medv'])\n",
    "\n",
    "print('Estimated value median is {}.'.format(median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) We now would like to estimate the standard error of med. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boostrap Results for median\n",
      "estimated_value: 21.189\n",
      "std_dev: 0.3864\n"
     ]
    }
   ],
   "source": [
    "def boot(data,R):\n",
    "    \n",
    "    median = []\n",
    "    num_samples = 500\n",
    "    for i in range(R):\n",
    "        indices = np.random.choice(data.index, num_samples, replace=True)\n",
    "        median.append(data['medv'].loc[indices].median())\n",
    "    bootstrap_statistics = {'estimated_value':np.mean(median),'std_dev':np.std(median)} \n",
    "    \n",
    "    return bootstrap_statistics\n",
    "\n",
    "result = boot(boston,1000)\n",
    "\n",
    "bmean = round(result['estimated_value'],4)\n",
    "bstd = round(result['std_dev'],4)\n",
    "\n",
    "print('Boostrap Results for median\\nestimated_value: {}\\nstd_dev: {}'.format(bmean,bstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated median: 21.2\n",
      "Bootstrap standard error of the median: 0.37079770428091885\n"
     ]
    }
   ],
   "source": [
    "# Function to compute the median\n",
    "def compute_median(data):\n",
    "    return np.median(data)\n",
    "\n",
    "# Function to perform bootstrap resampling and compute standard error of the median\n",
    "def compute_bootstrap_std_error(data, num_bootstrap_samples):\n",
    "    medians = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # Generate a bootstrap sample\n",
    "        bootstrap_sample = np.random.choice(data, size=n, replace=True)\n",
    "        # Compute the median of the bootstrap sample\n",
    "        median = compute_median(bootstrap_sample)\n",
    "        # Store the median\n",
    "        medians.append(median)\n",
    "    \n",
    "    # Compute the standard error of the median\n",
    "    std_error = np.std(medians)\n",
    "    \n",
    "    return std_error\n",
    "\n",
    "# Example usage\n",
    "boston_median = np.median(boston['medv'])\n",
    "bootstrap_std_error = compute_bootstrap_std_error(boston['medv'], num_bootstrap_samples=1000)\n",
    "\n",
    "print(\"Estimated median:\", boston_median)\n",
    "print(\"Bootstrap standard error of the median:\", bootstrap_std_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Based on this data set, provide an estimate for the tenth percentile of medv in Boston census tracts. Call this quantity 0.1.(You can use the `np.percentile()` function.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated tenth percentile of medv (0.1): 12.75\n"
     ]
    }
   ],
   "source": [
    "# Estimate the tenth percentile of medv\n",
    "tenth_percentile = np.percentile(boston['medv'], 10)\n",
    "\n",
    "print(\"Estimated tenth percentile of medv (0.1):\", tenth_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h) Use the bootstrap to estimate the standard error of 0.1. Comment on your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error of the tenth percentile (0.1): 0.4971334604510141\n"
     ]
    }
   ],
   "source": [
    "# Perform bootstrap resampling to estimate the standard error of the tenth percentile\n",
    "n_bootstrap = 1000  # Number of bootstrap samples\n",
    "tenth_percentiles = np.zeros(n_bootstrap)  # Array to store bootstrapped tenth percentiles\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # Bootstrap resampling\n",
    "    bootstrap_sample = np.random.choice(boston['medv'], size=len(boston), replace=True)\n",
    "    \n",
    "    # Calculate the tenth percentile for the bootstrap sample\n",
    "    tenth_percentiles[i] = np.percentile(bootstrap_sample, 10)\n",
    "\n",
    "# Compute the standard error of the bootstrapped tenth percentiles\n",
    "standard_error = np.std(tenth_percentiles)\n",
    "\n",
    "print(\"Standard error of the tenth percentile (0.1):\", standard_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
