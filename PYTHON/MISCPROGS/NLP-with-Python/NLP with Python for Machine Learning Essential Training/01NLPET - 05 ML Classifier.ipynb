{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627aef3c-4474-4e6c-a803-b788e627a726",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27586c5e-b24b-4fdb-884f-6a7467fcda96",
   "metadata": {},
   "source": [
    "## Basic Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f078a6cc-6d1f-4f81-90d9-0bca6eb78671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659802d0-71fa-41bf-9c91-30d18f622d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "2   ham  Even my brother is not like to speak with me. ...\n",
       "3   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "4   ham  As per your request 'Melle Melle (Oru Minnamin..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"data/SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c6652f-bd55-40a2-97b7-20cd5ba87af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  body_len  punct%\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7\n",
       "1   ham  Nah I don't think he goes to usf, he lives aro...        49     4.1\n",
       "2   ham  Even my brother is not like to speak with me. ...        62     3.2\n",
       "3   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        28     7.1\n",
       "4   ham  As per your request 'Melle Melle (Oru Minnamin...       135     4.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fd1ce-248c-4164-8a9a-4e7f0947ec1b",
   "metadata": {},
   "source": [
    "**TfidVectorizer** means a document term matrix where each cell is a weight of how important that word is, by measuring how frequently it occurs within that text message, relative to how frequently that word occurs across all other text messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa05ba0e-4622-481b-9dc4-0492dc600ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtoriu</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%         0  008704050406  0089mi  0121  01223585236  \\\n",
       "0       128     4.7  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "1        49     4.1  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "2        62     3.2  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "3        28     7.1  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "4       135     4.4  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "\n",
       "   01223585334  0125698789  ...  zindgi  zoe  zogtoriu  zoom  zouk  zyada  \\\n",
       "0          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "1          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "2          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "3          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "4          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "\n",
       "     é    ü  üll  〨ud  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# Initialize TfidfVectorizer with the custom analyzer\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "# Create the DataFrame with additional features\n",
    "X_features = pd.concat([\n",
    "    data['body_len'],\n",
    "    data['punct%'],\n",
    "    pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vect.get_feature_names_out())\n",
    "], axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5522e-5552-43fd-9eeb-c625d5858406",
   "metadata": {},
   "source": [
    "## Explore RandomForestClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "048c22fa-e2a7-4782-8b7f-c5e0a4b5daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de32df04-1607-4b57-a831-7c7791a4451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__sklearn_clone__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_build_request_for_signature', '_check_feature_names', '_check_n_features', '_compute_oob_predictions', '_doc_link_module', '_doc_link_template', '_doc_link_url_param_generator', '_estimator_type', '_get_default_requests', '_get_doc_link', '_get_estimators_indices', '_get_metadata_request', '_get_oob_predictions', '_get_param_names', '_get_tags', '_make_estimator', '_more_tags', '_parameter_constraints', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_set_oob_score_and_attributes', '_validate_X_predict', '_validate_data', '_validate_estimator', '_validate_params', '_validate_y_class_weight', 'apply', 'decision_path', 'estimators_samples_', 'feature_importances_', 'fit', 'get_metadata_routing', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_fit_request', 'set_params', 'set_score_request']\n",
      "\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print()\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079d182-b27c-47dd-ba03-b0bf48a82b56",
   "metadata": {},
   "source": [
    "### Explore RandomForestClassifier through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a14f38-816e-4a77-9320-84b83621c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e78235e-9a0c-46d1-92c6-082e3bae6008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97576302, 0.97755835, 0.97394429, 0.96495957, 0.97484277])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs = -1) # Setting it to negative one basically just allows this to run faster \n",
    "                                         # by building the individual decision trees in parallel\n",
    "\n",
    "k_fold = KFold(n_splits= 5)\n",
    "\n",
    "cross_val_score(\n",
    "    rf,                   # The classifier or regressor to evaluate, in this case, a RandomForestClassifier instance.\n",
    "    X_features,           # The feature matrix (DataFrame) containing the input data for the model.\n",
    "    data['label'],        # The target variable (series) containing the true labels for each sample.\n",
    "    cv = k_fold,          # The cross-validation splitting strategy, here defined by the KFold object.\n",
    "    scoring = 'accuracy', # The metric to evaluate the model's performance, which is accuracy for classification tasks.\n",
    "    n_jobs = -1           # Number of parallel jobs to run; -1 means using all available CPUs.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3826e6-d23a-49c3-8283-90eb1494c7a7",
   "metadata": {},
   "source": [
    "### Explore RandomForestClassifier through Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "365b4788-2745-4192-82e0-f60553bad893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f290f96c-b702-4b8b-a822-ed80efac7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8854318e-0c9d-4a3b-b27a-8b7c81b25fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 50,  # The number of trees in the forest. More trees generally improve performance but also increase computation time.\n",
    "    max_depth = 20,     # The maximum depth of each tree in the forest. Limiting the depth helps prevent overfitting.\n",
    "    n_jobs = -1         # The number of parallel jobs to run; -1 means using all available CPUs for faster computation.\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(X_train,y_train)    # Fit the RandomForestClassifier model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b2bacdc-9050-47cc-8703-c4d85d8a047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05127839595044938, 'body_len'),\n",
       " (0.047101365959513315, 'txt'),\n",
       " (0.03395492552130747, 'call'),\n",
       " (0.033138926094627756, 'free'),\n",
       " (0.03192226678522689, 'claim'),\n",
       " (0.024781315571949247, 'stop'),\n",
       " (0.022608666285628055, 'mobil'),\n",
       " (0.021689809100748362, 'servic'),\n",
       " (0.01868831131828509, 'prize'),\n",
       " (0.018492119055469, 'urgent')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature importances from the trained model\n",
    "# Sort the features by importance in descending order\n",
    "# Display the top 10 features with the highest importance\n",
    "\n",
    "sorted(zip(rf_model.feature_importances_,X_train.columns), reverse = True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8bf025-5ad7-464c-a39d-ebde88014c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set using the trained model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, F1 score, and support for the 'spam' class\n",
    "precision, recall, fscore, support = score(\n",
    "    y_test,            # True labels for the test set\n",
    "    y_pred,            # Predicted labels by the model\n",
    "    pos_label='spam',  # Positive label in binary classification\n",
    "    average='binary'   # Compute metrics for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65a093ef-142c-4974-b98a-e542795d865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.59 / Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3),        # Round precision to 3 decimal places\n",
    "    round(recall, 3),           # Round recall to 3 decimal places\n",
    "    round((y_pred == y_test).sum() / len(y_pred), 3)  # Round accuracy to 3 decimal places\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91267c-1888-496b-9305-6cd3eea6a3ed",
   "metadata": {},
   "source": [
    "So our precision is 100%, our recall is 52%, and then our accuracy is 93.6%. So just as a reminder of what that actually means in the context of a spam filter, **100% precision**, what that actually means is that when the model identified something as spam, it actually was spam 100% of the time. So that's great. The **52% recall** means that of all the spam that has come into your email, 52% of that spam was properly placed in the spam folder, which means that the other 48% went into your inbox, so that's not great. And lastly, the **93.6%** accuracy just means that of all the emails that came into your email, spam or non-spam, they were identified correctly as one or the other, 93.6% of the time. \n",
    "\n",
    "So in summary, the amount of spam still making it to our inbox, tells us that our model's not quite aggressive enough in identifying spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737f356-dda3-48f9-86d9-d908166e6830",
   "metadata": {},
   "source": [
    "### Explore RandomForestClassifier with grid-search\n",
    "\n",
    "**Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model.\n",
    "\n",
    "Grid-search basically means defining a grid of hyperparameter settings, and then exploring a model fit with each combination of those hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1c2d4fb-0307-435f-9ac4-253005e3b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "741942aa-24da-45fb-9ef7-bf3467b11c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators = n_est, \n",
    "                                max_depth = depth,\n",
    "                                n_jobs = -1)\n",
    "    \n",
    "    rf_model = rf.fit(X_train,y_train)   # Fit the model on the training data\n",
    "    y_pred = rf_model.predict(X_test)    # Predict the labels for the test data\n",
    "    precision, recall, fscore, support = score(\n",
    "                                                y_test,            # True labels for the test set\n",
    "                                                y_pred,            # Predicted labels by the model\n",
    "                                                pos_label='spam',  # Positive label in binary classification\n",
    "                                                average='binary'   # Compute metrics for binary classification\n",
    "                                                )\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                                                    n_est,\n",
    "                                                                                    depth,\n",
    "                                                                                    round(precision, 3),\n",
    "                                                                                    round(recall, 3),\n",
    "                                                                                    round((y_pred == y_test).sum() / len(y_pred), 3)\n",
    "                                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f195548-362b-41b0-85c1-f6658c9d0222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Est: 10 / Depth: 10 ---- Precision: 1.0 / Recall: 0.245 / Accuracy: 0.906\n",
      "Est: 10 / Depth: 20 ---- Precision: 1.0 / Recall: 0.568 / Accuracy: 0.946\n",
      "Est: 10 / Depth: 30 ---- Precision: 1.0 / Recall: 0.64 / Accuracy: 0.955\n",
      "Est: 10 / Depth: None ---- Precision: 0.981 / Recall: 0.741 / Accuracy: 0.966\n",
      "\n",
      "Est: 50 / Depth: 10 ---- Precision: 1.0 / Recall: 0.187 / Accuracy: 0.899\n",
      "Est: 50 / Depth: 20 ---- Precision: 1.0 / Recall: 0.59 / Accuracy: 0.949\n",
      "Est: 50 / Depth: 30 ---- Precision: 1.0 / Recall: 0.712 / Accuracy: 0.964\n",
      "Est: 50 / Depth: None ---- Precision: 0.991 / Recall: 0.763 / Accuracy: 0.969\n",
      "\n",
      "Est: 100 / Depth: 10 ---- Precision: 1.0 / Recall: 0.201 / Accuracy: 0.9\n",
      "Est: 100 / Depth: 20 ---- Precision: 1.0 / Recall: 0.583 / Accuracy: 0.948\n",
      "Est: 100 / Depth: 30 ---- Precision: 1.0 / Recall: 0.676 / Accuracy: 0.96\n",
      "Est: 100 / Depth: None ---- Precision: 0.991 / Recall: 0.777 / Accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    print()\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f862af2c-447d-472a-beb8-241fb2245fb2",
   "metadata": {},
   "source": [
    " So in this example, as the depth increases from 10, to 20, to 30, and eventually to none, the recall increases quite drastically, while you see the precision doesn't really drop. So the model is getting much better and more aggressive as the depth increases.\n",
    "\n",
    "If **max_depth** is set to *None*, it means that the trees in the forest are allowed to grow until they contain only one sample per leaf, or until other stopping criteria are met (like the minimum number of samples required to split a node)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93978a-b497-4f64-8ca9-87135388fdbb",
   "metadata": {},
   "source": [
    "# Evaluate Random Forest with GridSearchCV\n",
    "\n",
    "**Cross-validation:** Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used as the houdout set in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "954f0196-0d0c-4ec1-8514-60d158328711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing both vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([\n",
    "                        data['body_len'],\n",
    "                        data['punct%'],\n",
    "                        pd.DataFrame(X_tfidf.toarray())\n",
    "                         ], axis=1)\n",
    "X_tfidf_feat.columns = X_tfidf_feat.columns.astype(str)    # Ensure all column names are strings\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([\n",
    "                        data['body_len'],\n",
    "                        data['punct%'],\n",
    "                        pd.DataFrame(X_count.toarray())\n",
    "                         ], axis=1) \n",
    "X_count_feat.columns = X_count_feat.columns.astype(str)   # Convert all column names to strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac508d-d465-4530-9091-6d55fbbe6a5a",
   "metadata": {},
   "source": [
    "We're doing this because this framework will allow us to test which of these vectorizing frameworks works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a1cae03-784d-4623-9e03-3db546f49513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  8094  8095  \\\n",
       "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8c26041-11d2-4ac3-98ef-949b2a7ee030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8094  8095  8096  8097  \\\n",
       "0       128     4.7  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1        49     4.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2        62     3.2  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        28     7.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4       135     4.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8098  8099  8100  8101  8102  8103  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af1203-4cb6-4c2d-bc22-5a4fb616458d",
   "metadata": {},
   "source": [
    "### Exploring parameter settings using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe547c2f-af47-480c-b423-84e2b2cb6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da0e6b59-6038-4006-9207-b0e0b5805523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.430931</td>\n",
       "      <td>1.009646</td>\n",
       "      <td>0.164938</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.975210</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.792181</td>\n",
       "      <td>2.527809</td>\n",
       "      <td>0.242927</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.974492</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.188715</td>\n",
       "      <td>2.284023</td>\n",
       "      <td>0.193822</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.973234</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.145766</td>\n",
       "      <td>1.061390</td>\n",
       "      <td>0.163194</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.627508</td>\n",
       "      <td>2.001571</td>\n",
       "      <td>0.203472</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.971797</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10      18.430931      1.009646         0.164938        0.014989   \n",
       "7       16.792181      2.527809         0.242927        0.101100   \n",
       "8       26.188715      2.284023         0.193822        0.013693   \n",
       "11      22.145766      1.061390         0.163194        0.021852   \n",
       "5       22.627508      2.001571         0.203472        0.018780   \n",
       "\n",
       "   param_max_depth  param_n_estimators  \\\n",
       "10            None                 150   \n",
       "7               90                 150   \n",
       "8               90                 300   \n",
       "11            None                 300   \n",
       "5               60                 300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.977558   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.978456   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.976661   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.976661   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.974865   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.978456           0.974843           0.969452   \n",
       "7            0.975763           0.973046           0.969452   \n",
       "8            0.978456           0.973046           0.966757   \n",
       "11           0.973968           0.974843           0.967655   \n",
       "5            0.974865           0.972147           0.965858   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10           0.975741         0.975210        0.003150                1  \n",
       "7            0.975741         0.974492        0.003046                2  \n",
       "8            0.971249         0.973234        0.004122                3  \n",
       "11           0.970350         0.972695        0.003251                4  \n",
       "5            0.971249         0.971797        0.003302                5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a basic RandomForestClassifier model -------------- TF-IDF\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define a dictionary with hyperparameters to tune:\n",
    "param = {'n_estimators': [10, 150, 300],   # number of trees in the forest.\n",
    "         'max_depth': [30, 60, 90, None]}  # maximum depth of each tree. 'None' means nodes are expanded until all leaves are pure\n",
    "\n",
    "# Initialize GridSearchCV with the following parameters:\n",
    "gs = GridSearchCV(\n",
    "                 rf,             # The model to be tuned   \n",
    "                 param,          # The grid of hyperparameters\n",
    "                 cv=5,           # 5-fold cross-validation\n",
    "                 n_jobs=-1       # Use all available cores for parallel processing\n",
    "                 )\n",
    "\n",
    "# Fit the GridSearchCV object to the data to find the best combination of parameters\n",
    "gs_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "\n",
    "# Convert the results of GridSearchCV into a DataFrame\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',    # Sort by 'mean_test_score' in descending order to find the best-performing models\n",
    "                                             ascending=False)[0:5] # Display the top 5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0501b-f94c-4d80-bffb-757b24944b59",
   "metadata": {},
   "source": [
    "So, **mean_fit_time** is the average time it takes each model to fit, **mean_score_time** is the average amount of time it takes each model to make a prediction on the test set, **mean_test_score** is the average accuracy on the test set, and then **mean_train_score** is the average accuracy on the training set. So in terms of parameter combinations, you'll notice that the best performing models are the ones with the deepest individual decision trees. So we have max_depth to 90, no max_depth, no max_depth, and max_depth to 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d24a2ff7-4605-493f-bbb1-4f5b21da1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.137917</td>\n",
       "      <td>0.779453</td>\n",
       "      <td>0.250272</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.097979</td>\n",
       "      <td>1.099049</td>\n",
       "      <td>0.195794</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21.483924</td>\n",
       "      <td>0.445812</td>\n",
       "      <td>0.160418</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.923720</td>\n",
       "      <td>0.258614</td>\n",
       "      <td>0.208501</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.971977</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.055342</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>0.134441</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.970719</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       16.137917      0.779453         0.250272        0.085463   \n",
       "10      16.097979      1.099049         0.195794        0.020500   \n",
       "11      21.483924      0.445812         0.160418        0.019236   \n",
       "8       26.923720      0.258614         0.208501        0.020290   \n",
       "3        2.055342      0.032410         0.134441        0.012076   \n",
       "\n",
       "   param_max_depth  param_n_estimators  \\\n",
       "7               90                 150   \n",
       "10            None                 150   \n",
       "11            None                 300   \n",
       "8               90                 300   \n",
       "3               60                  10   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.976661   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.977558   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.975763   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.976661   \n",
       "3      {'max_depth': 60, 'n_estimators': 10}           0.975763   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.972172           0.975741           0.967655   \n",
       "10           0.973070           0.972147           0.965858   \n",
       "11           0.975763           0.973944           0.967655   \n",
       "8            0.973070           0.973046           0.966757   \n",
       "3            0.973070           0.969452           0.965858   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.970350         0.972516        0.003347                1  \n",
       "10           0.973046         0.972336        0.003750                2  \n",
       "11           0.968553         0.972336        0.003530                3  \n",
       "8            0.970350         0.971977        0.003292                4  \n",
       "3            0.969452         0.970719        0.003400                5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a basic RandomForestClassifier model -------------- CountVectorizer\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define a dictionary with hyperparameters to tune:\n",
    "param = {'n_estimators': [10, 150, 300],   # number of trees in the forest.\n",
    "         'max_depth': [30, 60, 90, None]}  # maximum depth of each tree. 'None' means nodes are expanded until all leaves are pure\n",
    "\n",
    "# Initialize GridSearchCV with the following parameters:\n",
    "gs = GridSearchCV(\n",
    "                 rf,             # The model to be tuned   \n",
    "                 param,          # The grid of hyperparameters\n",
    "                 cv=5,           # 5-fold cross-validation\n",
    "                 n_jobs=-1       # Use all available cores for parallel processing\n",
    "                 )\n",
    "\n",
    "# Fit the GridSearchCV object to the data to find the best combination of parameters\n",
    "gs_fit = gs.fit(X_count_feat, data['label'])\n",
    "\n",
    "# Convert the results of GridSearchCV into a DataFrame\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',    # Sort by 'mean_test_score' in descending order to find the best-performing models\n",
    "                                             ascending=False)[0:5] # Display the top 5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bf664-b86d-4db6-9e0c-115bd2768f52",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5e5ec-5d19-4c5e-963b-c4a496de0121",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/rfandgb.png\" width=\"900\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1e763-166b-4cf0-a971-60e5d13cd939",
   "metadata": {},
   "source": [
    "So with that, why would you go with gradient boosting? Well, **the trade off is that gradient boosting is typically more powerful and better-performing if tuned properly**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7d6102-b2bd-472d-934c-3e2788006c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "2   ham  Even my brother is not like to speak with me. ...\n",
       "3   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "4   ham  As per your request 'Melle Melle (Oru Minnamin..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"data/SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8749895-caf4-4a7f-b4ab-bb4128181d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  body_len  punct%\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7\n",
       "1   ham  Nah I don't think he goes to usf, he lives aro...        49     4.1\n",
       "2   ham  Even my brother is not like to speak with me. ...        62     3.2\n",
       "3   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        28     7.1\n",
       "4   ham  As per your request 'Melle Melle (Oru Minnamin...       135     4.4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b33b5dbc-af26-44e6-96ed-50d34a5ce748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtoriu</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%         0  008704050406  0089mi  0121  01223585236  \\\n",
       "0       128     4.7  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "1        49     4.1  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "2        62     3.2  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "3        28     7.1  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "4       135     4.4  0.0  0.0           0.0     0.0   0.0          0.0   \n",
       "\n",
       "   01223585334  0125698789  ...  zindgi  zoe  zogtoriu  zoom  zouk  zyada  \\\n",
       "0          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "1          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "2          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "3          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "4          0.0         0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "\n",
       "     é    ü  üll  〨ud  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# Initialize TfidfVectorizer with the custom analyzer\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "# Create the DataFrame with additional features\n",
    "X_features = pd.concat([\n",
    "    data['body_len'],\n",
    "    data['punct%'],\n",
    "    pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vect.get_feature_names_out())\n",
    "], axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b3a14-f934-4c6a-87f1-085398face31",
   "metadata": {},
   "source": [
    "### Explore GradientBoostingClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12574f22-8590-4404-b775-eef7f0284569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65b2cf9a-011c-4774-b2d7-3f22630ed53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__sklearn_clone__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_build_request_for_signature', '_check_feature_names', '_check_initialized', '_check_n_features', '_clear_state', '_compute_partial_dependence_recursion', '_doc_link_module', '_doc_link_template', '_doc_link_url_param_generator', '_encode_y', '_estimator_type', '_fit_stage', '_fit_stages', '_get_default_requests', '_get_doc_link', '_get_loss', '_get_metadata_request', '_get_param_names', '_get_tags', '_init_state', '_is_fitted', '_make_estimator', '_more_tags', '_parameter_constraints', '_raw_predict', '_raw_predict_init', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_resize_state', '_set_max_features', '_staged_raw_predict', '_validate_data', '_validate_estimator', '_validate_params', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_metadata_routing', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_fit_request', 'set_params', 'set_score_request', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n",
      "\n",
      "GradientBoostingClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))\n",
    "print()\n",
    "print(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f523f-8c87-4da7-89fd-b717909a9de0",
   "metadata": {},
   "source": [
    "### Build our own Grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddca68a6-f759-45a2-94b0-ed97452b9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2943e46-a33d-44d7-91a6-a5bb22a8ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6ae8349-8e1e-4a0b-a1bc-ae6cc86e00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    \n",
    "    # Initialize the Gradient Boosting Classifier with the given parameters\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators = est,     # Number of boosting stages\n",
    "        max_depth = max_depth,  # Maximum depth of the individual trees\n",
    "        learning_rate = lr      # Learning rate shrinks the contribution of each tree\n",
    "    )\n",
    "    gb_model = gb.fit(X_train, y_train)  # Fit the model to the training data\n",
    "    \n",
    "    y_pred = gb_model.predict(X_test)    # Predict the labels for the test data\n",
    "\n",
    "    precision, recall, fscore, support = score(\n",
    "                                                y_test,            # True labels for the test set\n",
    "                                                y_pred,            # Predicted labels by the model\n",
    "                                                pos_label='spam',  # Positive label in binary classification\n",
    "                                                average='binary'   # Compute metrics for binary classification\n",
    "                                                )\n",
    "    print('Est: {} / Depth: {} / LR: {}---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                                                    est,\n",
    "                                                                                    max_depth,\n",
    "                                                                                    lr,\n",
    "                                                                                    round(precision, 3),\n",
    "                                                                                    round(recall, 3),\n",
    "                                                                                    round((y_pred == y_test).sum() / len(y_pred), 3)\n",
    "                                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d86455c2-f57d-4fd9-91ff-bb336251e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Est: 50 / Depth: 3 / LR: 0.01---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.863\n",
      "Est: 50 / Depth: 3 / LR: 0.1---- Precision: 0.972 / Recall: 0.673 / Accuracy: 0.952\n",
      "Est: 50 / Depth: 3 / LR: 1---- Precision: 0.852 / Recall: 0.791 / Accuracy: 0.952\n",
      "Est: 50 / Depth: 7 / LR: 0.01---- Precision: 1.0 / Recall: 0.02 / Accuracy: 0.865\n",
      "Est: 50 / Depth: 7 / LR: 0.1---- Precision: 0.913 / Recall: 0.758 / Accuracy: 0.957\n",
      "Est: 50 / Depth: 7 / LR: 1---- Precision: 0.892 / Recall: 0.81 / Accuracy: 0.961\n",
      "Est: 50 / Depth: 11 / LR: 0.01---- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.864\n",
      "Est: 50 / Depth: 11 / LR: 0.1---- Precision: 0.926 / Recall: 0.732 / Accuracy: 0.955\n",
      "Est: 50 / Depth: 11 / LR: 1---- Precision: 0.917 / Recall: 0.791 / Accuracy: 0.961\n",
      "Est: 50 / Depth: 15 / LR: 0.01---- Precision: 1.0 / Recall: 0.013 / Accuracy: 0.864\n",
      "Est: 50 / Depth: 15 / LR: 0.1---- Precision: 0.911 / Recall: 0.739 / Accuracy: 0.954\n",
      "Est: 50 / Depth: 15 / LR: 1---- Precision: 0.938 / Recall: 0.791 / Accuracy: 0.964\n",
      "\n",
      "Est: 100 / Depth: 3 / LR: 0.01---- Precision: 0.988 / Recall: 0.523 / Accuracy: 0.934\n",
      "Est: 100 / Depth: 3 / LR: 0.1---- Precision: 0.983 / Recall: 0.771 / Accuracy: 0.967\n",
      "Est: 100 / Depth: 3 / LR: 1---- Precision: 0.916 / Recall: 0.784 / Accuracy: 0.961\n",
      "Est: 100 / Depth: 7 / LR: 0.01---- Precision: 0.947 / Recall: 0.582 / Accuracy: 0.938\n",
      "Est: 100 / Depth: 7 / LR: 0.1---- Precision: 0.931 / Recall: 0.791 / Accuracy: 0.963\n",
      "Est: 100 / Depth: 7 / LR: 1---- Precision: 0.947 / Recall: 0.81 / Accuracy: 0.968\n",
      "Est: 100 / Depth: 11 / LR: 0.01---- Precision: 0.952 / Recall: 0.654 / Accuracy: 0.948\n",
      "Est: 100 / Depth: 11 / LR: 0.1---- Precision: 0.913 / Recall: 0.752 / Accuracy: 0.956\n",
      "Est: 100 / Depth: 11 / LR: 1---- Precision: 0.976 / Recall: 0.797 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 15 / LR: 0.01---- Precision: 0.937 / Recall: 0.68 / Accuracy: 0.95\n",
      "Est: 100 / Depth: 15 / LR: 0.1---- Precision: 0.908 / Recall: 0.778 / Accuracy: 0.959\n",
      "Est: 100 / Depth: 15 / LR: 1---- Precision: 0.968 / Recall: 0.784 / Accuracy: 0.967\n",
      "\n",
      "Est: 150 / Depth: 3 / LR: 0.01---- Precision: 0.976 / Recall: 0.536 / Accuracy: 0.934\n",
      "Est: 150 / Depth: 3 / LR: 0.1---- Precision: 0.984 / Recall: 0.791 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 3 / LR: 1---- Precision: 0.935 / Recall: 0.752 / Accuracy: 0.959\n",
      "Est: 150 / Depth: 7 / LR: 0.01---- Precision: 0.929 / Recall: 0.595 / Accuracy: 0.938\n",
      "Est: 150 / Depth: 7 / LR: 0.1---- Precision: 0.946 / Recall: 0.804 / Accuracy: 0.967\n",
      "Est: 150 / Depth: 7 / LR: 1---- Precision: 0.938 / Recall: 0.797 / Accuracy: 0.965\n",
      "Est: 150 / Depth: 11 / LR: 0.01---- Precision: 0.937 / Recall: 0.68 / Accuracy: 0.95\n",
      "Est: 150 / Depth: 11 / LR: 0.1---- Precision: 0.924 / Recall: 0.791 / Accuracy: 0.962\n",
      "Est: 150 / Depth: 11 / LR: 1---- Precision: 0.967 / Recall: 0.778 / Accuracy: 0.966\n",
      "Est: 150 / Depth: 15 / LR: 0.01---- Precision: 0.922 / Recall: 0.693 / Accuracy: 0.95\n",
      "Est: 150 / Depth: 15 / LR: 0.1---- Precision: 0.929 / Recall: 0.771 / Accuracy: 0.961\n",
      "Est: 150 / Depth: 15 / LR: 1---- Precision: 0.924 / Recall: 0.797 / Accuracy: 0.963\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:                  # Loop over different values for the number of estimators\n",
    "    print()\n",
    "    for max_depth in [3, 7, 11, 15]:          # Loop over different values for the maximum depth of the trees\n",
    "        for lr in [0.01, 0.1, 1]:             # Loop over different learning rates\n",
    "            train_GB(n_est, max_depth, lr)    # Call the function to train the Gradient Boosting model with the current parameters\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8fdab-d77f-4f44-9c94-d4fe0ed913fa",
   "metadata": {},
   "source": [
    "Let's take a look at some of the best models. Based on the results here, all of the best models had a learning rate of 0.1. Now we can draw that distinction, that that instruction to the model, of whether the learning rate is 0.01, or it's 0.1, is making a big difference in terms of the results of the model. For this problem, it appears that this learning rate of 0.1 is ideal. You'll also note that the estimators and the max depth are on the high end of the ranges that we tested out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9cbfc-0d66-49c8-a80a-4c4c78a7c8e8",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Evaluate Gradient Boosting with GridSearchCV\n",
    "\n",
    "**Cross-validation:** Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used as the houdout set in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4968145b-b0c2-4961-b72d-fa9979f133b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8094  8095  8096  8097  \\\n",
       "0       128     4.7  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1        49     4.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2        62     3.2  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        28     7.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4       135     4.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8098  8099  8100  8101  8102  8103  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"data/SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "# --------------------------------------------\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "# --------------------------------------------\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([\n",
    "                        data['body_len'],\n",
    "                        data['punct%'],\n",
    "                        pd.DataFrame(X_tfidf.toarray())\n",
    "                         ], axis=1)\n",
    "X_tfidf_feat.columns = X_tfidf_feat.columns.astype(str)    # Ensure all column names are strings\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([\n",
    "                        data['body_len'],\n",
    "                        data['punct%'],\n",
    "                        pd.DataFrame(X_count.toarray())\n",
    "                         ], axis=1) \n",
    "\n",
    "X_count_feat.columns = X_count_feat.columns.astype(str)   # Convert all column names to strings\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057a5d3-c9c4-456a-aefb-bb466850bf74",
   "metadata": {},
   "source": [
    "#### Exploring parameter settings using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee6da61d-c1e8-424a-a39f-b6b9ad05cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "039a3247-badb-4b68-8bb0-90eccf1ed50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>205.296830</td>\n",
       "      <td>0.991675</td>\n",
       "      <td>0.117536</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.969822</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.940286</td>\n",
       "      <td>0.836431</td>\n",
       "      <td>0.197344</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.969821</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244.594679</td>\n",
       "      <td>1.019254</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.969642</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.311198</td>\n",
       "      <td>0.752044</td>\n",
       "      <td>0.294007</td>\n",
       "      <td>0.077784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.961400</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.968744</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176.769086</td>\n",
       "      <td>1.053062</td>\n",
       "      <td>0.161939</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964093</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.968744</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5     205.296830      0.991675         0.117536        0.007667   \n",
       "1     173.940286      0.836431         0.197344        0.029401   \n",
       "3     244.594679      1.019254         0.188327        0.010996   \n",
       "0     112.311198      0.752044         0.294007        0.077784   \n",
       "4     176.769086      1.053062         0.161939        0.021501   \n",
       "\n",
       "   param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "5                  0.1               15                 150   \n",
       "1                  0.1                7                 150   \n",
       "3                  0.1               11                 150   \n",
       "0                  0.1                7                 100   \n",
       "4                  0.1               15                 100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964991   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.964991   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.964991   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.961400   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964093   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.976661           0.971249           0.969452           0.966757   \n",
       "1           0.979354           0.971249           0.966757           0.966757   \n",
       "3           0.979354           0.967655           0.968553           0.967655   \n",
       "0           0.978456           0.971249           0.964061           0.968553   \n",
       "4           0.975763           0.969452           0.965858           0.968553   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.969822        0.004042                1  \n",
       "1         0.969821        0.005197                2  \n",
       "3         0.969642        0.005001                3  \n",
       "0         0.968744        0.005941                4  \n",
       "4         0.968744        0.003994                4  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],  # Number of boosting stages\n",
    "    'max_depth' : [7, 11, 15],   # Maximum depth of the individual trees\n",
    "    'learning_rate' : [0.1]      # The default is 0.1, so it's optional\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the following parameters:\n",
    "gs = GridSearchCV(\n",
    "                 gb,             # The model to be tuned   \n",
    "                 param,          # The grid of hyperparameters\n",
    "                 cv=5,           # 5-fold cross-validation\n",
    "                 n_jobs=-1       # We'll train models on different subsets and parameter settings in parallel\n",
    "                 )\n",
    "\n",
    "# Fit the GridSearchCV object to the data to find the best combination of parameters\n",
    "cv_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "\n",
    "# Convert the results of GridSearchCV into a DataFrame\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score',    # Sort by 'mean_test_score' in descending order to find the best-performing models\n",
    "                                             ascending=False)[0:5] # Display the top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7313bea-83fb-4da1-9d65-4b7ff306b088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>196.260656</td>\n",
       "      <td>1.235784</td>\n",
       "      <td>0.119621</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.963196</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.969822</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236.492360</td>\n",
       "      <td>1.770359</td>\n",
       "      <td>0.204376</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.964093</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.969642</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166.323526</td>\n",
       "      <td>2.198403</td>\n",
       "      <td>0.220619</td>\n",
       "      <td>0.039965</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.968923</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.776075</td>\n",
       "      <td>0.748790</td>\n",
       "      <td>0.176183</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.963196</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.968744</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.778714</td>\n",
       "      <td>1.437996</td>\n",
       "      <td>0.241345</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.968205</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5     196.260656      1.235784         0.119621        0.009106   \n",
       "3     236.492360      1.770359         0.204376        0.023957   \n",
       "1     166.323526      2.198403         0.220619        0.039965   \n",
       "4     172.776075      0.748790         0.176183        0.017083   \n",
       "2     162.778714      1.437996         0.241345        0.054011   \n",
       "\n",
       "   param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "5                  0.1               15                 150   \n",
       "3                  0.1               11                 150   \n",
       "1                  0.1                7                 150   \n",
       "4                  0.1               15                 100   \n",
       "2                  0.1               11                 100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.963196   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.964093   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.964991   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.963196   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.964991   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.979354           0.968553           0.966757           0.971249   \n",
       "3           0.977558           0.970350           0.964960           0.971249   \n",
       "1           0.979354           0.967655           0.964960           0.967655   \n",
       "4           0.975763           0.966757           0.966757           0.971249   \n",
       "2           0.975763           0.966757           0.964061           0.969452   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.969822        0.005437                1  \n",
       "3         0.969642        0.004868                2  \n",
       "1         0.968923        0.005351                3  \n",
       "4         0.968744        0.004341                4  \n",
       "2         0.968205        0.004202                5  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],  # Number of boosting stages\n",
    "    'max_depth' : [7, 11, 15],   # Maximum depth of the individual trees\n",
    "    'learning_rate' : [0.1]      # The default is 0.1, so it's optional\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the following parameters:\n",
    "gs = GridSearchCV(\n",
    "                 gb,             # The model to be tuned   \n",
    "                 param,          # The grid of hyperparameters\n",
    "                 cv=5,           # 5-fold cross-validation\n",
    "                 n_jobs=-1       # We'll train models on different subsets and parameter settings in parallel\n",
    "                 )\n",
    "\n",
    "# Fit the GridSearchCV object to the data to find the best combination of parameters\n",
    "cvc_fit = gs.fit(X_count_feat, data['label'])\n",
    "\n",
    "# Convert the results of GridSearchCV into a DataFrame\n",
    "pd.DataFrame(cvc_fit.cv_results_).sort_values('mean_test_score',    # Sort by 'mean_test_score' in descending order to find the best-performing models\n",
    "                                             ascending=False)[0:5]  # Display the top 5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01ff71-5357-4a77-8824-8c0eccae0831",
   "metadata": {},
   "source": [
    "### Model Selection: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4e5e652-0186-4c52-afde-8f267c6c2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  body_len  punct%\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7\n",
       "1   ham  Nah I don't think he goes to usf, he lives aro...        49     4.1\n",
       "2   ham  Even my brother is not like to speak with me. ...        62     3.2\n",
       "3   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        28     7.1\n",
       "4   ham  As per your request 'Melle Melle (Oru Minnamin...       135     4.4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"data/SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca3faa-adeb-4216-9b71-b3f01b482cea",
   "metadata": {},
   "source": [
    "#### Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "815e6ec0-afe1-4863-8028-0688b67f65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data first before vectorizing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['body_text', 'body_len', 'punct%']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44df1b5-e805-4534-8d83-409ae42eba24",
   "metadata": {},
   "source": [
    "#### Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f7d8a9d-a452-4352-8cb9-6395fb1bddd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7109</th>\n",
       "      <th>7110</th>\n",
       "      <th>7111</th>\n",
       "      <th>7112</th>\n",
       "      <th>7113</th>\n",
       "      <th>7114</th>\n",
       "      <th>7115</th>\n",
       "      <th>7116</th>\n",
       "      <th>7117</th>\n",
       "      <th>7118</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.355565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%         0    1    2    3    4    5    6    7  ...  7109  \\\n",
       "0       124     5.6  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1        28     3.6  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2        22    27.3  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3        20    15.0  0.355565  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4        30     3.3  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   7110  7111  7112  7113  7114  7115  7116  7117  7118  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7121 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)  # Initialize TfidfVectorizer with custom text cleaning function 'clean_text'.\n",
    "tfidf_vect = tfidf_vect.fit(X_train['body_text'])  # Fit the vectorizer on the training data to learn the vocabulary.\n",
    "\n",
    "tfidf_train = tfidf_vect.fit_transform(X_train['body_text'])  # Fit and transform the training data into TF-IDF features.\n",
    "tfidf_test = tfidf_vect.fit_transform(X_test['body_text'])    # Fit and transform the test data into TF-IDF features.\n",
    "\n",
    "X_train_vect = pd.concat([  # Combine the original features and TF-IDF features.\n",
    "                    X_train[['body_len', 'punct%']].reset_index(drop=True), # Select 'body_len' and 'punct%' columns from the training set.\n",
    "                    pd.DataFrame(tfidf_train.toarray())                     # Convert TF-IDF features to a DataFrame and combine them w/ original feat.\n",
    "                    ], axis=1)                                              # Concatenate along the columns.\n",
    "\n",
    "X_test_vect = pd.concat([  # Combine the original features and TF-IDF features.\n",
    "                    X_test[['body_len', 'punct%']].reset_index(drop=True), # Select 'body_len' and 'punct%' columns from the testing set.\n",
    "                    pd.DataFrame(tfidf_test.toarray())                     # Convert TF-IDF features to a DataFrame and combine them w/ original feat.\n",
    "                    ], axis=1)                                             # Concatenate along the columns.\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc8c11-3eef-475a-b8f6-4e358784545b",
   "metadata": {},
   "source": [
    "`tfidf_train` and `tfidf_test` will have the same number of columns because they're both transformed using this TFIDF vect underscore fit that was trained on the training set so it only recognizes words in the training set and can only create columns for words from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046da3c-0b7e-4450-8324-6d02188e6453",
   "metadata": {},
   "source": [
    "#### Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "989eea49-6946-49d1-9327-d650cc84016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d72d3a6c-6cd1-47aa-b432-3851b953c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.79 / Predict time: 0.068 ---- Precision: 1.0 / Recall: 0.838 / Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "\n",
    "# Fit and transform training data\n",
    "tfidf_train = tfidf_vect.fit_transform(X_train['body_text'])\n",
    "\n",
    "# Transform test data based on the fitted vectorizer\n",
    "tfidf_test = tfidf_vect.transform(X_test['body_text'])\n",
    "\n",
    "# Concatenate features for training and test sets\n",
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), \n",
    "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True), \n",
    "                         pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "X_train_vect.columns = X_train_vect.columns.astype(str)\n",
    "X_test_vect.columns = X_test_vect.columns.astype(str)\n",
    "\n",
    "# Initialize RandomForestClassifier with specified parameters\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,  # Number of trees in the forest\n",
    "    max_depth=None,    # Maximum depth of the trees\n",
    "    n_jobs=-1          # Number of parallel jobs to run\n",
    ")\n",
    "\n",
    "# Measure the time taken to fit the RandomForest model\n",
    "start = time.time()                       # Record the start time\n",
    "rf_model = rf.fit(X_train_vect, y_train)  # Fit the model to the training data\n",
    "end = time.time()                         # Record the end time\n",
    "fit_time = (end - start)                  # Calculate the duration of the fitting process in seconds\n",
    "\n",
    "# Measure the time taken to make predictions\n",
    "start = time.time()                      # Record the start time\n",
    "y_pred = rf_model.predict(X_test_vect)  # Predict the labels for the test set\n",
    "end = time.time()                       # Record the end time\n",
    "pred_time = (end - start)               # Calculate the duration of the prediction process in seconds\n",
    "\n",
    "# Compute evaluation metrics: precision, recall, and F1 score\n",
    "precision, recall, fscore, support = score(\n",
    "    y_test,              # True labels for the test data\n",
    "    y_pred,              # Predicted labels for the test data\n",
    "    pos_label='spam',    # Label considered as the positive class for evaluation\n",
    "    average='binary'     # Type of averaging for the metrics\n",
    ")\n",
    "\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n",
    "\n",
    "# precision: Proportion of true positive predictions among all positive predictions.\n",
    "# recall: Proportion of true positive predictions among all actual positives.\n",
    "# fscore: Harmonic mean of precision and recall, providing a single score to evaluate the model's performance.\n",
    "# train_support: Number of occurrences of each label in the test set, useful for understanding class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7531ecb-87a5-40da-beda-9193a0caf763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 95.783 / Predict time: 0.083 ---- Precision: 0.9 / Recall: 0.851 / Accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "# Initialize GradientBoostingClassifier with specified parameters\n",
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "# Measure the time taken to fit the GradientBoosting model\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)  # Fit the model to the training data\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "# Measure the time taken to make predictions\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)    # Predict the labels for the test set\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "# Compute evaluation metrics: precision, recall, and F1 score\n",
    "precision, recall, fscore, support = score(\n",
    "    y_test,              # True labels for the test data\n",
    "    y_pred,              # Predicted labels for the test data\n",
    "    pos_label='spam',    # Label considered as the positive class for evaluation\n",
    "    average='binary'     # Type of averaging for the metrics\n",
    ")\n",
    "\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n",
    "\n",
    "# precision: Proportion of true positive predictions among all positive predictions.\n",
    "# recall: Proportion of true positive predictions among all actual positives.\n",
    "# fscore: Harmonic mean of precision and recall, providing a single score to evaluate the model's performance.\n",
    "# train_support: Number of occurrences of each label in the test set, useful for understanding class distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
