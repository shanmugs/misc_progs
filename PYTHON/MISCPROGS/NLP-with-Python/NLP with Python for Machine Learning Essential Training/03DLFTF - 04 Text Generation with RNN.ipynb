{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTguFckTEDWd"
   },
   "source": [
    "# Introduction to Text generation\n",
    "\n",
    "This notebook explains how we can split a given corpus of data into features and labels and then train a neural network to predict the next word in a sentence.\n",
    "\n",
    "1. Create a corpus - break the text down to list of sentences.\n",
    "2. Create a word_index(vocabulary) from the text.\n",
    "3. Tokenize the data and create n-gram sequence for each sequence of the corpus.\n",
    "4. Pad those sequences.\n",
    "5. Segregate features from the sequences by reserving the last element of the array as labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9mW3Mt2q5kL2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "##import the required libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFhZpNjHoxSt"
   },
   "source": [
    "#### Step 1: Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CwT0yxfRgZY_"
   },
   "outputs": [],
   "source": [
    "data = \"October arrived, spreading a damp chill over the grounds and into the castle.\\n Madam Pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students.\\n Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. Ginny Weasley, who had been looking pale, was bullied into taking some by Percy.\\n The steam pouring from under her vivid hair gave the impression that her whole head was on fire.\\n Raindrops the size of bullets thundered on the castle windows for days on end; the lake rose, the flower beds turned into muddy streams, and Hagrid's pumpkins swelled to the size of garden sheds.\\n Oliver Wood's enthusiasm for regular training sessions, however, was not dampened, which was why Harry was to be found, late one stormy Saturday afternoon a few days before Halloween, returning to Gryffindor Tower, drenched to the skin and splattered with mud.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EYtWr3OAoz53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['october arrived, spreading a damp chill over the grounds and into the castle.', ' madam pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students.', ' her pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. ginny weasley, who had been looking pale, was bullied into taking some by percy.', ' the steam pouring from under her vivid hair gave the impression that her whole head was on fire.', \" raindrops the size of bullets thundered on the castle windows for days on end; the lake rose, the flower beds turned into muddy streams, and hagrid's pumpkins swelled to the size of garden sheds.\", \" oliver wood's enthusiasm for regular training sessions, however, was not dampened, which was why harry was to be found, late one stormy saturday afternoon a few days before halloween, returning to gryffindor tower, drenched to the skin and splattered with mud.\"]\n"
     ]
    }
   ],
   "source": [
    "## Instantiate the Tokenizer object\n",
    "tokenizer = Tokenizer()            # Initialize the tokenizer for text preprocessing\n",
    "\n",
    "## Create a corpus by converting text to lowercase and splitting by newline characters\n",
    "corpus = data.lower().split(\"\\n\")  # Convert text to lowercase and split into individual lines\n",
    "print(corpus)                      # Print the corpus to check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ce_7Op3eHPS"
   },
   "source": [
    "#### Step 2: Train the tokenizer and create word encoding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aAoHN0Ar01tt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'was': 2, 'and': 3, 'to': 4, 'a': 5, 'into': 6, 'of': 7, 'her': 8, 'for': 9, 'on': 10, 'castle': 11, 'by': 12, 'size': 13, 'days': 14, 'october': 15, 'arrived': 16, 'spreading': 17, 'damp': 18, 'chill': 19, 'over': 20, 'grounds': 21, 'madam': 22, 'pomfrey': 23, 'nurse': 24, 'kept': 25, 'busy': 26, 'sudden': 27, 'spate': 28, 'colds': 29, 'among': 30, 'staff': 31, 'students': 32, 'pepperup': 33, 'potion': 34, 'worked': 35, 'instantly': 36, 'though': 37, 'it': 38, 'left': 39, 'drinker': 40, 'smoking': 41, 'at': 42, 'ears': 43, 'several': 44, 'hours': 45, 'afterward': 46, 'ginny': 47, 'weasley': 48, 'who': 49, 'had': 50, 'been': 51, 'looking': 52, 'pale': 53, 'bullied': 54, 'taking': 55, 'some': 56, 'percy': 57, 'steam': 58, 'pouring': 59, 'from': 60, 'under': 61, 'vivid': 62, 'hair': 63, 'gave': 64, 'impression': 65, 'that': 66, 'whole': 67, 'head': 68, 'fire': 69, 'raindrops': 70, 'bullets': 71, 'thundered': 72, 'windows': 73, 'end': 74, 'lake': 75, 'rose': 76, 'flower': 77, 'beds': 78, 'turned': 79, 'muddy': 80, 'streams': 81, \"hagrid's\": 82, 'pumpkins': 83, 'swelled': 84, 'garden': 85, 'sheds': 86, 'oliver': 87, \"wood's\": 88, 'enthusiasm': 89, 'regular': 90, 'training': 91, 'sessions': 92, 'however': 93, 'not': 94, 'dampened': 95, 'which': 96, 'why': 97, 'harry': 98, 'be': 99, 'found': 100, 'late': 101, 'one': 102, 'stormy': 103, 'saturday': 104, 'afternoon': 105, 'few': 106, 'before': 107, 'halloween': 108, 'returning': 109, 'gryffindor': 110, 'tower': 111, 'drenched': 112, 'skin': 113, 'splattered': 114, 'with': 115, 'mud': 116}\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "## Fit the tokenizer on the corpus to build the word index\n",
    "tokenizer.fit_on_texts(corpus)              # Tokenize the text data to build the vocabulary\n",
    "\n",
    "## Calculate the vocabulary size, adding 1 for the padding token\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Include an extra token for padding\n",
    "\n",
    "print(tokenizer.word_index)  # Print the word index mapping words to their token ids\n",
    "print(vocab_size)            # Print the total vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t0633pzeA5y"
   },
   "source": [
    "#### Step 3: Create N-gram sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/ngram.png\" width=\"500\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3uEYLlk8ra-O"
   },
   "outputs": [],
   "source": [
    "# Create n-gram sequences of each text sequence\n",
    "input_sequences = []                                 # Initialize an empty list to store n-gram sequences\n",
    "for line in corpus:                                  # Iterate over each line in the corpus\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0] # Convert the line into a sequence of tokens using the tokenizer\n",
    "    for i in range(1, len(tokens)):                  # Iterate through the token sequence to create n-grams\n",
    "        n_gram_sequence = tokens[:i+1]               # Create an n-gram sequence from the beginning up to the current token index\n",
    "        input_sequences.append(n_gram_sequence)      # Append the n-gram sequence to the list of input sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Pad those sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1zzrLngux8Bd"
   },
   "outputs": [],
   "source": [
    "## Calculate the maximum sequence length from the input sequences\n",
    "max_seq_len = max([len(i) for i in input_sequences])  # Find the length of the longest sequence in the list\n",
    "\n",
    "## Pad all sequences to the same length\n",
    "input_seq_array = np.array(pad_sequences(             # Convert padded sequences into a numpy array\n",
    "    input_sequences,                                  # List of n-gram sequences to pad\n",
    "    maxlen=max_seq_len,                               # Specify the maximum length for padding\n",
    "    padding='pre'                                     # Pad sequences at the beginning\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJiCqSqYeQDM"
   },
   "source": [
    "#### Step 5: Segregate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/extra.png\" width=\"800\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tTGbnKtG1zqD"
   },
   "outputs": [],
   "source": [
    "## Creating features (X) and labels (y)\n",
    "X = input_seq_array[:, :-1]      # Features: all tokens except the last one in each sequence\n",
    "labels = input_seq_array[:, -1]  # Labels: only the last token in each sequence\n",
    "\n",
    "## One-hot encode the labels to get y\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)  # Convert labels to one-hot encoding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3X_GvVM22Wsm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['mud'])  # Print the index of the word 'mud' from the tokenizer's word index\n",
    "print()\n",
    "print(X[0])                         # Print the first sequence of features (X) to inspect the token values\n",
    "print()\n",
    "print(y[0])                         # Print the one-hot encoded label for the first sequence to verify the encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFLkSjPoeg-B"
   },
   "source": [
    "#### Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "95bU1pLN5c0s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 2s 8ms/step - loss: 4.7614 - accuracy: 0.0067\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.7497 - accuracy: 0.0933\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.7388 - accuracy: 0.0867\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.7247 - accuracy: 0.0867\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.7028 - accuracy: 0.0867\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6621 - accuracy: 0.0867\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5979 - accuracy: 0.0867\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5500 - accuracy: 0.0867\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5192 - accuracy: 0.0867\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4837 - accuracy: 0.0867\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.4532 - accuracy: 0.0867\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4232 - accuracy: 0.0867\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3913 - accuracy: 0.0867\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.3607 - accuracy: 0.0867\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3218 - accuracy: 0.0867\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2874 - accuracy: 0.0933\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2513 - accuracy: 0.0933\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2165 - accuracy: 0.0867\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.1797 - accuracy: 0.0867\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.1415 - accuracy: 0.0867\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.1050 - accuracy: 0.0867\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0683 - accuracy: 0.0867\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.0284 - accuracy: 0.0800\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.9893 - accuracy: 0.0933\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.9483 - accuracy: 0.0933\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.9138 - accuracy: 0.0867\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.8691 - accuracy: 0.0867\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.8240 - accuracy: 0.1000\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.7860 - accuracy: 0.1133\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.7415 - accuracy: 0.1200\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7054 - accuracy: 0.1333\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.6585 - accuracy: 0.1333\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.6213 - accuracy: 0.1400\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.5765 - accuracy: 0.1467\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.5339 - accuracy: 0.1333\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.4907 - accuracy: 0.1400\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4518 - accuracy: 0.1467\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4085 - accuracy: 0.1400\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3692 - accuracy: 0.1533\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3242 - accuracy: 0.1733\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3032 - accuracy: 0.1600\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2504 - accuracy: 0.1667\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2164 - accuracy: 0.1733\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.1730 - accuracy: 0.1933\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1395 - accuracy: 0.1800\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1125 - accuracy: 0.2133\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0635 - accuracy: 0.2067\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0285 - accuracy: 0.2267\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9871 - accuracy: 0.2533\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9560 - accuracy: 0.2267\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9186 - accuracy: 0.2333\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8846 - accuracy: 0.2533\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8472 - accuracy: 0.2467\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8164 - accuracy: 0.2667\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7806 - accuracy: 0.2733\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7497 - accuracy: 0.2867\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7189 - accuracy: 0.2733\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6823 - accuracy: 0.2733\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6606 - accuracy: 0.2867\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.6232 - accuracy: 0.2933\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6027 - accuracy: 0.2867\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5766 - accuracy: 0.3200\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5422 - accuracy: 0.3067\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5208 - accuracy: 0.3200\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5060 - accuracy: 0.3333\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4840 - accuracy: 0.3267\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4533 - accuracy: 0.3600\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.4261 - accuracy: 0.3400\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4012 - accuracy: 0.3533\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.3662 - accuracy: 0.3667\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3386 - accuracy: 0.3533\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3173 - accuracy: 0.3733\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3024 - accuracy: 0.3533\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2882 - accuracy: 0.3667\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.2644 - accuracy: 0.3667\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2480 - accuracy: 0.3800\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2080 - accuracy: 0.4067\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1883 - accuracy: 0.4200\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.1655 - accuracy: 0.4333\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1465 - accuracy: 0.4533\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1279 - accuracy: 0.4533\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1149 - accuracy: 0.4600\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0894 - accuracy: 0.4533\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0650 - accuracy: 0.4933\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0477 - accuracy: 0.4600\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0271 - accuracy: 0.4800\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0109 - accuracy: 0.5400\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9955 - accuracy: 0.5267\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9807 - accuracy: 0.5733\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9504 - accuracy: 0.5933\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9343 - accuracy: 0.6000\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9181 - accuracy: 0.5867\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9007 - accuracy: 0.6000\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8897 - accuracy: 0.6067\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.8724 - accuracy: 0.6267\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8599 - accuracy: 0.6200\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.8428 - accuracy: 0.6400\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8267 - accuracy: 0.6533\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7929 - accuracy: 0.6800\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7659 - accuracy: 0.6867\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7494 - accuracy: 0.7200\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7328 - accuracy: 0.7200\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7088 - accuracy: 0.7600\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6934 - accuracy: 0.7600\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6784 - accuracy: 0.7267\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6598 - accuracy: 0.7667\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6449 - accuracy: 0.7400\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6330 - accuracy: 0.7600\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6090 - accuracy: 0.7867\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5963 - accuracy: 0.8000\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5930 - accuracy: 0.8133\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5976 - accuracy: 0.7867\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6534 - accuracy: 0.6800\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6454 - accuracy: 0.7400\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6113 - accuracy: 0.7133\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5608 - accuracy: 0.8000\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5349 - accuracy: 0.8067\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5123 - accuracy: 0.8400\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4896 - accuracy: 0.8533\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4766 - accuracy: 0.8600\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4585 - accuracy: 0.8933\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4437 - accuracy: 0.8733\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4275 - accuracy: 0.9067\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4104 - accuracy: 0.8800\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4020 - accuracy: 0.8933\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3855 - accuracy: 0.8867\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3606 - accuracy: 0.8800\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3514 - accuracy: 0.9000\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3373 - accuracy: 0.9067\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3261 - accuracy: 0.8933\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3177 - accuracy: 0.9000\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3198 - accuracy: 0.9067\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3009 - accuracy: 0.8933\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3024 - accuracy: 0.9267\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2972 - accuracy: 0.8933\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2944 - accuracy: 0.9133\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2833 - accuracy: 0.9000\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2655 - accuracy: 0.9200\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2382 - accuracy: 0.9267\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2253 - accuracy: 0.9200\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2127 - accuracy: 0.9133\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1954 - accuracy: 0.9467\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1899 - accuracy: 0.9467\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1960 - accuracy: 0.9400\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2012 - accuracy: 0.9333\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1867 - accuracy: 0.9467\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1650 - accuracy: 0.9267\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1430 - accuracy: 0.9467\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1254 - accuracy: 0.9533\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1130 - accuracy: 0.9467\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0981 - accuracy: 0.9467\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0832 - accuracy: 0.9467\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0714 - accuracy: 0.9400\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0616 - accuracy: 0.9600\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0488 - accuracy: 0.9600\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0395 - accuracy: 0.9600\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0317 - accuracy: 0.9533\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0211 - accuracy: 0.9733\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0071 - accuracy: 0.9667\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9972 - accuracy: 0.9667\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9876 - accuracy: 0.9667\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9781 - accuracy: 0.9667\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9650 - accuracy: 0.9733\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9555 - accuracy: 0.9733\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.9437 - accuracy: 0.9733\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9327 - accuracy: 0.9600\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9221 - accuracy: 0.9733\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9226 - accuracy: 0.9467\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9105 - accuracy: 0.9733\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8952 - accuracy: 0.9667\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8880 - accuracy: 0.9667\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8871 - accuracy: 0.9667\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8818 - accuracy: 0.9800\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8616 - accuracy: 0.9733\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.8530 - accuracy: 0.9667\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8458 - accuracy: 0.9867\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8432 - accuracy: 0.9733\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.8352 - accuracy: 0.9800\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8416 - accuracy: 0.9667\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8562 - accuracy: 0.9533\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8454 - accuracy: 0.9800\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.8201 - accuracy: 0.9933\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.8324 - accuracy: 0.9667\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.8122 - accuracy: 0.9733\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7943 - accuracy: 0.9800\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7933 - accuracy: 0.9800\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8086 - accuracy: 0.9667\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8196 - accuracy: 0.9733\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8425 - accuracy: 0.9400\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8160 - accuracy: 0.9533\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7729 - accuracy: 0.9733\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7603 - accuracy: 0.9800\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7402 - accuracy: 0.9933\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7285 - accuracy: 0.9933\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7155 - accuracy: 0.9933\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7079 - accuracy: 0.9933\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7007 - accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6816 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6715 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6616 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6624 - accuracy: 0.9933\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6468 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6431 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6303 - accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6260 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6205 - accuracy: 0.9933\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6152 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6169 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6199 - accuracy: 0.9867\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6381 - accuracy: 0.9933\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6285 - accuracy: 0.9933\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6450 - accuracy: 0.9800\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6063 - accuracy: 0.9867\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5866 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5742 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5633 - accuracy: 0.9933\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5593 - accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5520 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5517 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5485 - accuracy: 0.9867\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5465 - accuracy: 0.9933\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5415 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5311 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5312 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5223 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5123 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5069 - accuracy: 0.9933\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5465 - accuracy: 0.9800\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.9867\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5230 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5147 - accuracy: 0.9867\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5364 - accuracy: 0.9800\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5045 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5010 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4845 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4791 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4726 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4777 - accuracy: 0.9867\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4597 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4546 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4542 - accuracy: 0.9933\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4586 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4522 - accuracy: 0.9933\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4388 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4303 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4268 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4177 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4168 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4108 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4069 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3946 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3899 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3874 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3807 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3749 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3717 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3662 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3620 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3594 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3568 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3508 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3475 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3434 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3397 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3362 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3334 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3303 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3285 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3291 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3498 - accuracy: 0.9867\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3352 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3550 - accuracy: 0.9867\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3332 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3278 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3185 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3115 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3067 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3007 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2955 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2932 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2893 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2855 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2824 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2793 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2769 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2739 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2717 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2689 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2658 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2634 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2613 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2595 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2568 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2536 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2517 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2488 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2470 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2457 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2444 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2421 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2412 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2384 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2374 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2361 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2350 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2334 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2297 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2276 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2272 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2258 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2279 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2423 - accuracy: 0.9933\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2394 - accuracy: 0.9933\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2312 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2359 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2825 - accuracy: 0.9867\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2624 - accuracy: 0.9867\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2709 - accuracy: 0.9867\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2605 - accuracy: 0.9800\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2589 - accuracy: 0.9867\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2428 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2435 - accuracy: 0.9867\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2374 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2727 - accuracy: 0.9800\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2661 - accuracy: 0.9867\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2348 - accuracy: 0.9933\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2209 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2147 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2139 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2307 - accuracy: 0.9867\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2153 - accuracy: 0.9933\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1971 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1939 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1912 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2030 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2479 - accuracy: 0.9867\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2403 - accuracy: 0.9933\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2013 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1965 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1850 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1767 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1744 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1706 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1695 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1664 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1649 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1625 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1608 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1589 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1558 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1541 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1530 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1519 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1505 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1499 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1481 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1459 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1446 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1434 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1421 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1411 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1399 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1388 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1378 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1368 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1356 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1347 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1337 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1326 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1307 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1294 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1289 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1276 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1269 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1259 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1250 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1242 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1233 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1227 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1213 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1207 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1196 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1180 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1164 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1154 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1145 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1137 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1129 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1113 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1105 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1099 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1090 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1081 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1060 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1053 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1048 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1039 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1032 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1026 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1021 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1014 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1006 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1000 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0994 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0991 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0983 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0972 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0969 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0955 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0947 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0942 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0933 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0930 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0923 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0911 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0899 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0893 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0882 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0879 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0874 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0866 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0861 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0829 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0823 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0819 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0812 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0803 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0798 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0795 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0789 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0780 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0773 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0770 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0760 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0756 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0746 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0738 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0728 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0725 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0712 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0704 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0695 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0683 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0679 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0675 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0663 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0647 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0632 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0600 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Sequential model\n",
    "model = tf.keras.Sequential([  # Initialize a Sequential model\n",
    "\n",
    "    tf.keras.layers.Embedding(vocab_size,                    # Set the vocabulary size as the number of possible word indices.\n",
    "                              64,                            # Set the dimension of the dense embedding output to 64.\n",
    "                              input_length=max_seq_len-1),   # Specify the length of the input sequences.\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), # Bidirectional LSTM layer with 32 units: \n",
    "                                                             # processes sequences in both directions (forward and backward)\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')  # Dense layer: fully connected with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model with loss, optimizer, and evaluation metric\n",
    "model.compile(                    \n",
    "    loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "    optimizer='adam',                 # Adaptive Moment Estimation optimizer\n",
    "    metrics=['accuracy']              # Evaluate model performance using accuracy\n",
    ")\n",
    "\n",
    "# Train the model with input data X and target labels y\n",
    "history = model.fit(  \n",
    "    X,           # Input sequences\n",
    "    y,           # Target labels\n",
    "    epochs=500,  # Train for 500 epochs\n",
    "    verbose=1    # Print progress during training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDpFBjlzm1Up"
   },
   "source": [
    "#### Visualize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tc7nqPbg5tBy"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.show()\n",
    "\n",
    "plot_metric(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows how the accuracy of the model has increased from epoch by epoch. So, in the range of let's say 290 or 300 epoch, we reached close to hundred percent accuracy and it took the model somewhere around 250, 200 epochs to reach that accuracy level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GLsNdvSm3uv"
   },
   "source": [
    "#### Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "db3z5YdkrtXI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a cold night. thundered though thundered on the castle days fire end on for turned into muddy muddy streams and streams and hagrid's pumpkins swelled to the size of garden sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds sheds percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy sheds sheds sheds sheds sheds sheds sheds percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy percy sheds sheds sheds sheds sheds sheds sheds percy percy percy percy percy percy percy percy\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a cold night.\"  # Initial seed text for generating predictions\n",
    "\n",
    "##add number of words you want to predict\n",
    "next_words = 100  # Number of words to generate\n",
    "\n",
    "##run the loop to predict and concatenate the word\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]                      # Convert seed text to sequence of tokens\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')  # Pad sequences to the required length\n",
    "\n",
    "    ##predict the class using the trained model\n",
    "    predicted_probs = model.predict(token_list, verbose=0)  # Predict the next word probabilities\n",
    "    predicted = np.argmax(predicted_probs, axis=-1)         # Get the index of the highest probability\n",
    "    \n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        \n",
    "        ##reference the predicted class with the vocabulary\n",
    "        if index == predicted:      # Match the predicted index to the word in the tokenizer\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word  # Append the predicted word to the seed text\n",
    "    \n",
    "print(seed_text)                    # Print the generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a challenge on how to create poetry like Shakespeare by leveraging RNNs(LSTMs). We'll be using the Shakerpeare poetry as the training data and then use the trained network to predict the next words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "##import the required libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28893\n"
     ]
    }
   ],
   "source": [
    "##printing the text\n",
    "shakespeare_text = open('data/sonnets.txt').read()\n",
    "print(len(shakespeare_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " '',\n",
       " ' from fairest creatures we desire increase,',\n",
       " \" that thereby beauty's rose might never die,\",\n",
       " ' but as the riper should by time decease,',\n",
       " ' his tender heir might bear his memory:',\n",
       " ' but thou, contracted to thine own bright eyes,',\n",
       " \" feed'st thy light's flame with self-substantial fuel,\",\n",
       " ' making a famine where abundance lies,',\n",
       " ' thy self thy foe, to thy sweet self too cruel:']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create corpus by lowering the letters and splitting the text by \\n\n",
    "corpus = shakespeare_text.lower().split(\"\\n\")\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Train the tokenizer and create word encoding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544\n"
     ]
    }
   ],
   "source": [
    "##set up tokenizer\n",
    "tokenizer = Tokenizer()     # Initialize the tokenizer\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)              # Fit the tokenizer on the corpus to build word index\n",
    "\n",
    "##calculate vocabulary size - be mindful of the token\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Calculate vocabulary size (+1 for the padding token)\n",
    "\n",
    "#print(tokenizer.word_index)\n",
    "\n",
    "print(vocab_size)           # Print the vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create N-gram sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create sequences of \n",
    "input_sequences = []                                  # Initialize list to store sequences\n",
    "for line in corpus:                                   # Iterate over each line in the corpus\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0]  # Convert the line to token indices\n",
    "    for i in range(1, len(tokens)):                   # Create n-gram sequences\n",
    "        n_gram_sequence = tokens[:i+1]                # Create sequence from the start up to the current index\n",
    "        input_sequences.append(n_gram_sequence)       # Append the sequence to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Pad those sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pad sequences\n",
    "max_seq_len = max([len(i) for i in input_sequences])          # Determine the length of the longest sequence\n",
    "input_seq_array = np.array(pad_sequences(input_sequences,     # Pad sequences to ensure uniform length\n",
    "                                         maxlen=max_seq_len,  # Maximum length of sequences\n",
    "                                         padding='pre')       # Pad sequences at the beginning\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Segregate features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating features(X) and label(y)\n",
    "X = input_seq_array[:, :-1]      # Extract features: all columns except the last one\n",
    "labels = input_seq_array[:, -1]  # Extract labels: the last column\n",
    "\n",
    "##one-hot encode the labels to get y - since it is actually just a classification problem\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)  # Convert labels to one-hot encoded format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "142/142 [==============================] - 10s 27ms/step - loss: 6.6995 - accuracy: 0.0230\n",
      "Epoch 2/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 6.0449 - accuracy: 0.0415\n",
      "Epoch 3/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 5.3739 - accuracy: 0.0696\n",
      "Epoch 4/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 4.4038 - accuracy: 0.1335\n",
      "Epoch 5/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 3.2641 - accuracy: 0.2921\n",
      "Epoch 6/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 2.2285 - accuracy: 0.4872\n",
      "Epoch 7/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.5182 - accuracy: 0.6456\n",
      "Epoch 8/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 1.0113 - accuracy: 0.7689\n",
      "Epoch 9/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.7314 - accuracy: 0.8369\n",
      "Epoch 10/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.5871 - accuracy: 0.8615\n",
      "Epoch 11/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.5208 - accuracy: 0.8699\n",
      "Epoch 12/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.4780 - accuracy: 0.8736\n",
      "Epoch 13/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.4571 - accuracy: 0.8769\n",
      "Epoch 14/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.4455 - accuracy: 0.8747\n",
      "Epoch 15/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.4336 - accuracy: 0.8780\n",
      "Epoch 16/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.4286 - accuracy: 0.8756\n",
      "Epoch 17/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4197 - accuracy: 0.8765\n",
      "Epoch 18/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.4149 - accuracy: 0.8749\n",
      "Epoch 19/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4074 - accuracy: 0.8776\n",
      "Epoch 20/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4086 - accuracy: 0.8776\n",
      "Epoch 21/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4060 - accuracy: 0.8767\n",
      "Epoch 22/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4060 - accuracy: 0.8752\n",
      "Epoch 23/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4056 - accuracy: 0.8738\n",
      "Epoch 24/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3961 - accuracy: 0.8767\n",
      "Epoch 25/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4014 - accuracy: 0.8763\n",
      "Epoch 26/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3974 - accuracy: 0.8747\n",
      "Epoch 27/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3957 - accuracy: 0.8778\n",
      "Epoch 28/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3940 - accuracy: 0.8745\n",
      "Epoch 29/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3938 - accuracy: 0.8765\n",
      "Epoch 30/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.6311 - accuracy: 0.8182\n",
      "Epoch 31/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 4.1364 - accuracy: 0.1969\n",
      "Epoch 32/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 2.7160 - accuracy: 0.3654\n",
      "Epoch 33/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 1.5400 - accuracy: 0.6012\n",
      "Epoch 34/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.8838 - accuracy: 0.7711\n",
      "Epoch 35/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.5937 - accuracy: 0.8504\n",
      "Epoch 36/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4827 - accuracy: 0.8705\n",
      "Epoch 37/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4397 - accuracy: 0.8756\n",
      "Epoch 38/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4211 - accuracy: 0.8738\n",
      "Epoch 39/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4090 - accuracy: 0.8774\n",
      "Epoch 40/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4087 - accuracy: 0.8756\n",
      "Epoch 41/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3971 - accuracy: 0.8769\n",
      "Epoch 42/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 0.4000 - accuracy: 0.8756\n",
      "Epoch 43/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3962 - accuracy: 0.8765\n",
      "Epoch 44/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 0.3954 - accuracy: 0.8743\n",
      "Epoch 45/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 0.3924 - accuracy: 0.8767\n",
      "Epoch 46/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3891 - accuracy: 0.8756\n",
      "Epoch 47/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3916 - accuracy: 0.8736\n",
      "Epoch 48/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3879 - accuracy: 0.8760\n",
      "Epoch 49/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3835 - accuracy: 0.8791\n",
      "Epoch 50/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3849 - accuracy: 0.8765\n",
      "Epoch 51/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 0.3867 - accuracy: 0.8760\n",
      "Epoch 52/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3843 - accuracy: 0.8763\n",
      "Epoch 53/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3817 - accuracy: 0.8754\n",
      "Epoch 54/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3865 - accuracy: 0.8756\n",
      "Epoch 55/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3842 - accuracy: 0.8778\n",
      "Epoch 56/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3851 - accuracy: 0.8778\n",
      "Epoch 57/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3904 - accuracy: 0.8772\n",
      "Epoch 58/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3950 - accuracy: 0.8774\n",
      "Epoch 59/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.4042 - accuracy: 0.8725\n",
      "Epoch 60/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 1.4637 - accuracy: 0.6456\n",
      "Epoch 61/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 3.3052 - accuracy: 0.3115\n",
      "Epoch 62/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 1.8570 - accuracy: 0.5354\n",
      "Epoch 63/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 1.0705 - accuracy: 0.7148\n",
      "Epoch 64/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.6887 - accuracy: 0.8160\n",
      "Epoch 65/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.5120 - accuracy: 0.8621\n",
      "Epoch 66/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4481 - accuracy: 0.8741\n",
      "Epoch 67/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.4223 - accuracy: 0.8772\n",
      "Epoch 68/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.4047 - accuracy: 0.8760\n",
      "Epoch 69/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.4028 - accuracy: 0.8774\n",
      "Epoch 70/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4004 - accuracy: 0.8763\n",
      "Epoch 71/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.3985 - accuracy: 0.8763\n",
      "Epoch 72/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.3952 - accuracy: 0.8760\n",
      "Epoch 73/200\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 0.3942 - accuracy: 0.8756\n",
      "Epoch 74/200\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 0.3909 - accuracy: 0.8756\n",
      "Epoch 75/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3895 - accuracy: 0.8774\n",
      "Epoch 76/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3911 - accuracy: 0.8772\n",
      "Epoch 77/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3885 - accuracy: 0.8763\n",
      "Epoch 78/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.3871 - accuracy: 0.8743\n",
      "Epoch 79/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3903 - accuracy: 0.8769\n",
      "Epoch 80/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.3881 - accuracy: 0.8772\n",
      "Epoch 81/200\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 0.3878 - accuracy: 0.8754\n",
      "Epoch 82/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3867 - accuracy: 0.8747\n",
      "Epoch 83/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3832 - accuracy: 0.8760\n",
      "Epoch 84/200\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.3851 - accuracy: 0.8769\n",
      "Epoch 85/200\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.3799 - accuracy: 0.8791\n",
      "Epoch 86/200\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.3841 - accuracy: 0.8765\n",
      "Epoch 87/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3867 - accuracy: 0.8749\n",
      "Epoch 88/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3843 - accuracy: 0.8760\n",
      "Epoch 89/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3833 - accuracy: 0.8767\n",
      "Epoch 90/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3895 - accuracy: 0.8727\n",
      "Epoch 91/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3921 - accuracy: 0.8754\n",
      "Epoch 92/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.9314 - accuracy: 0.7598\n",
      "Epoch 93/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 3.1458 - accuracy: 0.3568\n",
      "Epoch 94/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 2.0287 - accuracy: 0.5223\n",
      "Epoch 95/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.1729 - accuracy: 0.6823\n",
      "Epoch 96/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.7349 - accuracy: 0.8014\n",
      "Epoch 97/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.5528 - accuracy: 0.8480\n",
      "Epoch 98/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.4652 - accuracy: 0.8723\n",
      "Epoch 99/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4367 - accuracy: 0.8714\n",
      "Epoch 100/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4145 - accuracy: 0.8745\n",
      "Epoch 101/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4057 - accuracy: 0.8756\n",
      "Epoch 102/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4028 - accuracy: 0.8758\n",
      "Epoch 103/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3957 - accuracy: 0.8765\n",
      "Epoch 104/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3918 - accuracy: 0.8780\n",
      "Epoch 105/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3912 - accuracy: 0.8758\n",
      "Epoch 106/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3916 - accuracy: 0.8765\n",
      "Epoch 107/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3889 - accuracy: 0.8765\n",
      "Epoch 108/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3903 - accuracy: 0.8758\n",
      "Epoch 109/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3881 - accuracy: 0.8752\n",
      "Epoch 110/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3855 - accuracy: 0.8765\n",
      "Epoch 111/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3863 - accuracy: 0.8749\n",
      "Epoch 112/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3836 - accuracy: 0.8765\n",
      "Epoch 113/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3843 - accuracy: 0.8780\n",
      "Epoch 114/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3871 - accuracy: 0.8780\n",
      "Epoch 115/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3853 - accuracy: 0.8758\n",
      "Epoch 116/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3827 - accuracy: 0.8783\n",
      "Epoch 117/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3872 - accuracy: 0.8772\n",
      "Epoch 118/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3795 - accuracy: 0.8778\n",
      "Epoch 119/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.3878 - accuracy: 0.8752\n",
      "Epoch 120/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3823 - accuracy: 0.8774\n",
      "Epoch 121/200\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.3839 - accuracy: 0.8774\n",
      "Epoch 122/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.3854 - accuracy: 0.8765\n",
      "Epoch 123/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.3878 - accuracy: 0.8758\n",
      "Epoch 124/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3980 - accuracy: 0.8754\n",
      "Epoch 125/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.7838 - accuracy: 0.7886\n",
      "Epoch 126/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 2.7212 - accuracy: 0.4335\n",
      "Epoch 127/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 1.9408 - accuracy: 0.5360\n",
      "Epoch 128/200\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.1191 - accuracy: 0.6997\n",
      "Epoch 129/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.7297 - accuracy: 0.7916\n",
      "Epoch 130/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.5408 - accuracy: 0.8482\n",
      "Epoch 131/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4600 - accuracy: 0.8681\n",
      "Epoch 132/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4242 - accuracy: 0.8747\n",
      "Epoch 133/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.4091 - accuracy: 0.8778\n",
      "Epoch 134/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.4020 - accuracy: 0.8776\n",
      "Epoch 135/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.3941 - accuracy: 0.8778\n",
      "Epoch 136/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3931 - accuracy: 0.8752\n",
      "Epoch 137/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3914 - accuracy: 0.8772\n",
      "Epoch 138/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3903 - accuracy: 0.8749\n",
      "Epoch 139/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3892 - accuracy: 0.8767\n",
      "Epoch 140/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3902 - accuracy: 0.8752\n",
      "Epoch 141/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3881 - accuracy: 0.8763\n",
      "Epoch 142/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3834 - accuracy: 0.8780\n",
      "Epoch 143/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3841 - accuracy: 0.8783\n",
      "Epoch 144/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3835 - accuracy: 0.8756\n",
      "Epoch 145/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3832 - accuracy: 0.8774\n",
      "Epoch 146/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3844 - accuracy: 0.8776\n",
      "Epoch 147/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3844 - accuracy: 0.8756\n",
      "Epoch 148/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.3825 - accuracy: 0.8776\n",
      "Epoch 149/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3842 - accuracy: 0.8763\n",
      "Epoch 150/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3840 - accuracy: 0.8754\n",
      "Epoch 151/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3836 - accuracy: 0.8756\n",
      "Epoch 152/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3840 - accuracy: 0.8767\n",
      "Epoch 153/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.3832 - accuracy: 0.8780\n",
      "Epoch 154/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3824 - accuracy: 0.8756\n",
      "Epoch 155/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3860 - accuracy: 0.8789\n",
      "Epoch 156/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3923 - accuracy: 0.8758\n",
      "Epoch 157/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.5957 - accuracy: 0.8305\n",
      "Epoch 158/200\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 2.3283 - accuracy: 0.5053\n",
      "Epoch 159/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.8579 - accuracy: 0.5619\n",
      "Epoch 160/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.1377 - accuracy: 0.6922\n",
      "Epoch 161/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.7603 - accuracy: 0.7857\n",
      "Epoch 162/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.5763 - accuracy: 0.8383\n",
      "Epoch 163/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4942 - accuracy: 0.8604\n",
      "Epoch 164/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4429 - accuracy: 0.8707\n",
      "Epoch 165/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4210 - accuracy: 0.8758\n",
      "Epoch 166/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4094 - accuracy: 0.8765\n",
      "Epoch 167/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4022 - accuracy: 0.8760\n",
      "Epoch 168/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4001 - accuracy: 0.8772\n",
      "Epoch 169/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3939 - accuracy: 0.8772\n",
      "Epoch 170/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3940 - accuracy: 0.8769\n",
      "Epoch 171/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3880 - accuracy: 0.8783\n",
      "Epoch 172/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3877 - accuracy: 0.8763\n",
      "Epoch 173/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3877 - accuracy: 0.8769\n",
      "Epoch 174/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3878 - accuracy: 0.8763\n",
      "Epoch 175/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3873 - accuracy: 0.8765\n",
      "Epoch 176/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3835 - accuracy: 0.8776\n",
      "Epoch 177/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3873 - accuracy: 0.8772\n",
      "Epoch 178/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3858 - accuracy: 0.8763\n",
      "Epoch 179/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3869 - accuracy: 0.8772\n",
      "Epoch 180/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3856 - accuracy: 0.8747\n",
      "Epoch 181/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3842 - accuracy: 0.8772\n",
      "Epoch 182/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3800 - accuracy: 0.8778\n",
      "Epoch 183/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3847 - accuracy: 0.8765\n",
      "Epoch 184/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3898 - accuracy: 0.8747\n",
      "Epoch 185/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3976 - accuracy: 0.8758\n",
      "Epoch 186/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4679 - accuracy: 0.8610\n",
      "Epoch 187/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.3180 - accuracy: 0.6697\n",
      "Epoch 188/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 1.7307 - accuracy: 0.5917\n",
      "Epoch 189/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.1835 - accuracy: 0.6913\n",
      "Epoch 190/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.8272 - accuracy: 0.7680\n",
      "Epoch 191/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.6204 - accuracy: 0.8235\n",
      "Epoch 192/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4999 - accuracy: 0.8584\n",
      "Epoch 193/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4454 - accuracy: 0.8710\n",
      "Epoch 194/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.4177 - accuracy: 0.8741\n",
      "Epoch 195/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.4070 - accuracy: 0.8767\n",
      "Epoch 196/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.4002 - accuracy: 0.8772\n",
      "Epoch 197/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.3942 - accuracy: 0.8780\n",
      "Epoch 198/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 0.3927 - accuracy: 0.8747\n",
      "Epoch 199/200\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3906 - accuracy: 0.8743\n",
      "Epoch 200/200\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3913 - accuracy: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential([ \n",
    "    \n",
    "    # Embedding layer: Converts input sequences into dense vectors of fixed size\n",
    "    tf.keras.layers.Embedding(vocab_size, 120, input_length=max_seq_len-1),  # vocab_size: size of the vocabulary; \n",
    "                                                                             # 120: dimensionality of the output space; \n",
    "                                                                             # max_seq_len-1: length of input sequences\n",
    "    \n",
    "    # Bidirectional LSTM layer: Processes the input sequences in both forward and backward directions to capture context from both sides\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(120)),  # 120: number of output units for the LSTM layer\n",
    "\n",
    "    # Dense layer: Output layer that produces a probability distribution over the vocabulary (softmax activation function)\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')  # vocab_size: number of output neurons equal to the size of the vocabulary; \n",
    "                                                             # 'softmax': activation function for multi-class classification\n",
    "])\n",
    "\n",
    "# Define the learning rate - step size for the optimizer\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01)  # Adam optimizer with a learning rate of 0.01\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "              optimizer=adam,                   # Optimizer to use for updating the model weights\n",
    "              metrics=['accuracy'])             # Metric to evaluate the model's performance\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X, y,        # X: input data; y: target data\n",
    "                    epochs=200,  # Number of epochs (iterations over the entire dataset)\n",
    "                    verbose=1)   # Verbosity mode; 1 displays progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.show()\n",
    "\n",
    "plot_metric(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a cold night. my cloak day my grief me receivest hence thee be thee hence thee thee tongue rain is it for thee me ' through as if self art me more days me travel forth without my brow muse me more beauty hidden thee me hence thee me ' is me mine me me number me but me me alack that am fair me me me before me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a cold night.\"  # Starting text for generating new words\n",
    "next_words = 100                    # Number of words to generate\n",
    "\n",
    "# Loop to generate the next 'next_words' words\n",
    "for _ in range(next_words):\n",
    "    \n",
    "    # Convert the seed text to a sequence of integers based on the tokenizer's vocabulary\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    \n",
    "    # Pad the sequence to ensure it matches the input length required by the model\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "    \n",
    "    # Predict the probability distribution of the next word using the model\n",
    "    predicted_probs = model.predict(token_list, verbose=0)  # Use predict() to get probabilities\n",
    "    \n",
    "    # Get the index of the word with the highest predicted probability\n",
    "    predicted = np.argmax(predicted_probs, axis=-1)  # Find the index of the max probability\n",
    "    \n",
    "    output_word = \"\"  # Initialize an empty string to store the predicted word\n",
    "    \n",
    "    # Loop through the tokenizer's word index to find the word corresponding to the predicted index\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        \n",
    "        if index == predicted:  # Check if the index matches the predicted index\n",
    "            output_word = word  # If it matches, set the output word\n",
    "            break               # Exit the loop as we found the word\n",
    "    \n",
    "    # Append the predicted word to the seed text to form a new input for the next prediction\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)  # Print the generated text"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMuN4awaNnVTEn4aO8QlDbV",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "04_02_begin.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
